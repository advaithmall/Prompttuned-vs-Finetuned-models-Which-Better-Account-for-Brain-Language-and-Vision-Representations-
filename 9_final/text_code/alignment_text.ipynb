{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/advaith.malladi/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_summ_path = \"./models/summ_ft.pt\"\n",
    "fine_tuned_qna_path = \"./models/qa_ft.pt\"\n",
    "fine_tuned_trans_model = \"./models/trans_ft.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_qa_model = torch.load(fine_tuned_qna_path)\n",
    "finetuned_summ_model = torch.load(fine_tuned_summ_path)\n",
    "finetuned_trans_model = torch.load(fine_tuned_trans_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "finetuned_qa_model = finetuned_qa_model.to(\"cpu\")\n",
    "finetuned_summ_model = finetuned_summ_model.to(\"cpu\")\n",
    "finetuned_trans_model = finetuned_trans_model.to(\"cpu\")\n",
    "def get_summ_feats(encoded_input):\n",
    "        output = finetuned_summ_model(encoded_input)\n",
    "        summ_row = 0\n",
    "        for row in output[1]:\n",
    "            for loc_row in row:\n",
    "                # shape of loc row is 1, a, b, c\n",
    "                # reshape it to 1, b, a*c\n",
    "                reshaped = loc_row.reshape(1, loc_row.shape[2], loc_row.shape[1]*loc_row.shape[3])\n",
    "                #print(summ_row)\n",
    "                if type(summ_row) == int:\n",
    "                    summ_row = reshaped\n",
    "                else:\n",
    "                    summ_row = summ_row + reshaped\n",
    "        return summ_row\n",
    "    \n",
    "def get_qa_feats(encoded_input):\n",
    "    output = finetuned_qa_model(encoded_input)\n",
    "    summ_row = 0\n",
    "    for row in output[1]:\n",
    "        for loc_row in row:\n",
    "            # shape of loc row is 1, a, b, c\n",
    "            # reshape it to 1, b, a*c\n",
    "            reshaped = loc_row.reshape(1, loc_row.shape[2], loc_row.shape[1]*loc_row.shape[3])\n",
    "            #print(summ_row)\n",
    "            if type(summ_row) == int:\n",
    "                summ_row = reshaped\n",
    "            else:\n",
    "                summ_row = summ_row + reshaped\n",
    "    return summ_row\n",
    "\n",
    "def get_trans_feats(encoded_input):\n",
    "    output = finetuned_trans_model(encoded_input)\n",
    "    summ_row = 0\n",
    "    for row in output[1]:\n",
    "        for loc_row in row:\n",
    "            # shape of loc row is 1, a, b, c\n",
    "            # reshape it to 1, b, a*c\n",
    "            reshaped = loc_row.reshape(1, loc_row.shape[2], loc_row.shape[1]*loc_row.shape[3])\n",
    "            #print(summ_row)\n",
    "            if type(summ_row) == int:\n",
    "                summ_row = reshaped\n",
    "            else:\n",
    "                summ_row = summ_row + reshaped\n",
    "    return summ_row\n",
    "\n",
    "def get_feats(list_sents, max_length):\n",
    "    summ_reps = []\n",
    "    qa_reps = []\n",
    "    trans_reps = []\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    for sent in tqdm(list_sents, total = len(list_sents)):\n",
    "        input_s = tokenizer.encode(sent,return_tensors=\"pt\", max_length=max_length, truncation=True, padding=\"max_length\")   \n",
    "        summ_feats = get_summ_feats(input_s)\n",
    "        trans_feats = get_trans_feats(input_s)\n",
    "        qa_feats = get_qa_feats(input_s)\n",
    "        # convert shape from 1, x, 768 to x, 768\n",
    "        summ_feats = summ_feats.squeeze(0)\n",
    "        trans_feats = trans_feats.squeeze(0)\n",
    "        qa_feats = qa_feats.squeeze(0)\n",
    "        summ_feats = np.array(torch.mean(summ_feats, dim=0).detach().numpy())\n",
    "        trans_feats = np.array(torch.mean(trans_feats, dim=0).detach().numpy())\n",
    "        qa_feats = np.array(torch.mean(qa_feats, dim=0).detach().numpy())   \n",
    "        summ_reps.append(summ_feats)\n",
    "        qa_reps.append(qa_feats)\n",
    "        trans_reps.append(trans_feats)\n",
    "    return summ_reps, qa_reps, trans_reps  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the stim and fmri data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/advaith.malladi\n"
     ]
    }
   ],
   "source": [
    "# print cwd\n",
    "import os\n",
    "print(os.getcwd())\n",
    "working_dir = \"csai_a5\"\n",
    "# switch to working dir\n",
    "os.chdir(working_dir)\n",
    "\n",
    "parent_dir = \"assignment5\"\n",
    "stim_file = \"stimuli.txt\"\n",
    "subj1 = \"subj1.npy\"\n",
    "subj2 = \"subj2.npy\"\n",
    "# load the stims file\n",
    "import regex as re\n",
    "with open(os.path.join(parent_dir, stim_file), \"r\") as f:\n",
    "    stims = f.readlines()\n",
    "final_stims = []\n",
    "for item in stims:\n",
    "    # remove all numbers and punctuation\n",
    "    item = re.sub(r'[^\\w\\s]','',item)\n",
    "    # remove all numbers\n",
    "    item = re.sub(r'\\d+', '', item)\n",
    "    item = item.lower()\n",
    "    final_stims.append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 627/627 [00:49<00:00, 12.64it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "import numpy as np\n",
    "for sent in final_stims:\n",
    "    length= len(sent.split())\n",
    "    if max_len < length:\n",
    "        max_len  = length\n",
    "print(max_len)\n",
    "max_len = max_len + 5\n",
    "summ_reps, qa_reps, trans_reps = get_feats(final_stims, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing fmri data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 11437) (627, 33792) (627, 17190) (627, 35120) (627, 10791) (627, 31109) (627, 15070) (627, 30594)\n"
     ]
    }
   ],
   "source": [
    "# load fmri data of subj1 and subj2\n",
    "import numpy as np\n",
    "subj1_data = np.load(os.path.join(parent_dir, subj1), allow_pickle=True).item()\n",
    "subj2_data = np.load(os.path.join(parent_dir, subj2), allow_pickle=True).item()\n",
    "\n",
    "subj1_lang = subj1_data[\"language\"]\n",
    "subj1_vis = subj1_data[\"vision\"]\n",
    "subj1_dmn = subj1_data[\"dmn\"]\n",
    "subj1_task = subj1_data[\"task\"]\n",
    "subj2_lang = subj2_data[\"language\"]\n",
    "subj2_vis = subj2_data[\"vision\"]\n",
    "subj2_dmn = subj2_data[\"dmn\"]\n",
    "subj2_task = subj2_data[\"task\"]\n",
    "print(subj1_lang.shape, subj1_vis.shape, subj1_dmn.shape, subj1_task.shape, subj2_lang.shape, subj2_vis.shape, subj2_dmn.shape, subj2_task.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# import R2 as well\n",
    "from sklearn.metrics import r2_score\n",
    "def cos_d(y1, y2):\n",
    "    cos_sim = np.dot(y1, y2)/(np.linalg.norm(y1)*np.linalg.norm(y2))\n",
    "    cos_d = 1 - cos_sim\n",
    "    return cos_d\n",
    "def get_2v2_accuracy(y_pred, y_test):\n",
    "    N = y_pred.shape[0]\n",
    "    tot_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    for i in range(0, N):\n",
    "        for j in range(1, N):\n",
    "            yi_test = y_test[i]\n",
    "            yi_pred = y_pred[i]\n",
    "            yj_test = y_test[j]\n",
    "            yj_pred = y_pred[j]\n",
    "            score1 = cos_d(yi_test, yi_pred) + cos_d(yj_test, yj_pred)\n",
    "            score2 = cos_d(yi_test, yj_pred) + cos_d(yj_test, yi_pred)\n",
    "            if score1 < score2:\n",
    "                pos_cnt += 1\n",
    "            tot_cnt += 1\n",
    "    return pos_cnt/tot_cnt\n",
    "\n",
    "def get_avg_corr(y_pred, y_test):\n",
    "    N = y_pred.shape[0]\n",
    "    tot_corr = 0\n",
    "    for i in range(0, N):\n",
    "        corr = np.corrcoef(y_pred[i], y_test[i])[0,1]\n",
    "        tot_corr += corr\n",
    "    return tot_corr/N\n",
    "\n",
    "def decoding_module(X, y):\n",
    "    kf = KFold(n_splits=5)\n",
    "    mse = []\n",
    "    r2 = []\n",
    "    acc = []\n",
    "    acc_scores = []\n",
    "    corr_scores = []\n",
    "    for train_index, test_index in  kf.split(X) :\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        get_2v2_accuracy(y_pred, y_test)\n",
    "        mse.append(mean_squared_error(y_test, y_pred))\n",
    "        r2.append(r2_score(y_test, y_pred))\n",
    "        acc_scores.append(get_2v2_accuracy(y_pred, y_test))\n",
    "        corr_scores.append(get_avg_corr(y_pred, y_test))\n",
    "    loc_dict = {}\n",
    "    loc_dict[\"MSE\"] = np.mean(mse)\n",
    "    loc_dict[\"R2\"] = np.mean(r2)\n",
    "    loc_dict[\"Accuracy\"] = np.mean(acc_scores)\n",
    "    loc_dict[\"Correlation\"] = np.mean(corr_scores)\n",
    "    return loc_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "subj1_decoding_scores = {}\n",
    "subj2_decoding_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# import R2 as well\n",
    "from sklearn.metrics import r2_score\n",
    "def cos_d(y1, y2):\n",
    "    cos_sim = np.dot(y1, y2)/(np.linalg.norm(y1)*np.linalg.norm(y2))\n",
    "    cos_d = 1 - cos_sim\n",
    "    return cos_d\n",
    "def get_2v2_accuracy(y_pred, y_test):\n",
    "    N = y_pred.shape[0]\n",
    "    tot_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    for i in range(0, N):\n",
    "        for j in range(1, N):\n",
    "            yi_test = y_test[i]\n",
    "            yi_pred = y_pred[i]\n",
    "            yj_test = y_test[j]\n",
    "            yj_pred = y_pred[j]\n",
    "            score1 = cos_d(yi_test, yi_pred) + cos_d(yj_test, yj_pred)\n",
    "            score2 = cos_d(yi_test, yj_pred) + cos_d(yj_test, yi_pred)\n",
    "            if score1 < score2:\n",
    "                pos_cnt += 1\n",
    "            tot_cnt += 1\n",
    "    return pos_cnt/tot_cnt\n",
    "\n",
    "def get_avg_corr(y_pred, y_test):\n",
    "    N = y_pred.shape[0]\n",
    "    tot_corr = 0\n",
    "    for i in range(0, N):\n",
    "        corr = np.corrcoef(y_pred[i], y_test[i])[0,1]\n",
    "        tot_corr += corr\n",
    "    return tot_corr/N\n",
    "\n",
    "def decoding_module(X, y):\n",
    "    kf = KFold(n_splits=5)\n",
    "    mse = []\n",
    "    r2 = []\n",
    "    acc = []\n",
    "    acc_scores = []\n",
    "    corr_scores = []\n",
    "    for train_index, test_index in  kf.split(X) :\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        get_2v2_accuracy(y_pred, y_test)\n",
    "        mse.append(mean_squared_error(y_test, y_pred))\n",
    "        r2.append(r2_score(y_test, y_pred))\n",
    "        acc_scores.append(get_2v2_accuracy(y_pred, y_test))\n",
    "        corr_scores.append(get_avg_corr(y_pred, y_test))\n",
    "    loc_dict = {}\n",
    "    loc_dict[\"MSE\"] = np.mean(mse)\n",
    "    loc_dict[\"R2\"] = np.mean(r2)\n",
    "    loc_dict[\"Accuracy\"] = np.mean(acc_scores)\n",
    "    loc_dict[\"Correlation\"] = np.mean(corr_scores)\n",
    "    return loc_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "subj1_decoding_scores = {}\n",
    "subj2_decoding_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.41692516945067587, 'R2': -0.8019612808247804, 'Accuracy': 0.673699743983615, 'Correlation': 0.9544017007764758}\n",
      "{'MSE': 0.39084791091594606, 'R2': -0.6896086010065352, 'Accuracy': 0.6787705069124425, 'Correlation': 0.9571530443214094}\n",
      "{'MSE': 0.3938045747674267, 'R2': -0.6971755711243084, 'Accuracy': 0.6303516641065028, 'Correlation': 0.9568386984066433}\n",
      "{'MSE': 0.34106144839845903, 'R2': -0.46737424504526703, 'Accuracy': 0.6436487455197133, 'Correlation': 0.9624091724452206}\n",
      "{'MSE': 0.4564297108846068, 'R2': -0.9738772939264088, 'Accuracy': 0.6318384024577574, 'Correlation': 0.9502035474353422}\n",
      "{'MSE': 0.43658729847395855, 'R2': -0.883764801655705, 'Accuracy': 0.6313110087045571, 'Correlation': 0.9522742495151993}\n",
      "{'MSE': 0.442553782367756, 'R2': -0.9131307502611111, 'Accuracy': 0.6039723502304147, 'Correlation': 0.951676027193234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 1/3 [00:38<01:17, 38.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.38321955636877814, 'R2': -0.651942407208009, 'Accuracy': 0.6319266769073221, 'Correlation': 0.9579453815496233}\n",
      "{'MSE': 0.419272794888068, 'R2': -0.8096041084448489, 'Accuracy': 0.6524940092165898, 'Correlation': 0.9544916960618728}\n",
      "{'MSE': 0.39466602043034593, 'R2': -0.7027753948125922, 'Accuracy': 0.6457745007680492, 'Correlation': 0.9570191542898444}\n",
      "{'MSE': 0.39719917784617065, 'R2': -0.709646130766465, 'Accuracy': 0.6028923707117255, 'Correlation': 0.956723694549883}\n",
      "{'MSE': 0.34327483559744476, 'R2': -0.4752228768488817, 'Accuracy': 0.6298750640040962, 'Correlation': 0.9624611233021264}\n",
      "{'MSE': 0.45814226800481517, 'R2': -0.9781965060677544, 'Accuracy': 0.6253650793650793, 'Correlation': 0.9503129674625115}\n",
      "{'MSE': 0.4341286481766932, 'R2': -0.8715602041796604, 'Accuracy': 0.6388729134664619, 'Correlation': 0.9528045623275956}\n",
      "{'MSE': 0.44237874163702573, 'R2': -0.9103170684459837, 'Accuracy': 0.6024202764976959, 'Correlation': 0.9519984689888886}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 2/3 [01:18<00:39, 39.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.38442586414089824, 'R2': -0.6578138943462977, 'Accuracy': 0.6226164874551972, 'Correlation': 0.9581040126827242}\n",
      "{'MSE': 0.4125637011300068, 'R2': -0.8093906454333762, 'Accuracy': 0.6661824884792626, 'Correlation': 0.9498060662601333}\n",
      "{'MSE': 0.38763659582470406, 'R2': -0.700535513373924, 'Accuracy': 0.672794674859191, 'Correlation': 0.9527344753658804}\n",
      "{'MSE': 0.3891405586023013, 'R2': -0.7023881561868409, 'Accuracy': 0.6258461853558628, 'Correlation': 0.9525146528186641}\n",
      "{'MSE': 0.3333748383002843, 'R2': -0.45542660792621137, 'Accuracy': 0.6779006656426011, 'Correlation': 0.9590640741140166}\n",
      "{'MSE': 0.45179643834667454, 'R2': -0.9820464806508887, 'Accuracy': 0.6273511520737327, 'Correlation': 0.9451405046345769}\n",
      "{'MSE': 0.4300895490380466, 'R2': -0.8835103301434867, 'Accuracy': 0.6233701996927803, 'Correlation': 0.9476669012705873}\n",
      "{'MSE': 0.4347281196997847, 'R2': -0.9069411499493547, 'Accuracy': 0.6050431131592422, 'Correlation': 0.9471308867966709}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [01:56<00:00, 38.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.3806434855816832, 'R2': -0.6662523945201411, 'Accuracy': 0.6107594470046083, 'Correlation': 0.953483643996106}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_feats = [summ_reps, qa_reps, trans_reps]\n",
    "list_fmris = [subj1_lang, subj1_vis, subj1_dmn, subj1_task, subj2_lang, subj2_vis, subj2_dmn, subj2_task]\n",
    "feats_names = [\"prompt-tuned-summarization\", \"prompt-tuned-question-answering\", \"prompt-tuned-translation\"]\n",
    "fmri_names = ['subj1_lang', 'subj1_vis', 'subj1_dmn', 'subj1_task', 'subj2_lang', 'subj2_vis', 'subj2_dmn', 'subj2_task']\n",
    "for i in tqdm(range(len(list_feats)), total = len(list_feats)):\n",
    "    for j in range(len(list_fmris)):\n",
    "        label = \"decoding \" + feats_names[i] + \" with \" + fmri_names[j]\n",
    "        reps = list_feats[i]\n",
    "        fmris = list_fmris[j]\n",
    "        x = np.array(fmris)\n",
    "        y = np.array(reps)\n",
    "        decoding_scores = decoding_module(x, y)\n",
    "        if j < 4:\n",
    "            subj1_decoding_scores[label] = decoding_scores\n",
    "        else:\n",
    "            subj2_decoding_scores[label] = decoding_scores\n",
    "        print(decoding_scores)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# import R2 as well\n",
    "from sklearn.metrics import r2_score\n",
    "def cos_d(y1, y2):\n",
    "    cos_sim = np.dot(y1, y2)/(np.linalg.norm(y1)*np.linalg.norm(y2))\n",
    "    cos_d = 1 - cos_sim\n",
    "    return cos_d\n",
    "def get_2v2_accuracy(y_pred, y_test):\n",
    "    N = y_pred.shape[0]\n",
    "    tot_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    for i in range(0, N):\n",
    "        for j in range(1, N):\n",
    "            yi_test = y_test[i]\n",
    "            yi_pred = y_pred[i]\n",
    "            yj_test = y_test[j]\n",
    "            yj_pred = y_pred[j]\n",
    "            score1 = cos_d(yi_test, yi_pred) + cos_d(yj_test, yj_pred)\n",
    "            score2 = cos_d(yi_test, yj_pred) + cos_d(yj_test, yi_pred)\n",
    "            if score1 < score2:\n",
    "                pos_cnt += 1\n",
    "            tot_cnt += 1\n",
    "    return pos_cnt/tot_cnt\n",
    "\n",
    "def get_avg_corr(y_pred, y_test):\n",
    "    N = y_pred.shape[0]\n",
    "    tot_corr = 0\n",
    "    for i in range(0, N):\n",
    "        corr = np.corrcoef(y_pred[i], y_test[i])[0,1]\n",
    "        tot_corr += corr\n",
    "    return tot_corr/N\n",
    "\n",
    "def encoding_module(X, y):\n",
    "    kf = KFold(n_splits=5)\n",
    "    mse = []\n",
    "    r2 = []\n",
    "    acc = []\n",
    "    acc_scores = []\n",
    "    corr_scores = []\n",
    "    for train_index, test_index in  kf.split(X) :\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        get_2v2_accuracy(y_pred, y_test)\n",
    "        mse.append(mean_squared_error(y_test, y_pred))\n",
    "        r2.append(r2_score(y_test, y_pred))\n",
    "        acc_scores.append(get_2v2_accuracy(y_pred, y_test))\n",
    "        corr_scores.append(get_avg_corr(y_pred, y_test))\n",
    "    loc_dict = {}\n",
    "    loc_dict[\"MSE\"] = np.mean(mse)\n",
    "    loc_dict[\"R2\"] = np.mean(r2)\n",
    "    loc_dict[\"Accuracy\"] = np.mean(acc_scores)\n",
    "    loc_dict[\"Correlation\"] = np.mean(corr_scores)\n",
    "    return loc_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "subj1_encoding_scores = {}\n",
    "subj2_encoding_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.41692516945067587, 'R2': -0.8019612808247804, 'Accuracy': 0.673699743983615, 'Correlation': 0.9544017007764758}\n",
      "{'MSE': 0.39084791091594606, 'R2': -0.6896086010065352, 'Accuracy': 0.6787705069124425, 'Correlation': 0.9571530443214094}\n",
      "{'MSE': 0.3938045747674267, 'R2': -0.6971755711243084, 'Accuracy': 0.6303516641065028, 'Correlation': 0.9568386984066433}\n",
      "{'MSE': 0.34106144839845903, 'R2': -0.46737424504526703, 'Accuracy': 0.6436487455197133, 'Correlation': 0.9624091724452206}\n",
      "{'MSE': 0.4564297108846068, 'R2': -0.9738772939264088, 'Accuracy': 0.6318384024577574, 'Correlation': 0.9502035474353422}\n",
      "{'MSE': 0.43658729847395855, 'R2': -0.883764801655705, 'Accuracy': 0.6313110087045571, 'Correlation': 0.9522742495151993}\n",
      "{'MSE': 0.442553782367756, 'R2': -0.9131307502611111, 'Accuracy': 0.6039723502304147, 'Correlation': 0.951676027193234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 1/3 [00:37<01:14, 37.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.38321955636877814, 'R2': -0.651942407208009, 'Accuracy': 0.6319266769073221, 'Correlation': 0.9579453815496233}\n",
      "{'MSE': 0.419272794888068, 'R2': -0.8096041084448489, 'Accuracy': 0.6524940092165898, 'Correlation': 0.9544916960618728}\n",
      "{'MSE': 0.39466602043034593, 'R2': -0.7027753948125922, 'Accuracy': 0.6457745007680492, 'Correlation': 0.9570191542898444}\n",
      "{'MSE': 0.39719917784617065, 'R2': -0.709646130766465, 'Accuracy': 0.6028923707117255, 'Correlation': 0.956723694549883}\n",
      "{'MSE': 0.34327483559744476, 'R2': -0.4752228768488817, 'Accuracy': 0.6298750640040962, 'Correlation': 0.9624611233021264}\n",
      "{'MSE': 0.45814226800481517, 'R2': -0.9781965060677544, 'Accuracy': 0.6253650793650793, 'Correlation': 0.9503129674625115}\n",
      "{'MSE': 0.4341286481766932, 'R2': -0.8715602041796604, 'Accuracy': 0.6388729134664619, 'Correlation': 0.9528045623275956}\n",
      "{'MSE': 0.44237874163702573, 'R2': -0.9103170684459837, 'Accuracy': 0.6024202764976959, 'Correlation': 0.9519984689888886}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 2/3 [01:14<00:37, 37.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.38442586414089824, 'R2': -0.6578138943462977, 'Accuracy': 0.6226164874551972, 'Correlation': 0.9581040126827242}\n",
      "{'MSE': 0.4125637011300068, 'R2': -0.8093906454333762, 'Accuracy': 0.6661824884792626, 'Correlation': 0.9498060662601333}\n",
      "{'MSE': 0.38763659582470406, 'R2': -0.700535513373924, 'Accuracy': 0.672794674859191, 'Correlation': 0.9527344753658804}\n",
      "{'MSE': 0.3891405586023013, 'R2': -0.7023881561868409, 'Accuracy': 0.6258461853558628, 'Correlation': 0.9525146528186641}\n",
      "{'MSE': 0.3333748383002843, 'R2': -0.45542660792621137, 'Accuracy': 0.6779006656426011, 'Correlation': 0.9590640741140166}\n",
      "{'MSE': 0.45179643834667454, 'R2': -0.9820464806508887, 'Accuracy': 0.6273511520737327, 'Correlation': 0.9451405046345769}\n",
      "{'MSE': 0.4300895490380466, 'R2': -0.8835103301434867, 'Accuracy': 0.6233701996927803, 'Correlation': 0.9476669012705873}\n",
      "{'MSE': 0.4347281196997847, 'R2': -0.9069411499493547, 'Accuracy': 0.6050431131592422, 'Correlation': 0.9471308867966709}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [01:51<00:00, 37.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.3806434855816832, 'R2': -0.6662523945201411, 'Accuracy': 0.6107594470046083, 'Correlation': 0.953483643996106}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_feats = [summ_reps, qa_reps, trans_reps]\n",
    "list_fmris = [subj1_lang, subj1_vis, subj1_dmn, subj1_task, subj2_lang, subj2_vis, subj2_dmn, subj2_task]\n",
    "feats_names = [\"prompt-tuned-summarization\", \"prompt-tuned-question-answering\", \"prompt-tuned-translation\"]\n",
    "fmri_names = ['subj1_lang', 'subj1_vis', 'subj1_dmn', 'subj1_task', 'subj2_lang', 'subj2_vis', 'subj2_dmn', 'subj2_task']\n",
    "for i in tqdm(range(len(list_feats)), total = len(list_feats)):\n",
    "    for j in range(len(list_fmris)):\n",
    "        label = \"encoding \" + feats_names[i] + \" with \" + fmri_names[j]\n",
    "        reps = list_feats[i]\n",
    "        fmris = list_fmris[j]\n",
    "        x = np.array(fmris)\n",
    "        y = np.array(reps)\n",
    "        encoding_scores = encoding_module(x, y)\n",
    "        if j < 4:\n",
    "            subj1_encoding_scores[label] = encoding_scores\n",
    "        else:\n",
    "            subj2_encoding_scores[label] = encoding_scores\n",
    "        print(encoding_scores)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save subj1_encoding_scores as subj1_encoding_scores.json with indent 4\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# make dir scoreas and move to that dir\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft_subj1_encoding_scores.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'scores'"
     ]
    }
   ],
   "source": [
    "# save subj1_encoding_scores as subj1_encoding_scores.json with indent 4\n",
    "# make dir scoreas and move to that dir\n",
    "os.chdir(\"scores\")\n",
    "import json\n",
    "with open(\"ft_subj1_encoding_scores.json\", \"w\") as f:\n",
    "    json.dump(subj1_encoding_scores, f, indent=4)\n",
    "with open(\"ft_subj2_encoding_scores.json\", \"w\") as f:\n",
    "    json.dump(subj2_encoding_scores, f, indent=4)\n",
    "with open(\"ft_subj1_decoding_scores.json\", \"w\") as f:\n",
    "    json.dump(subj1_decoding_scores, f, indent=4)\n",
    "with open(\"ft_subj2_decoding_scores.json\", \"w\") as f:\n",
    "    json.dump(subj2_decoding_scores, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
