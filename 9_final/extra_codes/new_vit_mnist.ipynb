{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel, AutoImageProcessor\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'https://lumiere-a.akamaihd.net/v1/images/darth-vader-main_4560aff7.jpeg?region=71%2C0%2C1139%2C854'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test, take 10000 train samples and 1000 test samples\n",
    "# randomly shuffle the data list\n",
    "import random\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = torch.load('train_split_mnist.pt')\n",
    "test_split = train_split[:1000]\n",
    "train_split = train_split[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_split), len(test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "class ptuned_VIT(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ptuned_VIT, self).__init__()\n",
    "        self.model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.embeddings = nn.Embedding(3, 768)\n",
    "        self.classification_layer = nn.Linear(768, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.trainable = [self.embeddings, self.classification_layer]\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        tens = [0,1,2]\n",
    "        tens = torch.tensor(tens)\n",
    "        tens = tens.to(device)\n",
    "        x1 = self.embeddings(tens)\n",
    "        x2 = self.model.embeddings(x)\n",
    "        # change x1 shape from x, 768 to 1, x, 768\n",
    "        x1 = x1.unsqueeze(0)\n",
    "        # concat x1 and x2 along the first dimension\n",
    "        # x1 is 1, 3, 768, make is x2.shape[0], 3, 768\n",
    "        x1 = x1.expand(x2.shape[0], -1, -1)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.model.encoder(x)\n",
    "        x = x['last_hidden_state']\n",
    "        x = self.model.pooler(x)\n",
    "        x = self.classification_layer(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "        \n",
    "classes = 10\n",
    "p_tokens = 3\n",
    "import torch\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "from torch import nn, optim\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# use data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_split, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_split, batch_size=32, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0/313, Loss: 2.3010013103485107, Running Accuracy: 0.0625, Current Accuracy 0.0625\n",
      "Epoch: 0, Batch: 1/313, Loss: 2.2837631702423096, Running Accuracy: 0.140625, Current Accuracy 0.21875\n",
      "Epoch: 0, Batch: 2/313, Loss: 2.2730467319488525, Running Accuracy: 0.16666666666666666, Current Accuracy 0.21875\n",
      "Epoch: 0, Batch: 3/313, Loss: 2.2582132816314697, Running Accuracy: 0.203125, Current Accuracy 0.3125\n",
      "Epoch: 0, Batch: 4/313, Loss: 2.290294647216797, Running Accuracy: 0.1875, Current Accuracy 0.125\n",
      "Epoch: 0, Batch: 5/313, Loss: 2.208986759185791, Running Accuracy: 0.20833333333333334, Current Accuracy 0.3125\n",
      "Epoch: 0, Batch: 6/313, Loss: 2.2569849491119385, Running Accuracy: 0.20982142857142858, Current Accuracy 0.21875\n",
      "Epoch: 0, Batch: 7/313, Loss: 2.2954745292663574, Running Accuracy: 0.19921875, Current Accuracy 0.125\n",
      "Epoch: 0, Batch: 8/313, Loss: 2.2345309257507324, Running Accuracy: 0.2013888888888889, Current Accuracy 0.21875\n",
      "Epoch: 0, Batch: 9/313, Loss: 2.2632930278778076, Running Accuracy: 0.20625, Current Accuracy 0.25\n",
      "Epoch: 0, Batch: 10/313, Loss: 2.225482225418091, Running Accuracy: 0.20454545454545456, Current Accuracy 0.1875\n",
      "Epoch: 0, Batch: 11/313, Loss: 2.1978466510772705, Running Accuracy: 0.21614583333333334, Current Accuracy 0.34375\n",
      "Epoch: 0, Batch: 12/313, Loss: 2.1138153076171875, Running Accuracy: 0.23076923076923078, Current Accuracy 0.40625\n",
      "Epoch: 0, Batch: 13/313, Loss: 2.1822659969329834, Running Accuracy: 0.23883928571428573, Current Accuracy 0.34375\n",
      "Epoch: 0, Batch: 14/313, Loss: 2.2142205238342285, Running Accuracy: 0.23958333333333334, Current Accuracy 0.25\n",
      "Epoch: 0, Batch: 15/313, Loss: 2.1697349548339844, Running Accuracy: 0.24609375, Current Accuracy 0.34375\n",
      "Epoch: 0, Batch: 16/313, Loss: 2.072052001953125, Running Accuracy: 0.26286764705882354, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 17/313, Loss: 2.098304510116577, Running Accuracy: 0.2708333333333333, Current Accuracy 0.40625\n",
      "Epoch: 0, Batch: 18/313, Loss: 2.059600353240967, Running Accuracy: 0.28289473684210525, Current Accuracy 0.5\n",
      "Epoch: 0, Batch: 19/313, Loss: 2.0477657318115234, Running Accuracy: 0.2953125, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 20/313, Loss: 2.046633005142212, Running Accuracy: 0.3080357142857143, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 21/313, Loss: 2.1538286209106445, Running Accuracy: 0.31392045454545453, Current Accuracy 0.4375\n",
      "Epoch: 0, Batch: 22/313, Loss: 2.118502140045166, Running Accuracy: 0.32065217391304346, Current Accuracy 0.46875\n",
      "Epoch: 0, Batch: 23/313, Loss: 2.0742859840393066, Running Accuracy: 0.328125, Current Accuracy 0.5\n",
      "Epoch: 0, Batch: 24/313, Loss: 2.072937488555908, Running Accuracy: 0.335, Current Accuracy 0.5\n",
      "Epoch: 0, Batch: 25/313, Loss: 1.9765493869781494, Running Accuracy: 0.34615384615384615, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 26/313, Loss: 2.0161991119384766, Running Accuracy: 0.35648148148148145, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 27/313, Loss: 1.976446509361267, Running Accuracy: 0.3638392857142857, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 28/313, Loss: 2.031067132949829, Running Accuracy: 0.36961206896551724, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 29/313, Loss: 2.0264816284179688, Running Accuracy: 0.375, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 30/313, Loss: 2.0878419876098633, Running Accuracy: 0.37600806451612906, Current Accuracy 0.40625\n",
      "Epoch: 0, Batch: 31/313, Loss: 1.9871121644973755, Running Accuracy: 0.380859375, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 32/313, Loss: 1.9733965396881104, Running Accuracy: 0.38636363636363635, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 33/313, Loss: 1.9991494417190552, Running Accuracy: 0.390625, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 34/313, Loss: 2.003160238265991, Running Accuracy: 0.39553571428571427, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 35/313, Loss: 1.9180760383605957, Running Accuracy: 0.4010416666666667, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 36/313, Loss: 2.124894857406616, Running Accuracy: 0.39949324324324326, Current Accuracy 0.34375\n",
      "Epoch: 0, Batch: 37/313, Loss: 1.9964735507965088, Running Accuracy: 0.40213815789473684, Current Accuracy 0.5\n",
      "Epoch: 0, Batch: 38/313, Loss: 2.0090441703796387, Running Accuracy: 0.40544871794871795, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 39/313, Loss: 1.9199938774108887, Running Accuracy: 0.409375, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 40/313, Loss: 1.8626503944396973, Running Accuracy: 0.41615853658536583, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 41/313, Loss: 1.9937599897384644, Running Accuracy: 0.4181547619047619, Current Accuracy 0.5\n",
      "Epoch: 0, Batch: 42/313, Loss: 2.030355930328369, Running Accuracy: 0.42005813953488375, Current Accuracy 0.5\n",
      "Epoch: 0, Batch: 43/313, Loss: 1.8749094009399414, Running Accuracy: 0.42542613636363635, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 44/313, Loss: 1.8462133407592773, Running Accuracy: 0.43125, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 45/313, Loss: 1.9588394165039062, Running Accuracy: 0.43342391304347827, Current Accuracy 0.53125\n",
      "Epoch: 0, Batch: 46/313, Loss: 1.9382346868515015, Running Accuracy: 0.43617021276595747, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 47/313, Loss: 2.101879596710205, Running Accuracy: 0.435546875, Current Accuracy 0.40625\n",
      "Epoch: 0, Batch: 48/313, Loss: 1.9188406467437744, Running Accuracy: 0.44005102040816324, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 49/313, Loss: 2.0252702236175537, Running Accuracy: 0.4425, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 50/313, Loss: 1.8124805688858032, Running Accuracy: 0.4491421568627451, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 51/313, Loss: 1.9506628513336182, Running Accuracy: 0.4519230769230769, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 52/313, Loss: 1.9254646301269531, Running Accuracy: 0.4545990566037736, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 53/313, Loss: 1.83803391456604, Running Accuracy: 0.4600694444444444, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 54/313, Loss: 1.9302419424057007, Running Accuracy: 0.4630681818181818, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 55/313, Loss: 1.93656587600708, Running Accuracy: 0.46595982142857145, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 56/313, Loss: 1.9104688167572021, Running Accuracy: 0.46984649122807015, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 57/313, Loss: 1.8477668762207031, Running Accuracy: 0.4730603448275862, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 58/313, Loss: 1.8515162467956543, Running Accuracy: 0.4772245762711864, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 59/313, Loss: 1.842465877532959, Running Accuracy: 0.48125, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 60/313, Loss: 1.9084705114364624, Running Accuracy: 0.48411885245901637, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 61/313, Loss: 1.9791275262832642, Running Accuracy: 0.48538306451612906, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 62/313, Loss: 1.8378705978393555, Running Accuracy: 0.4895833333333333, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 63/313, Loss: 1.8417290449142456, Running Accuracy: 0.49267578125, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 64/313, Loss: 1.892790675163269, Running Accuracy: 0.4947115384615385, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 65/313, Loss: 1.8953914642333984, Running Accuracy: 0.4966856060606061, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 66/313, Loss: 1.8287993669509888, Running Accuracy: 0.5, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 67/313, Loss: 1.885068655014038, Running Accuracy: 0.5027573529411765, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 68/313, Loss: 1.9162489175796509, Running Accuracy: 0.5040760869565217, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 69/313, Loss: 2.119295120239258, Running Accuracy: 0.5013392857142858, Current Accuracy 0.3125\n",
      "Epoch: 0, Batch: 70/313, Loss: 1.8715100288391113, Running Accuracy: 0.5026408450704225, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 71/313, Loss: 1.8216160535812378, Running Accuracy: 0.5052083333333334, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 72/313, Loss: 1.8123080730438232, Running Accuracy: 0.5077054794520548, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 73/313, Loss: 1.862585425376892, Running Accuracy: 0.5097128378378378, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 74/313, Loss: 2.0040018558502197, Running Accuracy: 0.50875, Current Accuracy 0.4375\n",
      "Epoch: 0, Batch: 75/313, Loss: 1.8554242849349976, Running Accuracy: 0.5106907894736842, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 76/313, Loss: 1.9406896829605103, Running Accuracy: 0.5113636363636364, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 77/313, Loss: 1.8851604461669922, Running Accuracy: 0.5124198717948718, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 78/313, Loss: 1.9237414598464966, Running Accuracy: 0.5130537974683544, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 79/313, Loss: 1.7290632724761963, Running Accuracy: 0.516015625, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 80/313, Loss: 1.7992688417434692, Running Accuracy: 0.5181327160493827, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 81/313, Loss: 1.8564419746398926, Running Accuracy: 0.5198170731707317, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 82/313, Loss: 1.863750696182251, Running Accuracy: 0.5218373493975904, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 83/313, Loss: 1.8579156398773193, Running Accuracy: 0.5234375, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 84/313, Loss: 1.6897541284561157, Running Accuracy: 0.5275735294117647, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 85/313, Loss: 1.8438469171524048, Running Accuracy: 0.5294331395348837, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 86/313, Loss: 1.866636037826538, Running Accuracy: 0.5298132183908046, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 87/313, Loss: 1.905669927597046, Running Accuracy: 0.5308948863636364, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 88/313, Loss: 1.821912407875061, Running Accuracy: 0.5333567415730337, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 89/313, Loss: 1.7913850545883179, Running Accuracy: 0.5350694444444445, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 90/313, Loss: 1.9099591970443726, Running Accuracy: 0.5357142857142857, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 91/313, Loss: 1.854760766029358, Running Accuracy: 0.5373641304347826, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 92/313, Loss: 1.8971856832504272, Running Accuracy: 0.5376344086021505, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 93/313, Loss: 1.7949265241622925, Running Accuracy: 0.5402260638297872, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 94/313, Loss: 1.6800060272216797, Running Accuracy: 0.5434210526315789, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 95/313, Loss: 1.8712469339370728, Running Accuracy: 0.5442708333333334, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 96/313, Loss: 1.7815004587173462, Running Accuracy: 0.5470360824742269, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 97/313, Loss: 1.866599202156067, Running Accuracy: 0.5481505102040817, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 98/313, Loss: 1.8316757678985596, Running Accuracy: 0.5495580808080808, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 99/313, Loss: 1.9700837135314941, Running Accuracy: 0.5490625, Current Accuracy 0.5\n",
      "Epoch: 0, Batch: 100/313, Loss: 1.7331879138946533, Running Accuracy: 0.5516707920792079, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 101/313, Loss: 1.8239630460739136, Running Accuracy: 0.5530024509803921, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 102/313, Loss: 1.8135228157043457, Running Accuracy: 0.5546116504854369, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 103/313, Loss: 1.8075205087661743, Running Accuracy: 0.5564903846153846, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 104/313, Loss: 1.7082703113555908, Running Accuracy: 0.5592261904761905, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 105/313, Loss: 1.8068362474441528, Running Accuracy: 0.5610259433962265, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 106/313, Loss: 1.8469966650009155, Running Accuracy: 0.5622079439252337, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 107/313, Loss: 1.8557525873184204, Running Accuracy: 0.5633680555555556, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 108/313, Loss: 1.766445279121399, Running Accuracy: 0.5656536697247706, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 109/313, Loss: 1.7339755296707153, Running Accuracy: 0.5676136363636364, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 110/313, Loss: 1.7575429677963257, Running Accuracy: 0.5692567567567568, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 111/313, Loss: 1.8033087253570557, Running Accuracy: 0.5711495535714286, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 112/313, Loss: 1.7304421663284302, Running Accuracy: 0.5732853982300885, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 113/313, Loss: 1.7151342630386353, Running Accuracy: 0.5753837719298246, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 114/313, Loss: 1.7592709064483643, Running Accuracy: 0.5771739130434783, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 115/313, Loss: 1.757298469543457, Running Accuracy: 0.5794719827586207, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 116/313, Loss: 1.8953012228012085, Running Accuracy: 0.5795940170940171, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 117/313, Loss: 1.7006943225860596, Running Accuracy: 0.581302966101695, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 118/313, Loss: 1.8224691152572632, Running Accuracy: 0.5821953781512605, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 119/313, Loss: 1.7389609813690186, Running Accuracy: 0.58359375, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 120/313, Loss: 1.816178560256958, Running Accuracy: 0.5847107438016529, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 121/313, Loss: 1.7599656581878662, Running Accuracy: 0.5860655737704918, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 122/313, Loss: 1.7765169143676758, Running Accuracy: 0.5871443089430894, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 123/313, Loss: 1.7409240007400513, Running Accuracy: 0.5889616935483871, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 124/313, Loss: 1.720093011856079, Running Accuracy: 0.591, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 125/313, Loss: 1.771437644958496, Running Accuracy: 0.5922619047619048, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 126/313, Loss: 1.783972978591919, Running Accuracy: 0.593503937007874, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 127/313, Loss: 1.77619469165802, Running Accuracy: 0.594482421875, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 128/313, Loss: 1.9436758756637573, Running Accuracy: 0.594234496124031, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 129/313, Loss: 1.6984342336654663, Running Accuracy: 0.5959134615384616, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 130/313, Loss: 1.9001264572143555, Running Accuracy: 0.5956583969465649, Current Accuracy 0.5625\n",
      "Epoch: 0, Batch: 131/313, Loss: 1.8028455972671509, Running Accuracy: 0.5963541666666666, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 132/313, Loss: 1.8684780597686768, Running Accuracy: 0.5968045112781954, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 133/313, Loss: 1.7082539796829224, Running Accuracy: 0.5981809701492538, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 134/313, Loss: 1.7646633386611938, Running Accuracy: 0.5990740740740741, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 135/313, Loss: 1.7644855976104736, Running Accuracy: 0.6004136029411765, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 136/313, Loss: 1.6617931127548218, Running Accuracy: 0.6021897810218978, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 137/313, Loss: 1.779919147491455, Running Accuracy: 0.6032608695652174, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 138/313, Loss: 1.8476262092590332, Running Accuracy: 0.6038669064748201, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 139/313, Loss: 1.8005852699279785, Running Accuracy: 0.6049107142857143, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 140/313, Loss: 1.7712918519973755, Running Accuracy: 0.6054964539007093, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 141/313, Loss: 1.6671366691589355, Running Accuracy: 0.6071742957746479, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 142/313, Loss: 1.7822548151016235, Running Accuracy: 0.6083916083916084, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 143/313, Loss: 1.7104564905166626, Running Accuracy: 0.6095920138888888, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 144/313, Loss: 1.6906757354736328, Running Accuracy: 0.6112068965517241, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 145/313, Loss: 1.8840806484222412, Running Accuracy: 0.6113013698630136, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 146/313, Loss: 1.796572208404541, Running Accuracy: 0.6116071428571429, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 147/313, Loss: 1.7031267881393433, Running Accuracy: 0.612964527027027, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 148/313, Loss: 1.8450706005096436, Running Accuracy: 0.6134647651006712, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 149/313, Loss: 1.7401853799819946, Running Accuracy: 0.6145833333333334, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 150/313, Loss: 1.6921974420547485, Running Accuracy: 0.6158940397350994, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 151/313, Loss: 1.7154076099395752, Running Accuracy: 0.6171875, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 152/313, Loss: 1.6822147369384766, Running Accuracy: 0.6186683006535948, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 153/313, Loss: 1.8420710563659668, Running Accuracy: 0.6191152597402597, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 154/313, Loss: 1.7815661430358887, Running Accuracy: 0.619758064516129, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 155/313, Loss: 1.7412159442901611, Running Accuracy: 0.6207932692307693, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 156/313, Loss: 1.7235623598098755, Running Accuracy: 0.6218152866242038, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 157/313, Loss: 1.7855992317199707, Running Accuracy: 0.622626582278481, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 158/313, Loss: 1.7047096490859985, Running Accuracy: 0.6238207547169812, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 159/313, Loss: 1.7090808153152466, Running Accuracy: 0.6251953125, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 160/313, Loss: 1.6965669393539429, Running Accuracy: 0.626358695652174, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 161/313, Loss: 1.6655091047286987, Running Accuracy: 0.6275077160493827, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 162/313, Loss: 1.7509183883666992, Running Accuracy: 0.6284509202453987, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 163/313, Loss: 1.6609796285629272, Running Accuracy: 0.629954268292683, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 164/313, Loss: 1.7820062637329102, Running Accuracy: 0.6306818181818182, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 165/313, Loss: 1.6892037391662598, Running Accuracy: 0.6319653614457831, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 166/313, Loss: 1.797101616859436, Running Accuracy: 0.6322979041916168, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 167/313, Loss: 1.6692421436309814, Running Accuracy: 0.6333705357142857, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 168/313, Loss: 1.7644269466400146, Running Accuracy: 0.6342455621301775, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 169/313, Loss: 1.7113182544708252, Running Accuracy: 0.6351102941176471, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 170/313, Loss: 1.7915761470794678, Running Accuracy: 0.6355994152046783, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 171/313, Loss: 1.6518146991729736, Running Accuracy: 0.6369912790697675, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 172/313, Loss: 1.698493242263794, Running Accuracy: 0.6380057803468208, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 173/313, Loss: 1.7659424543380737, Running Accuracy: 0.6386494252873564, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 174/313, Loss: 1.76750910282135, Running Accuracy: 0.6394642857142857, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 175/313, Loss: 1.724966049194336, Running Accuracy: 0.6400923295454546, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 176/313, Loss: 1.7295851707458496, Running Accuracy: 0.6407132768361582, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 177/313, Loss: 1.86231529712677, Running Accuracy: 0.6404494382022472, Current Accuracy 0.59375\n",
      "Epoch: 0, Batch: 178/313, Loss: 1.8036755323410034, Running Accuracy: 0.6408868715083799, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 179/313, Loss: 1.6556041240692139, Running Accuracy: 0.6420138888888889, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 180/313, Loss: 1.7917693853378296, Running Accuracy: 0.642610497237569, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 181/313, Loss: 1.7347983121871948, Running Accuracy: 0.6433722527472527, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 182/313, Loss: 1.7433321475982666, Running Accuracy: 0.6437841530054644, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 183/313, Loss: 1.642677664756775, Running Accuracy: 0.6450407608695652, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 184/313, Loss: 1.7231475114822388, Running Accuracy: 0.6456081081081081, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 185/313, Loss: 1.779708743095398, Running Accuracy: 0.6461693548387096, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 186/313, Loss: 1.7350506782531738, Running Accuracy: 0.6468917112299465, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 187/313, Loss: 1.5784070491790771, Running Accuracy: 0.6482712765957447, Current Accuracy 0.90625\n",
      "Epoch: 0, Batch: 188/313, Loss: 1.739414930343628, Running Accuracy: 0.6489748677248677, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 189/313, Loss: 1.7755367755889893, Running Accuracy: 0.6493421052631579, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 190/313, Loss: 1.7457928657531738, Running Accuracy: 0.649869109947644, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 191/313, Loss: 1.8183785676956177, Running Accuracy: 0.650390625, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 192/313, Loss: 1.5670098066329956, Running Accuracy: 0.6520401554404145, Current Accuracy 0.96875\n",
      "Epoch: 0, Batch: 193/313, Loss: 1.6569571495056152, Running Accuracy: 0.6531894329896907, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 194/313, Loss: 1.611066222190857, Running Accuracy: 0.6544871794871795, Current Accuracy 0.90625\n",
      "Epoch: 0, Batch: 195/313, Loss: 1.8279048204421997, Running Accuracy: 0.6544961734693877, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 196/313, Loss: 1.6779080629348755, Running Accuracy: 0.6554568527918782, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 197/313, Loss: 1.6416388750076294, Running Accuracy: 0.6565656565656566, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 198/313, Loss: 1.779418706893921, Running Accuracy: 0.657035175879397, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 199/313, Loss: 1.7772698402404785, Running Accuracy: 0.6575, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 200/313, Loss: 1.8212307691574097, Running Accuracy: 0.6576492537313433, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 201/313, Loss: 1.6239733695983887, Running Accuracy: 0.6590346534653465, Current Accuracy 0.9375\n",
      "Epoch: 0, Batch: 202/313, Loss: 1.6440609693527222, Running Accuracy: 0.6602524630541872, Current Accuracy 0.90625\n",
      "Epoch: 0, Batch: 203/313, Loss: 1.8369609117507935, Running Accuracy: 0.6600796568627451, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 204/313, Loss: 1.6998813152313232, Running Accuracy: 0.6608231707317073, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 205/313, Loss: 1.7385693788528442, Running Accuracy: 0.6612560679611651, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 206/313, Loss: 1.7395814657211304, Running Accuracy: 0.6618357487922706, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 207/313, Loss: 1.837220311164856, Running Accuracy: 0.6618088942307693, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 208/313, Loss: 1.710087776184082, Running Accuracy: 0.6622308612440191, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 209/313, Loss: 1.8944553136825562, Running Accuracy: 0.6620535714285715, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 210/313, Loss: 1.728428602218628, Running Accuracy: 0.6627665876777251, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 211/313, Loss: 1.8134673833847046, Running Accuracy: 0.6628832547169812, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 212/313, Loss: 1.6465163230895996, Running Accuracy: 0.6638791079812206, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 213/313, Loss: 1.7763547897338867, Running Accuracy: 0.6641355140186916, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 214/313, Loss: 1.786489486694336, Running Accuracy: 0.6643895348837209, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 215/313, Loss: 1.7246648073196411, Running Accuracy: 0.6650752314814815, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 216/313, Loss: 1.6764578819274902, Running Accuracy: 0.6658986175115207, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 217/313, Loss: 1.7284594774246216, Running Accuracy: 0.6662844036697247, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 218/313, Loss: 1.706968069076538, Running Accuracy: 0.6668093607305936, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 219/313, Loss: 1.6652040481567383, Running Accuracy: 0.6676136363636364, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 220/313, Loss: 1.6631728410720825, Running Accuracy: 0.6684106334841629, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 221/313, Loss: 1.6788054704666138, Running Accuracy: 0.6693412162162162, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 222/313, Loss: 1.7098702192306519, Running Accuracy: 0.6699831838565022, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 223/313, Loss: 1.7713277339935303, Running Accuracy: 0.6702008928571429, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 224/313, Loss: 1.7107234001159668, Running Accuracy: 0.6706944444444445, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 225/313, Loss: 1.5683122873306274, Running Accuracy: 0.671875, Current Accuracy 0.9375\n",
      "Epoch: 0, Batch: 226/313, Loss: 1.7301429510116577, Running Accuracy: 0.6723568281938326, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 227/313, Loss: 1.7533656358718872, Running Accuracy: 0.6725603070175439, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 228/313, Loss: 1.6712934970855713, Running Accuracy: 0.6733078602620087, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 229/313, Loss: 1.6507967710494995, Running Accuracy: 0.6739130434782609, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 230/313, Loss: 1.7272942066192627, Running Accuracy: 0.6747835497835498, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 231/313, Loss: 1.6040526628494263, Running Accuracy: 0.6759159482758621, Current Accuracy 0.9375\n",
      "Epoch: 0, Batch: 232/313, Loss: 1.732557773590088, Running Accuracy: 0.6762339055793991, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 233/313, Loss: 1.6789448261260986, Running Accuracy: 0.6768162393162394, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 234/313, Loss: 1.748152732849121, Running Accuracy: 0.6771276595744681, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 235/313, Loss: 1.7483186721801758, Running Accuracy: 0.6773040254237288, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 236/313, Loss: 1.7263063192367554, Running Accuracy: 0.6777426160337553, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 237/313, Loss: 1.7590526342391968, Running Accuracy: 0.678046218487395, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 238/313, Loss: 1.6948045492172241, Running Accuracy: 0.6786087866108786, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 239/313, Loss: 1.7963967323303223, Running Accuracy: 0.6787760416666667, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 240/313, Loss: 1.6456356048583984, Running Accuracy: 0.6794605809128631, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 241/313, Loss: 1.6499114036560059, Running Accuracy: 0.6801394628099173, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 242/313, Loss: 1.6249949932098389, Running Accuracy: 0.6809413580246914, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 243/313, Loss: 1.6706992387771606, Running Accuracy: 0.6818647540983607, Current Accuracy 0.90625\n",
      "Epoch: 0, Batch: 244/313, Loss: 1.7311656475067139, Running Accuracy: 0.682015306122449, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 245/313, Loss: 1.7918260097503662, Running Accuracy: 0.6820376016260162, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 246/313, Loss: 1.6841100454330444, Running Accuracy: 0.6824392712550608, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 247/313, Loss: 1.7528109550476074, Running Accuracy: 0.6827116935483871, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 248/313, Loss: 1.6489301919937134, Running Accuracy: 0.6834839357429718, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 249/313, Loss: 1.777451515197754, Running Accuracy: 0.683625, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 250/313, Loss: 1.7054167985916138, Running Accuracy: 0.6840139442231076, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 251/313, Loss: 1.7682960033416748, Running Accuracy: 0.6841517857142857, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 252/313, Loss: 1.5933340787887573, Running Accuracy: 0.6849061264822134, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 253/313, Loss: 1.7267464399337769, Running Accuracy: 0.6851624015748031, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 254/313, Loss: 1.753035545349121, Running Accuracy: 0.6854166666666667, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 255/313, Loss: 1.674541711807251, Running Accuracy: 0.6859130859375, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 256/313, Loss: 1.672025203704834, Running Accuracy: 0.6864056420233463, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 257/313, Loss: 1.561355710029602, Running Accuracy: 0.6873788759689923, Current Accuracy 0.9375\n",
      "Epoch: 0, Batch: 258/313, Loss: 1.7089258432388306, Running Accuracy: 0.6878619691119691, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 259/313, Loss: 1.7076750993728638, Running Accuracy: 0.6882211538461539, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 260/313, Loss: 1.7131880521774292, Running Accuracy: 0.6886973180076629, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 261/313, Loss: 1.8045042753219604, Running Accuracy: 0.6884541984732825, Current Accuracy 0.625\n",
      "Epoch: 0, Batch: 262/313, Loss: 1.6170637607574463, Running Accuracy: 0.6891634980988594, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 263/313, Loss: 1.6936835050582886, Running Accuracy: 0.6896306818181818, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 264/313, Loss: 1.6144328117370605, Running Accuracy: 0.6904481132075472, Current Accuracy 0.90625\n",
      "Epoch: 0, Batch: 265/313, Loss: 1.75163996219635, Running Accuracy: 0.690671992481203, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 266/313, Loss: 1.748331069946289, Running Accuracy: 0.6908941947565543, Current Accuracy 0.75\n",
      "Epoch: 0, Batch: 267/313, Loss: 1.7828807830810547, Running Accuracy: 0.6908815298507462, Current Accuracy 0.6875\n",
      "Epoch: 0, Batch: 268/313, Loss: 1.7255256175994873, Running Accuracy: 0.6912174721189591, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 269/313, Loss: 1.8224742412567139, Running Accuracy: 0.6910879629629629, Current Accuracy 0.65625\n",
      "Epoch: 0, Batch: 270/313, Loss: 1.7114620208740234, Running Accuracy: 0.691420664206642, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 271/313, Loss: 1.7912758588790894, Running Accuracy: 0.6915211397058824, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 272/313, Loss: 1.655356764793396, Running Accuracy: 0.6920787545787546, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 273/313, Loss: 1.69874107837677, Running Accuracy: 0.6925182481751825, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 274/313, Loss: 1.6926980018615723, Running Accuracy: 0.6931818181818182, Current Accuracy 0.875\n",
      "Epoch: 0, Batch: 275/313, Loss: 1.7392890453338623, Running Accuracy: 0.6935009057971014, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 276/313, Loss: 1.6576323509216309, Running Accuracy: 0.694043321299639, Current Accuracy 0.84375\n",
      "Epoch: 0, Batch: 277/313, Loss: 1.6847625970840454, Running Accuracy: 0.6943570143884892, Current Accuracy 0.78125\n",
      "Epoch: 0, Batch: 278/313, Loss: 1.5827586650848389, Running Accuracy: 0.6951164874551972, Current Accuracy 0.90625\n",
      "Epoch: 0, Batch: 279/313, Loss: 1.6724759340286255, Running Accuracy: 0.6955357142857143, Current Accuracy 0.8125\n",
      "Epoch: 0, Batch: 280/313, Loss: 1.7538683414459229, Running Accuracy: 0.6956183274021353, Current Accuracy 0.71875\n",
      "Epoch: 0, Batch: 281/313, Loss: 1.9127329587936401, Running Accuracy: 0.6949246453900709, Current Accuracy 0.5\n",
      "Epoch: 0, Test Accuracy: 0.875\n",
      "Epoch: 0, Test Accuracy: 0.8125\n",
      "Epoch: 0, Test Accuracy: 0.8125\n",
      "Epoch: 0, Test Accuracy: 0.8359375\n",
      "Epoch: 0, Test Accuracy: 0.80625\n",
      "Epoch: 0, Test Accuracy: 0.8177083333333334\n",
      "Epoch: 0, Test Accuracy: 0.8214285714285714\n",
      "Epoch: 0, Test Accuracy: 0.83203125\n",
      "Epoch: 0, Test Accuracy: 0.8298611111111112\n",
      "Epoch: 0, Test Accuracy: 0.828125\n",
      "Epoch: 0, Test Accuracy: 0.8238636363636364\n",
      "Epoch: 0, Test Accuracy: 0.8229166666666666\n",
      "Epoch: 0, Test Accuracy: 0.8269230769230769\n",
      "Epoch: 0, Test Accuracy: 0.8303571428571429\n",
      "Epoch: 0, Test Accuracy: 0.8270833333333333\n",
      "Epoch: 0, Test Accuracy: 0.818359375\n",
      "Epoch: 0, Test Accuracy: 0.8180147058823529\n",
      "Epoch: 0, Test Accuracy: 0.8072916666666666\n",
      "Epoch: 0, Test Accuracy: 0.8026315789473685\n",
      "Epoch: 0, Test Accuracy: 0.803125\n",
      "Epoch: 0, Test Accuracy: 0.8020833333333334\n",
      "Epoch: 0, Test Accuracy: 0.8068181818181818\n",
      "Epoch: 0, Test Accuracy: 0.8057065217391305\n",
      "Epoch: 0, Test Accuracy: 0.8072916666666666\n",
      "Epoch: 0, Test Accuracy: 0.80875\n",
      "Epoch: 0, Test Accuracy: 0.8076923076923077\n",
      "Epoch: 0, Test Accuracy: 0.8067129629629629\n",
      "Epoch: 0, Test Accuracy: 0.8080357142857143\n",
      "Epoch: 0, Test Accuracy: 0.8038793103448276\n",
      "Epoch: 0, Test Accuracy: 0.803125\n",
      "Epoch: 0, Test Accuracy: 0.8004032258064516\n",
      "Epoch: 0, Test Accuracy: 0.783203125\n",
      "Epoch: 1, Batch: 0/313, Loss: 1.767236590385437, Running Accuracy: 0.7803030303030303, Current Accuracy 0.6875\n",
      "Epoch: 1, Batch: 1/313, Loss: 1.7983238697052002, Running Accuracy: 0.7775735294117647, Current Accuracy 0.6875\n",
      "Epoch: 1, Batch: 2/313, Loss: 1.703878402709961, Running Accuracy: 0.7785714285714286, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 3/313, Loss: 1.7884719371795654, Running Accuracy: 0.7769097222222222, Current Accuracy 0.71875\n",
      "Epoch: 1, Batch: 4/313, Loss: 1.6462682485580444, Running Accuracy: 0.7787162162162162, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 5/313, Loss: 1.6225924491882324, Running Accuracy: 0.7820723684210527, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 6/313, Loss: 1.6806689500808716, Running Accuracy: 0.782051282051282, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 7/313, Loss: 1.6014939546585083, Running Accuracy: 0.78515625, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 8/313, Loss: 1.6242612600326538, Running Accuracy: 0.7865853658536586, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 9/313, Loss: 1.631311297416687, Running Accuracy: 0.7879464285714286, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 10/313, Loss: 1.7149202823638916, Running Accuracy: 0.7877906976744186, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 11/313, Loss: 1.762404203414917, Running Accuracy: 0.7862215909090909, Current Accuracy 0.71875\n",
      "Epoch: 1, Batch: 12/313, Loss: 1.594041347503662, Running Accuracy: 0.7888888888888889, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 13/313, Loss: 1.6799026727676392, Running Accuracy: 0.7894021739130435, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 14/313, Loss: 1.739966869354248, Running Accuracy: 0.788563829787234, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 15/313, Loss: 1.6403313875198364, Running Accuracy: 0.7903645833333334, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 16/313, Loss: 1.6651420593261719, Running Accuracy: 0.7914540816326531, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 17/313, Loss: 1.6518927812576294, Running Accuracy: 0.791875, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 18/313, Loss: 1.6192916631698608, Running Accuracy: 0.7941176470588235, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 19/313, Loss: 1.6340436935424805, Running Accuracy: 0.7950721153846154, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 20/313, Loss: 1.7473273277282715, Running Accuracy: 0.7942216981132075, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 21/313, Loss: 1.7367066144943237, Running Accuracy: 0.7934027777777778, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 22/313, Loss: 1.7275258302688599, Running Accuracy: 0.7931818181818182, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 23/313, Loss: 1.7168794870376587, Running Accuracy: 0.79296875, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 24/313, Loss: 1.7313966751098633, Running Accuracy: 0.7927631578947368, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 25/313, Loss: 1.7055116891860962, Running Accuracy: 0.7925646551724138, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 26/313, Loss: 1.6383389234542847, Running Accuracy: 0.7934322033898306, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 27/313, Loss: 1.519199013710022, Running Accuracy: 0.796875, Current Accuracy 1.0\n",
      "Epoch: 1, Batch: 28/313, Loss: 1.6795142889022827, Running Accuracy: 0.7966188524590164, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 29/313, Loss: 1.713376522064209, Running Accuracy: 0.7963709677419355, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 30/313, Loss: 1.6352838277816772, Running Accuracy: 0.7971230158730159, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 31/313, Loss: 1.6618561744689941, Running Accuracy: 0.7978515625, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 32/313, Loss: 1.6714617013931274, Running Accuracy: 0.7985576923076924, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 33/313, Loss: 1.7544703483581543, Running Accuracy: 0.7978219696969697, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 34/313, Loss: 1.571590781211853, Running Accuracy: 0.7999067164179104, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 35/313, Loss: 1.5557000637054443, Running Accuracy: 0.8019301470588235, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 36/313, Loss: 1.702803373336792, Running Accuracy: 0.801177536231884, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 37/313, Loss: 1.6549218893051147, Running Accuracy: 0.8017857142857143, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 38/313, Loss: 1.7306220531463623, Running Accuracy: 0.8014964788732394, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 39/313, Loss: 1.7463010549545288, Running Accuracy: 0.80078125, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 40/313, Loss: 1.686472773551941, Running Accuracy: 0.8009417808219178, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 41/313, Loss: 1.6502617597579956, Running Accuracy: 0.8019425675675675, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 42/313, Loss: 1.7045460939407349, Running Accuracy: 0.8016666666666666, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 43/313, Loss: 1.6774418354034424, Running Accuracy: 0.8018092105263158, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 44/313, Loss: 1.6999431848526, Running Accuracy: 0.8015422077922078, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 45/313, Loss: 1.7697651386260986, Running Accuracy: 0.8008814102564102, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 46/313, Loss: 1.6919474601745605, Running Accuracy: 0.8006329113924051, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 47/313, Loss: 1.7168766260147095, Running Accuracy: 0.800390625, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 48/313, Loss: 1.6158039569854736, Running Accuracy: 0.8016975308641975, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 49/313, Loss: 1.6305702924728394, Running Accuracy: 0.8025914634146342, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 50/313, Loss: 1.6745589971542358, Running Accuracy: 0.8023343373493976, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 51/313, Loss: 1.6538180112838745, Running Accuracy: 0.8028273809523809, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 52/313, Loss: 1.6685749292373657, Running Accuracy: 0.8033088235294118, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 53/313, Loss: 1.806140422821045, Running Accuracy: 0.8019622093023255, Current Accuracy 0.6875\n",
      "Epoch: 1, Batch: 54/313, Loss: 1.7198594808578491, Running Accuracy: 0.8017241379310345, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 55/313, Loss: 1.6417882442474365, Running Accuracy: 0.8025568181818182, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 56/313, Loss: 1.5953673124313354, Running Accuracy: 0.8037219101123596, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 57/313, Loss: 1.675759196281433, Running Accuracy: 0.8034722222222223, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 58/313, Loss: 1.7191580533981323, Running Accuracy: 0.8028846153846154, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 59/313, Loss: 1.6242012977600098, Running Accuracy: 0.8036684782608695, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 60/313, Loss: 1.8109115362167358, Running Accuracy: 0.8020833333333334, Current Accuracy 0.65625\n",
      "Epoch: 1, Batch: 61/313, Loss: 1.7401635646820068, Running Accuracy: 0.801529255319149, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 62/313, Loss: 1.6256297826766968, Running Accuracy: 0.8023026315789473, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 63/313, Loss: 1.6653887033462524, Running Accuracy: 0.802734375, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 64/313, Loss: 1.6595288515090942, Running Accuracy: 0.8031572164948454, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 65/313, Loss: 1.639888882637024, Running Accuracy: 0.8038903061224489, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 66/313, Loss: 1.7230101823806763, Running Accuracy: 0.8033459595959596, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 67/313, Loss: 1.6123545169830322, Running Accuracy: 0.8040625, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 68/313, Loss: 1.651244044303894, Running Accuracy: 0.8041460396039604, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 69/313, Loss: 1.703080415725708, Running Accuracy: 0.803921568627451, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 70/313, Loss: 1.7081788778305054, Running Accuracy: 0.804004854368932, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 71/313, Loss: 1.6861766576766968, Running Accuracy: 0.8040865384615384, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 72/313, Loss: 1.7438503503799438, Running Accuracy: 0.8035714285714286, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 73/313, Loss: 1.6966133117675781, Running Accuracy: 0.8036556603773585, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 74/313, Loss: 1.6393358707427979, Running Accuracy: 0.804322429906542, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 75/313, Loss: 1.6338163614273071, Running Accuracy: 0.8049768518518519, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 76/313, Loss: 1.6490421295166016, Running Accuracy: 0.8053325688073395, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 77/313, Loss: 1.712876796722412, Running Accuracy: 0.8051136363636363, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 78/313, Loss: 1.5917021036148071, Running Accuracy: 0.8060247747747747, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 79/313, Loss: 1.5897454023361206, Running Accuracy: 0.8069196428571429, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 80/313, Loss: 1.6546003818511963, Running Accuracy: 0.807245575221239, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 81/313, Loss: 1.6340006589889526, Running Accuracy: 0.8078399122807017, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 82/313, Loss: 1.7151827812194824, Running Accuracy: 0.8073369565217391, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 83/313, Loss: 1.70358407497406, Running Accuracy: 0.8073814655172413, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 84/313, Loss: 1.6419271230697632, Running Accuracy: 0.8082264957264957, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 85/313, Loss: 1.6031032800674438, Running Accuracy: 0.8090572033898306, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 86/313, Loss: 1.601455569267273, Running Accuracy: 0.8096113445378151, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 87/313, Loss: 1.7127662897109985, Running Accuracy: 0.809375, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 88/313, Loss: 1.6777757406234741, Running Accuracy: 0.809400826446281, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 89/313, Loss: 1.5861412286758423, Running Accuracy: 0.8101946721311475, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 90/313, Loss: 1.6396515369415283, Running Accuracy: 0.8104674796747967, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 91/313, Loss: 1.594053030014038, Running Accuracy: 0.8112399193548387, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 92/313, Loss: 1.6408051252365112, Running Accuracy: 0.8115, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 93/313, Loss: 1.6156811714172363, Running Accuracy: 0.8117559523809523, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 94/313, Loss: 1.5794323682785034, Running Accuracy: 0.812746062992126, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 95/313, Loss: 1.637465238571167, Running Accuracy: 0.81298828125, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 96/313, Loss: 1.6336075067520142, Running Accuracy: 0.813468992248062, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 97/313, Loss: 1.5890638828277588, Running Accuracy: 0.8141826923076924, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 98/313, Loss: 1.59180748462677, Running Accuracy: 0.8148854961832062, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 99/313, Loss: 1.605176329612732, Running Accuracy: 0.8153409090909091, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 100/313, Loss: 1.6153005361557007, Running Accuracy: 0.8160244360902256, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 101/313, Loss: 1.5943392515182495, Running Accuracy: 0.8166977611940298, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 102/313, Loss: 1.6720651388168335, Running Accuracy: 0.8168981481481481, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 103/313, Loss: 1.6191946268081665, Running Accuracy: 0.8173253676470589, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 104/313, Loss: 1.6270047426223755, Running Accuracy: 0.8179744525547445, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 105/313, Loss: 1.639223337173462, Running Accuracy: 0.8183876811594203, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 106/313, Loss: 1.653676986694336, Running Accuracy: 0.8187949640287769, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 107/313, Loss: 1.6893694400787354, Running Accuracy: 0.81875, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 108/313, Loss: 1.630749225616455, Running Accuracy: 0.8193705673758865, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 109/313, Loss: 1.6265970468521118, Running Accuracy: 0.8199823943661971, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 110/313, Loss: 1.5975134372711182, Running Accuracy: 0.8210227272727273, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 111/313, Loss: 1.5628780126571655, Running Accuracy: 0.8218315972222222, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 112/313, Loss: 1.56551194190979, Running Accuracy: 0.8228448275862069, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 113/313, Loss: 1.6871665716171265, Running Accuracy: 0.8225599315068494, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 114/313, Loss: 1.6143096685409546, Running Accuracy: 0.8231292517006803, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 115/313, Loss: 1.6961122751235962, Running Accuracy: 0.8230574324324325, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 116/313, Loss: 1.5921359062194824, Running Accuracy: 0.8238255033557047, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 117/313, Loss: 1.6391819715499878, Running Accuracy: 0.8241666666666667, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 118/313, Loss: 1.5315978527069092, Running Accuracy: 0.8253311258278145, Current Accuracy 1.0\n",
      "Epoch: 1, Batch: 119/313, Loss: 1.6520272493362427, Running Accuracy: 0.825452302631579, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 120/313, Loss: 1.6827008724212646, Running Accuracy: 0.8249591503267973, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 121/313, Loss: 1.5750524997711182, Running Accuracy: 0.8258928571428571, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 122/313, Loss: 1.6532319784164429, Running Accuracy: 0.8262096774193548, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 123/313, Loss: 1.694250464439392, Running Accuracy: 0.8261217948717948, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 124/313, Loss: 1.6049354076385498, Running Accuracy: 0.8268312101910829, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 125/313, Loss: 1.5990046262741089, Running Accuracy: 0.8273338607594937, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 126/313, Loss: 1.620431661605835, Running Accuracy: 0.8276336477987422, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 127/313, Loss: 1.7191121578216553, Running Accuracy: 0.8271484375, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 128/313, Loss: 1.6461576223373413, Running Accuracy: 0.827251552795031, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 129/313, Loss: 1.6086161136627197, Running Accuracy: 0.8279320987654321, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 130/313, Loss: 1.5846912860870361, Running Accuracy: 0.8284125766871165, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 131/313, Loss: 1.5939297676086426, Running Accuracy: 0.8288871951219512, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 132/313, Loss: 1.602725863456726, Running Accuracy: 0.8289772727272727, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 133/313, Loss: 1.6235524415969849, Running Accuracy: 0.8292545180722891, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 134/313, Loss: 1.6195133924484253, Running Accuracy: 0.8295284431137725, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 135/313, Loss: 1.6382521390914917, Running Accuracy: 0.8296130952380952, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 136/313, Loss: 1.672857642173767, Running Accuracy: 0.8295118343195266, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 137/313, Loss: 1.628693699836731, Running Accuracy: 0.8299632352941176, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 138/313, Loss: 1.6166805028915405, Running Accuracy: 0.8302266081871345, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 139/313, Loss: 1.5840040445327759, Running Accuracy: 0.8306686046511628, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 140/313, Loss: 1.580521821975708, Running Accuracy: 0.8309248554913294, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 141/313, Loss: 1.5572396516799927, Running Accuracy: 0.8315373563218391, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 142/313, Loss: 1.7256402969360352, Running Accuracy: 0.83125, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 143/313, Loss: 1.5566738843917847, Running Accuracy: 0.8318536931818182, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 144/313, Loss: 1.6418917179107666, Running Accuracy: 0.8320974576271186, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 145/313, Loss: 1.577972650527954, Running Accuracy: 0.8328651685393258, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 146/313, Loss: 1.6179757118225098, Running Accuracy: 0.8332751396648045, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 147/313, Loss: 1.6476805210113525, Running Accuracy: 0.8335069444444444, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 148/313, Loss: 1.6035162210464478, Running Accuracy: 0.8339088397790055, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 149/313, Loss: 1.5945698022842407, Running Accuracy: 0.8343063186813187, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 150/313, Loss: 1.6352413892745972, Running Accuracy: 0.8345286885245902, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 151/313, Loss: 1.631858229637146, Running Accuracy: 0.834578804347826, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 152/313, Loss: 1.5759278535842896, Running Accuracy: 0.8353040540540541, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 153/313, Loss: 1.6539161205291748, Running Accuracy: 0.8355174731182796, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 154/313, Loss: 1.5538479089736938, Running Accuracy: 0.8362299465240641, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 155/313, Loss: 1.5515177249908447, Running Accuracy: 0.8369348404255319, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 156/313, Loss: 1.6193972826004028, Running Accuracy: 0.8371362433862434, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 157/313, Loss: 1.588823676109314, Running Accuracy: 0.8375, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 158/313, Loss: 1.5881537199020386, Running Accuracy: 0.8378599476439791, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 159/313, Loss: 1.6113945245742798, Running Accuracy: 0.8380533854166666, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 160/313, Loss: 1.7633930444717407, Running Accuracy: 0.8374352331606217, Current Accuracy 0.71875\n",
      "Epoch: 1, Batch: 161/313, Loss: 1.620548963546753, Running Accuracy: 0.8376288659793815, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 162/313, Loss: 1.668143391609192, Running Accuracy: 0.8375, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 163/313, Loss: 1.6394927501678467, Running Accuracy: 0.8378507653061225, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 164/313, Loss: 1.571427583694458, Running Accuracy: 0.8380393401015228, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 165/313, Loss: 1.5950942039489746, Running Accuracy: 0.8383838383838383, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 166/313, Loss: 1.610798954963684, Running Accuracy: 0.8384108040201005, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 167/313, Loss: 1.6589393615722656, Running Accuracy: 0.8384375, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 168/313, Loss: 1.5754872560501099, Running Accuracy: 0.8389303482587065, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 169/313, Loss: 1.6010991334915161, Running Accuracy: 0.8392636138613861, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 170/313, Loss: 1.6232722997665405, Running Accuracy: 0.8395935960591133, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 171/313, Loss: 1.6191432476043701, Running Accuracy: 0.8397671568627451, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 172/313, Loss: 1.602902889251709, Running Accuracy: 0.8400914634146341, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 173/313, Loss: 1.5663337707519531, Running Accuracy: 0.8404126213592233, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 174/313, Loss: 1.5236191749572754, Running Accuracy: 0.8410326086956522, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 175/313, Loss: 1.6201001405715942, Running Accuracy: 0.8413461538461539, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 176/313, Loss: 1.6186156272888184, Running Accuracy: 0.8413576555023924, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 177/313, Loss: 1.5856101512908936, Running Accuracy: 0.8418154761904761, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 178/313, Loss: 1.631239414215088, Running Accuracy: 0.8419727488151659, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 179/313, Loss: 1.6538796424865723, Running Accuracy: 0.8419811320754716, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 180/313, Loss: 1.7326781749725342, Running Accuracy: 0.8415492957746479, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 181/313, Loss: 1.5668845176696777, Running Accuracy: 0.8419976635514018, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 182/313, Loss: 1.5920822620391846, Running Accuracy: 0.842296511627907, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 183/313, Loss: 1.6415902376174927, Running Accuracy: 0.8421585648148148, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 184/313, Loss: 1.5687017440795898, Running Accuracy: 0.8424539170506913, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 185/313, Loss: 1.5051360130310059, Running Accuracy: 0.8430332568807339, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 186/313, Loss: 1.599115252494812, Running Accuracy: 0.8431792237442922, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 187/313, Loss: 1.6141573190689087, Running Accuracy: 0.8433238636363637, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 188/313, Loss: 1.6817244291305542, Running Accuracy: 0.8434671945701357, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 189/313, Loss: 1.622055172920227, Running Accuracy: 0.8436092342342343, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 190/313, Loss: 1.6447768211364746, Running Accuracy: 0.843609865470852, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 191/313, Loss: 1.5746986865997314, Running Accuracy: 0.8438895089285714, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 192/313, Loss: 1.5773673057556152, Running Accuracy: 0.8441666666666666, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 193/313, Loss: 1.5878270864486694, Running Accuracy: 0.8445796460176991, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 194/313, Loss: 1.6933302879333496, Running Accuracy: 0.8443006607929515, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 195/313, Loss: 1.590988039970398, Running Accuracy: 0.8444353070175439, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 196/313, Loss: 1.622216820716858, Running Accuracy: 0.8445687772925764, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 197/313, Loss: 1.580426812171936, Running Accuracy: 0.8449728260869566, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 198/313, Loss: 1.6865205764770508, Running Accuracy: 0.8446969696969697, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 199/313, Loss: 1.6767960786819458, Running Accuracy: 0.8445581896551724, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 200/313, Loss: 1.6739917993545532, Running Accuracy: 0.8444206008583691, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 201/313, Loss: 1.6521108150482178, Running Accuracy: 0.844551282051282, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 202/313, Loss: 1.6377986669540405, Running Accuracy: 0.8448138297872341, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 203/313, Loss: 1.6113784313201904, Running Accuracy: 0.8450741525423728, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 204/313, Loss: 1.519509196281433, Running Accuracy: 0.8455959915611815, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 205/313, Loss: 1.5772680044174194, Running Accuracy: 0.8458508403361344, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 206/313, Loss: 1.6046059131622314, Running Accuracy: 0.8461035564853556, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 207/313, Loss: 1.631212592124939, Running Accuracy: 0.8463541666666666, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 208/313, Loss: 1.5160021781921387, Running Accuracy: 0.8469917012448133, Current Accuracy 1.0\n",
      "Epoch: 1, Batch: 209/313, Loss: 1.6041089296340942, Running Accuracy: 0.8471074380165289, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 210/313, Loss: 1.652652382850647, Running Accuracy: 0.8469650205761317, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 211/313, Loss: 1.610253930091858, Running Accuracy: 0.8470799180327869, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 212/313, Loss: 1.6376789808273315, Running Accuracy: 0.8470663265306122, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 213/313, Loss: 1.5859038829803467, Running Accuracy: 0.8474339430894309, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 214/313, Loss: 1.627145767211914, Running Accuracy: 0.8476720647773279, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 215/313, Loss: 1.5873380899429321, Running Accuracy: 0.8480342741935484, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 216/313, Loss: 1.6562786102294922, Running Accuracy: 0.8480170682730924, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 217/313, Loss: 1.5671061277389526, Running Accuracy: 0.848375, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 218/313, Loss: 1.6241525411605835, Running Accuracy: 0.8483565737051793, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 219/313, Loss: 1.6471940279006958, Running Accuracy: 0.8482142857142857, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 220/313, Loss: 1.6366769075393677, Running Accuracy: 0.8483201581027668, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 221/313, Loss: 1.580648422241211, Running Accuracy: 0.8485482283464567, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 222/313, Loss: 1.654681921005249, Running Accuracy: 0.848406862745098, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 223/313, Loss: 1.6080975532531738, Running Accuracy: 0.8487548828125, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 224/313, Loss: 1.6009527444839478, Running Accuracy: 0.8488570038910506, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 225/313, Loss: 1.6474685668945312, Running Accuracy: 0.8488372093023255, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 226/313, Loss: 1.6150943040847778, Running Accuracy: 0.8490588803088803, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 227/313, Loss: 1.7194764614105225, Running Accuracy: 0.8485576923076923, Current Accuracy 0.71875\n",
      "Epoch: 1, Batch: 228/313, Loss: 1.5755523443222046, Running Accuracy: 0.8487787356321839, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 229/313, Loss: 1.5719237327575684, Running Accuracy: 0.8491173664122137, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 230/313, Loss: 1.6014291048049927, Running Accuracy: 0.8494534220532319, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 231/313, Loss: 1.5731258392333984, Running Accuracy: 0.8495501893939394, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 232/313, Loss: 1.6529425382614136, Running Accuracy: 0.8496462264150944, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 233/313, Loss: 1.567435383796692, Running Accuracy: 0.8499765037593985, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 234/313, Loss: 1.5532575845718384, Running Accuracy: 0.8503043071161048, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 235/313, Loss: 1.6643683910369873, Running Accuracy: 0.8503964552238806, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 236/313, Loss: 1.6412986516952515, Running Accuracy: 0.8503717472118959, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 237/313, Loss: 1.6132601499557495, Running Accuracy: 0.8505787037037037, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 238/313, Loss: 1.666174054145813, Running Accuracy: 0.8505535055350554, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 239/313, Loss: 1.5443055629730225, Running Accuracy: 0.8508731617647058, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 240/313, Loss: 1.65945303440094, Running Accuracy: 0.8509615384615384, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 241/313, Loss: 1.746764898300171, Running Accuracy: 0.8505930656934306, Current Accuracy 0.75\n",
      "Epoch: 1, Batch: 242/313, Loss: 1.5781865119934082, Running Accuracy: 0.8506818181818182, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 243/313, Loss: 1.6210817098617554, Running Accuracy: 0.8508831521739131, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 244/313, Loss: 1.5831800699234009, Running Accuracy: 0.8510830324909747, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 245/313, Loss: 1.584657073020935, Running Accuracy: 0.8513938848920863, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 246/313, Loss: 1.6835664510726929, Running Accuracy: 0.8512544802867383, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 247/313, Loss: 1.6472980976104736, Running Accuracy: 0.8511160714285714, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 248/313, Loss: 1.5151050090789795, Running Accuracy: 0.8516459074733096, Current Accuracy 1.0\n",
      "Epoch: 1, Batch: 249/313, Loss: 1.5756922960281372, Running Accuracy: 0.8519503546099291, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 250/313, Loss: 1.6860712766647339, Running Accuracy: 0.8518109540636042, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 251/313, Loss: 1.6921921968460083, Running Accuracy: 0.8516725352112676, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 252/313, Loss: 1.6296330690383911, Running Accuracy: 0.8516447368421053, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 253/313, Loss: 1.6801481246948242, Running Accuracy: 0.8513986013986014, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 254/313, Loss: 1.7058367729187012, Running Accuracy: 0.8512630662020906, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 255/313, Loss: 1.560437798500061, Running Accuracy: 0.8514539930555556, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 256/313, Loss: 1.6230388879776, Running Accuracy: 0.851643598615917, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 257/313, Loss: 1.617412805557251, Running Accuracy: 0.8518318965517241, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 258/313, Loss: 1.572657585144043, Running Accuracy: 0.8520189003436426, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 259/313, Loss: 1.5598604679107666, Running Accuracy: 0.8524186643835616, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 260/313, Loss: 1.5887539386749268, Running Accuracy: 0.8526023890784983, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 261/313, Loss: 1.7004172801971436, Running Accuracy: 0.8523596938775511, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 262/313, Loss: 1.595653772354126, Running Accuracy: 0.8526483050847458, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 263/313, Loss: 1.5150433778762817, Running Accuracy: 0.8531461148648649, Current Accuracy 1.0\n",
      "Epoch: 1, Batch: 264/313, Loss: 1.6378757953643799, Running Accuracy: 0.8531144781144782, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 265/313, Loss: 1.58814537525177, Running Accuracy: 0.8533976510067114, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 266/313, Loss: 1.654052972793579, Running Accuracy: 0.8532608695652174, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 267/313, Loss: 1.5847383737564087, Running Accuracy: 0.8535416666666666, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 268/313, Loss: 1.664400577545166, Running Accuracy: 0.8533014950166113, Current Accuracy 0.78125\n",
      "Epoch: 1, Batch: 269/313, Loss: 1.5647037029266357, Running Accuracy: 0.8535802980132451, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 270/313, Loss: 1.645255208015442, Running Accuracy: 0.8534447194719472, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 271/313, Loss: 1.5666366815567017, Running Accuracy: 0.8537212171052632, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 272/313, Loss: 1.5887633562088013, Running Accuracy: 0.8537909836065574, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 273/313, Loss: 1.6625577211380005, Running Accuracy: 0.8537581699346405, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 274/313, Loss: 1.5817660093307495, Running Accuracy: 0.8539291530944625, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 275/313, Loss: 1.5894007682800293, Running Accuracy: 0.854200487012987, Current Accuracy 0.9375\n",
      "Epoch: 1, Batch: 276/313, Loss: 1.6447949409484863, Running Accuracy: 0.8540655339805825, Current Accuracy 0.8125\n",
      "Epoch: 1, Batch: 277/313, Loss: 1.521329641342163, Running Accuracy: 0.8544354838709678, Current Accuracy 0.96875\n",
      "Epoch: 1, Batch: 278/313, Loss: 1.580073595046997, Running Accuracy: 0.8546020900321544, Current Accuracy 0.90625\n",
      "Epoch: 1, Batch: 279/313, Loss: 1.6007521152496338, Running Accuracy: 0.8545673076923077, Current Accuracy 0.84375\n",
      "Epoch: 1, Batch: 280/313, Loss: 1.6386010646820068, Running Accuracy: 0.854632587859425, Current Accuracy 0.875\n",
      "Epoch: 1, Batch: 281/313, Loss: 1.549787163734436, Running Accuracy: 0.8550955414012739, Current Accuracy 1.0\n",
      "Epoch: 1, Test Accuracy: 0.90625\n",
      "Epoch: 1, Test Accuracy: 0.90625\n",
      "Epoch: 1, Test Accuracy: 0.90625\n",
      "Epoch: 1, Test Accuracy: 0.9140625\n",
      "Epoch: 1, Test Accuracy: 0.9\n",
      "Epoch: 1, Test Accuracy: 0.90625\n",
      "Epoch: 1, Test Accuracy: 0.8973214285714286\n",
      "Epoch: 1, Test Accuracy: 0.90625\n",
      "Epoch: 1, Test Accuracy: 0.8958333333333334\n",
      "Epoch: 1, Test Accuracy: 0.884375\n",
      "Epoch: 1, Test Accuracy: 0.8863636363636364\n",
      "Epoch: 1, Test Accuracy: 0.8880208333333334\n",
      "Epoch: 1, Test Accuracy: 0.8894230769230769\n",
      "Epoch: 1, Test Accuracy: 0.8861607142857143\n",
      "Epoch: 1, Test Accuracy: 0.8833333333333333\n",
      "Epoch: 1, Test Accuracy: 0.880859375\n",
      "Epoch: 1, Test Accuracy: 0.8841911764705882\n",
      "Epoch: 1, Test Accuracy: 0.8819444444444444\n",
      "Epoch: 1, Test Accuracy: 0.8832236842105263\n",
      "Epoch: 1, Test Accuracy: 0.8796875\n",
      "Epoch: 1, Test Accuracy: 0.8809523809523809\n",
      "Epoch: 1, Test Accuracy: 0.8806818181818182\n",
      "Epoch: 1, Test Accuracy: 0.8804347826086957\n",
      "Epoch: 1, Test Accuracy: 0.8815104166666666\n",
      "Epoch: 1, Test Accuracy: 0.885\n",
      "Epoch: 1, Test Accuracy: 0.8882211538461539\n",
      "Epoch: 1, Test Accuracy: 0.8865740740740741\n",
      "Epoch: 1, Test Accuracy: 0.8883928571428571\n",
      "Epoch: 1, Test Accuracy: 0.8879310344827587\n",
      "Epoch: 1, Test Accuracy: 0.8864583333333333\n",
      "Epoch: 1, Test Accuracy: 0.8860887096774194\n",
      "Epoch: 1, Test Accuracy: 0.8857421875\n",
      "Epoch: 2, Batch: 0/313, Loss: 1.5691813230514526, Running Accuracy: 0.8873106060606061, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 1/313, Loss: 1.5999903678894043, Running Accuracy: 0.8878676470588235, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 2/313, Loss: 1.5542044639587402, Running Accuracy: 0.8892857142857142, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 3/313, Loss: 1.5529892444610596, Running Accuracy: 0.890625, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 4/313, Loss: 1.5867481231689453, Running Accuracy: 0.8910472972972973, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 5/313, Loss: 1.5774898529052734, Running Accuracy: 0.8914473684210527, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 6/313, Loss: 1.5724295377731323, Running Accuracy: 0.8926282051282052, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 7/313, Loss: 1.5468616485595703, Running Accuracy: 0.8953125, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 8/313, Loss: 1.5803959369659424, Running Accuracy: 0.8963414634146342, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 9/313, Loss: 1.5987497568130493, Running Accuracy: 0.8965773809523809, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 10/313, Loss: 1.6337116956710815, Running Accuracy: 0.8960755813953488, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 11/313, Loss: 1.6393814086914062, Running Accuracy: 0.8948863636363636, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 12/313, Loss: 1.5925034284591675, Running Accuracy: 0.8951388888888889, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 13/313, Loss: 1.6604831218719482, Running Accuracy: 0.8940217391304348, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 14/313, Loss: 1.5295486450195312, Running Accuracy: 0.8956117021276596, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 15/313, Loss: 1.6022264957427979, Running Accuracy: 0.8958333333333334, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 16/313, Loss: 1.6295371055603027, Running Accuracy: 0.8954081632653061, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 17/313, Loss: 1.600030779838562, Running Accuracy: 0.895625, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 18/313, Loss: 1.5573880672454834, Running Accuracy: 0.8970588235294118, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 19/313, Loss: 1.5256346464157104, Running Accuracy: 0.8984375, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 20/313, Loss: 1.483447790145874, Running Accuracy: 0.9003537735849056, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 21/313, Loss: 1.6482406854629517, Running Accuracy: 0.8987268518518519, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 22/313, Loss: 1.6360399723052979, Running Accuracy: 0.8982954545454546, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 23/313, Loss: 1.6502410173416138, Running Accuracy: 0.8967633928571429, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 24/313, Loss: 1.634101152420044, Running Accuracy: 0.8958333333333334, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 25/313, Loss: 1.5794695615768433, Running Accuracy: 0.896551724137931, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 26/313, Loss: 1.6112682819366455, Running Accuracy: 0.8961864406779662, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 27/313, Loss: 1.5506528615951538, Running Accuracy: 0.896875, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 28/313, Loss: 1.5999809503555298, Running Accuracy: 0.8970286885245902, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 29/313, Loss: 1.6100659370422363, Running Accuracy: 0.8966733870967742, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 30/313, Loss: 1.6022908687591553, Running Accuracy: 0.8968253968253969, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 31/313, Loss: 1.5436549186706543, Running Accuracy: 0.8974609375, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 32/313, Loss: 1.5650813579559326, Running Accuracy: 0.8975961538461539, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 33/313, Loss: 1.4875476360321045, Running Accuracy: 0.8991477272727273, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 34/313, Loss: 1.6428120136260986, Running Accuracy: 0.898320895522388, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 35/313, Loss: 1.6101118326187134, Running Accuracy: 0.8979779411764706, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 36/313, Loss: 1.5080275535583496, Running Accuracy: 0.8990036231884058, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 37/313, Loss: 1.508449912071228, Running Accuracy: 0.9004464285714285, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 38/313, Loss: 1.5887309312820435, Running Accuracy: 0.9005281690140845, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 39/313, Loss: 1.574979305267334, Running Accuracy: 0.9014756944444444, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 40/313, Loss: 1.583902359008789, Running Accuracy: 0.9011130136986302, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 41/313, Loss: 1.5868932008743286, Running Accuracy: 0.9011824324324325, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 42/313, Loss: 1.6126855611801147, Running Accuracy: 0.9, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 43/313, Loss: 1.5609817504882812, Running Accuracy: 0.9009046052631579, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 44/313, Loss: 1.5594881772994995, Running Accuracy: 0.900974025974026, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 45/313, Loss: 1.5243277549743652, Running Accuracy: 0.9018429487179487, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 46/313, Loss: 1.6192148923873901, Running Accuracy: 0.9011075949367089, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 47/313, Loss: 1.5802106857299805, Running Accuracy: 0.9015625, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 48/313, Loss: 1.5525004863739014, Running Accuracy: 0.9020061728395061, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 49/313, Loss: 1.5544737577438354, Running Accuracy: 0.9028201219512195, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 50/313, Loss: 1.5438439846038818, Running Accuracy: 0.9036144578313253, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 51/313, Loss: 1.5356390476226807, Running Accuracy: 0.9040178571428571, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 52/313, Loss: 1.593245506286621, Running Accuracy: 0.9036764705882353, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 53/313, Loss: 1.5564578771591187, Running Accuracy: 0.9040697674418605, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 54/313, Loss: 1.544750452041626, Running Accuracy: 0.9044540229885057, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 55/313, Loss: 1.6115179061889648, Running Accuracy: 0.9041193181818182, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 56/313, Loss: 1.555342435836792, Running Accuracy: 0.9044943820224719, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 57/313, Loss: 1.6387213468551636, Running Accuracy: 0.9041666666666667, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 58/313, Loss: 1.6840108633041382, Running Accuracy: 0.9031593406593407, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 59/313, Loss: 1.5705429315567017, Running Accuracy: 0.9035326086956522, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 60/313, Loss: 1.6250035762786865, Running Accuracy: 0.9028897849462365, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 61/313, Loss: 1.6226606369018555, Running Accuracy: 0.9022606382978723, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 62/313, Loss: 1.6100713014602661, Running Accuracy: 0.9023026315789474, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 63/313, Loss: 1.594655990600586, Running Accuracy: 0.9020182291666666, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 64/313, Loss: 1.5366629362106323, Running Accuracy: 0.9027061855670103, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 65/313, Loss: 1.5391743183135986, Running Accuracy: 0.9033801020408163, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 66/313, Loss: 1.568666934967041, Running Accuracy: 0.9034090909090909, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 67/313, Loss: 1.57878839969635, Running Accuracy: 0.9034375, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 68/313, Loss: 1.5761560201644897, Running Accuracy: 0.9034653465346535, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 69/313, Loss: 1.569993495941162, Running Accuracy: 0.9037990196078431, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 70/313, Loss: 1.5494272708892822, Running Accuracy: 0.904126213592233, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 71/313, Loss: 1.5803128480911255, Running Accuracy: 0.9041466346153846, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 72/313, Loss: 1.561218023300171, Running Accuracy: 0.9044642857142857, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 73/313, Loss: 1.612803339958191, Running Accuracy: 0.9041863207547169, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 74/313, Loss: 1.4962862730026245, Running Accuracy: 0.9050817757009346, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 75/313, Loss: 1.5525351762771606, Running Accuracy: 0.9053819444444444, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 76/313, Loss: 1.6416128873825073, Running Accuracy: 0.9051032110091743, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 77/313, Loss: 1.5487321615219116, Running Accuracy: 0.9053977272727273, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 78/313, Loss: 1.6229554414749146, Running Accuracy: 0.9045608108108109, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 79/313, Loss: 1.534239411354065, Running Accuracy: 0.9048549107142857, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 80/313, Loss: 1.625741720199585, Running Accuracy: 0.9045907079646017, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 81/313, Loss: 1.552049160003662, Running Accuracy: 0.9048793859649122, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 82/313, Loss: 1.627474069595337, Running Accuracy: 0.9046195652173913, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 83/313, Loss: 1.578992486000061, Running Accuracy: 0.904364224137931, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 84/313, Loss: 1.5863271951675415, Running Accuracy: 0.9041132478632479, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 85/313, Loss: 1.5979965925216675, Running Accuracy: 0.9036016949152542, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 86/313, Loss: 1.5063656568527222, Running Accuracy: 0.9041491596638656, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 87/313, Loss: 1.556756615638733, Running Accuracy: 0.9046875, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 88/313, Loss: 1.5559309720993042, Running Accuracy: 0.9049586776859504, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 89/313, Loss: 1.5343788862228394, Running Accuracy: 0.9054815573770492, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 90/313, Loss: 1.6349416971206665, Running Accuracy: 0.904979674796748, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 91/313, Loss: 1.5138152837753296, Running Accuracy: 0.9054939516129032, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 92/313, Loss: 1.5505859851837158, Running Accuracy: 0.906, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 93/313, Loss: 1.6159673929214478, Running Accuracy: 0.9060019841269841, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 94/313, Loss: 1.5532469749450684, Running Accuracy: 0.90625, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 95/313, Loss: 1.5446594953536987, Running Accuracy: 0.90673828125, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 96/313, Loss: 1.5589648485183716, Running Accuracy: 0.907218992248062, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 97/313, Loss: 1.594021201133728, Running Accuracy: 0.9067307692307692, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 98/313, Loss: 1.5646395683288574, Running Accuracy: 0.9069656488549618, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 99/313, Loss: 1.5848498344421387, Running Accuracy: 0.9071969696969697, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 100/313, Loss: 1.566672444343567, Running Accuracy: 0.9074248120300752, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 101/313, Loss: 1.5546280145645142, Running Accuracy: 0.9078824626865671, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 102/313, Loss: 1.5879746675491333, Running Accuracy: 0.9076388888888889, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 103/313, Loss: 1.5287835597991943, Running Accuracy: 0.9080882352941176, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 104/313, Loss: 1.5602368116378784, Running Accuracy: 0.9080748175182481, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 105/313, Loss: 1.6970196962356567, Running Accuracy: 0.9067028985507246, Current Accuracy 0.71875\n",
      "Epoch: 2, Batch: 106/313, Loss: 1.5660743713378906, Running Accuracy: 0.9069244604316546, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 107/313, Loss: 1.607657551765442, Running Accuracy: 0.9066964285714286, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 108/313, Loss: 1.5252885818481445, Running Accuracy: 0.9073581560283688, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 109/313, Loss: 1.5464296340942383, Running Accuracy: 0.9075704225352113, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 110/313, Loss: 1.5584608316421509, Running Accuracy: 0.9079982517482518, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 111/313, Loss: 1.615739345550537, Running Accuracy: 0.9077690972222222, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 112/313, Loss: 1.777461290359497, Running Accuracy: 0.9064655172413794, Current Accuracy 0.71875\n",
      "Epoch: 2, Batch: 113/313, Loss: 1.5864918231964111, Running Accuracy: 0.9064640410958904, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 114/313, Loss: 1.530571699142456, Running Accuracy: 0.9068877551020408, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 115/313, Loss: 1.632196068763733, Running Accuracy: 0.9064611486486487, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 116/313, Loss: 1.5780177116394043, Running Accuracy: 0.90625, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 117/313, Loss: 1.6155116558074951, Running Accuracy: 0.9060416666666666, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 118/313, Loss: 1.5551689863204956, Running Accuracy: 0.90625, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 119/313, Loss: 1.606272578239441, Running Accuracy: 0.9058388157894737, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 120/313, Loss: 1.5333999395370483, Running Accuracy: 0.9060457516339869, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 121/313, Loss: 1.6254005432128906, Running Accuracy: 0.9056412337662337, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 122/313, Loss: 1.5077199935913086, Running Accuracy: 0.9060483870967742, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 123/313, Loss: 1.5886223316192627, Running Accuracy: 0.9060496794871795, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 124/313, Loss: 1.5525455474853516, Running Accuracy: 0.90625, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 125/313, Loss: 1.5845332145690918, Running Accuracy: 0.90625, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 126/313, Loss: 1.5345462560653687, Running Accuracy: 0.9068396226415094, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 127/313, Loss: 1.6260772943496704, Running Accuracy: 0.9064453125, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 128/313, Loss: 1.5843806266784668, Running Accuracy: 0.90625, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 129/313, Loss: 1.5896251201629639, Running Accuracy: 0.9060570987654321, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 130/313, Loss: 1.6406968832015991, Running Accuracy: 0.9056748466257669, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 131/313, Loss: 1.650387167930603, Running Accuracy: 0.9051067073170732, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 132/313, Loss: 1.5410233736038208, Running Accuracy: 0.9053030303030303, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 133/313, Loss: 1.6245862245559692, Running Accuracy: 0.9049322289156626, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 134/313, Loss: 1.5230242013931274, Running Accuracy: 0.905501497005988, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 135/313, Loss: 1.6155219078063965, Running Accuracy: 0.9053199404761905, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 136/313, Loss: 1.571332335472107, Running Accuracy: 0.9055103550295858, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 137/313, Loss: 1.5296167135238647, Running Accuracy: 0.9058823529411765, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 138/313, Loss: 1.5482672452926636, Running Accuracy: 0.9060672514619883, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 139/313, Loss: 1.527634859085083, Running Accuracy: 0.9064316860465116, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 140/313, Loss: 1.5441712141036987, Running Accuracy: 0.9066112716763006, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 141/313, Loss: 1.5680735111236572, Running Accuracy: 0.9069683908045977, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 142/313, Loss: 1.5407906770706177, Running Accuracy: 0.9071428571428571, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 143/313, Loss: 1.585057020187378, Running Accuracy: 0.9073153409090909, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 144/313, Loss: 1.5956226587295532, Running Accuracy: 0.907132768361582, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 145/313, Loss: 1.5502431392669678, Running Accuracy: 0.9073033707865169, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 146/313, Loss: 1.599622368812561, Running Accuracy: 0.9069483240223464, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 147/313, Loss: 1.5705289840698242, Running Accuracy: 0.9067708333333333, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 148/313, Loss: 1.5795053243637085, Running Accuracy: 0.9071132596685083, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 149/313, Loss: 1.5623712539672852, Running Accuracy: 0.9072802197802198, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 150/313, Loss: 1.6138468980789185, Running Accuracy: 0.907103825136612, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 151/313, Loss: 1.557926058769226, Running Accuracy: 0.9074388586956522, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 152/313, Loss: 1.5147608518600464, Running Accuracy: 0.9079391891891891, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 153/313, Loss: 1.5843877792358398, Running Accuracy: 0.9079301075268817, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 154/313, Loss: 1.5603965520858765, Running Accuracy: 0.9082553475935828, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 155/313, Loss: 1.5636588335037231, Running Accuracy: 0.9084109042553191, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 156/313, Loss: 1.5974726676940918, Running Accuracy: 0.9083994708994709, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 157/313, Loss: 1.5148435831069946, Running Accuracy: 0.9085526315789474, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 158/313, Loss: 1.5334538221359253, Running Accuracy: 0.9087041884816754, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 159/313, Loss: 1.593623161315918, Running Accuracy: 0.90869140625, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 160/313, Loss: 1.5760244131088257, Running Accuracy: 0.9085168393782384, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 161/313, Loss: 1.595196008682251, Running Accuracy: 0.9085051546391752, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 162/313, Loss: 1.6072100400924683, Running Accuracy: 0.9084935897435897, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 163/313, Loss: 1.5685863494873047, Running Accuracy: 0.9086415816326531, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 164/313, Loss: 1.5760124921798706, Running Accuracy: 0.9086294416243654, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 165/313, Loss: 1.5602971315383911, Running Accuracy: 0.9087752525252525, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 166/313, Loss: 1.5619843006134033, Running Accuracy: 0.9087625628140703, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 167/313, Loss: 1.6570804119110107, Running Accuracy: 0.90828125, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 168/313, Loss: 1.6011847257614136, Running Accuracy: 0.908271144278607, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 169/313, Loss: 1.5541141033172607, Running Accuracy: 0.9084158415841584, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 170/313, Loss: 1.6063698530197144, Running Accuracy: 0.9082512315270936, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 171/313, Loss: 1.557348370552063, Running Accuracy: 0.9083946078431373, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 172/313, Loss: 1.605943202972412, Running Accuracy: 0.9083841463414634, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 173/313, Loss: 1.6096065044403076, Running Accuracy: 0.9082220873786407, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 174/313, Loss: 1.5173141956329346, Running Accuracy: 0.9085144927536232, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 175/313, Loss: 1.5677821636199951, Running Accuracy: 0.9085036057692307, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 176/313, Loss: 1.5193649530410767, Running Accuracy: 0.9086423444976076, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 177/313, Loss: 1.5885359048843384, Running Accuracy: 0.9084821428571429, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 178/313, Loss: 1.5079914331436157, Running Accuracy: 0.9087677725118484, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 179/313, Loss: 1.5565859079360962, Running Accuracy: 0.9087558962264151, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 180/313, Loss: 1.6988556385040283, Running Accuracy: 0.9083039906103286, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 181/313, Loss: 1.491744041442871, Running Accuracy: 0.908732476635514, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 182/313, Loss: 1.606032371520996, Running Accuracy: 0.9087209302325582, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 183/313, Loss: 1.6081247329711914, Running Accuracy: 0.9084201388888888, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 184/313, Loss: 1.6525532007217407, Running Accuracy: 0.9081221198156681, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 185/313, Loss: 1.5315970182418823, Running Accuracy: 0.9084002293577982, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 186/313, Loss: 1.5286511182785034, Running Accuracy: 0.908675799086758, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 187/313, Loss: 1.59443998336792, Running Accuracy: 0.9086647727272728, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 188/313, Loss: 1.5585157871246338, Running Accuracy: 0.9089366515837104, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 189/313, Loss: 1.565449595451355, Running Accuracy: 0.909206081081081, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 190/313, Loss: 1.7192010879516602, Running Accuracy: 0.9084921524663677, Current Accuracy 0.75\n",
      "Epoch: 2, Batch: 191/313, Loss: 1.6768239736557007, Running Accuracy: 0.9080636160714286, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 192/313, Loss: 1.552259922027588, Running Accuracy: 0.9080555555555555, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 193/313, Loss: 1.5593034029006958, Running Accuracy: 0.9081858407079646, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 194/313, Loss: 1.6118241548538208, Running Accuracy: 0.9079019823788547, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 195/313, Loss: 1.5822290182113647, Running Accuracy: 0.9080317982456141, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 196/313, Loss: 1.6090365648269653, Running Accuracy: 0.9078875545851528, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 197/313, Loss: 1.6335731744766235, Running Accuracy: 0.9077445652173913, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 198/313, Loss: 1.520830750465393, Running Accuracy: 0.9081439393939394, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 199/313, Loss: 1.6088215112686157, Running Accuracy: 0.908135775862069, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 200/313, Loss: 1.5842840671539307, Running Accuracy: 0.9079935622317596, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 201/313, Loss: 1.56308913230896, Running Accuracy: 0.9079861111111112, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 202/313, Loss: 1.5299339294433594, Running Accuracy: 0.9081117021276596, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 203/313, Loss: 1.5636045932769775, Running Accuracy: 0.908103813559322, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 204/313, Loss: 1.4942954778671265, Running Accuracy: 0.9084915611814346, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 205/313, Loss: 1.5761669874191284, Running Accuracy: 0.9084821428571429, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 206/313, Loss: 1.5500340461730957, Running Accuracy: 0.9087343096234309, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 207/313, Loss: 1.6099332571029663, Running Accuracy: 0.90859375, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 208/313, Loss: 1.5064585208892822, Running Accuracy: 0.9089730290456431, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 209/313, Loss: 1.581200361251831, Running Accuracy: 0.9089617768595041, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 210/313, Loss: 1.5832133293151855, Running Accuracy: 0.9089506172839507, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 211/313, Loss: 1.5238596200942993, Running Accuracy: 0.9093237704918032, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 212/313, Loss: 1.560497522354126, Running Accuracy: 0.9095663265306122, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 213/313, Loss: 1.6200307607650757, Running Accuracy: 0.9091717479674797, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 214/313, Loss: 1.5807697772979736, Running Accuracy: 0.9090334008097166, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 215/313, Loss: 1.5227075815200806, Running Accuracy: 0.909148185483871, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 216/313, Loss: 1.5414942502975464, Running Accuracy: 0.9092620481927711, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 217/313, Loss: 1.612017273902893, Running Accuracy: 0.90925, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 218/313, Loss: 1.5136491060256958, Running Accuracy: 0.9094870517928287, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 219/313, Loss: 1.5741978883743286, Running Accuracy: 0.9094742063492064, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 220/313, Loss: 1.5190191268920898, Running Accuracy: 0.9097084980237155, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 221/313, Loss: 1.6446607112884521, Running Accuracy: 0.9093257874015748, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 222/313, Loss: 1.585377812385559, Running Accuracy: 0.9091911764705882, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 223/313, Loss: 1.5569884777069092, Running Accuracy: 0.9091796875, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 224/313, Loss: 1.599800705909729, Running Accuracy: 0.9091682879377432, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 225/313, Loss: 1.555187702178955, Running Accuracy: 0.909156976744186, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 226/313, Loss: 1.6025892496109009, Running Accuracy: 0.9090250965250966, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 227/313, Loss: 1.5323044061660767, Running Accuracy: 0.9091346153846154, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 228/313, Loss: 1.5905379056930542, Running Accuracy: 0.9091235632183908, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 229/313, Loss: 1.5752366781234741, Running Accuracy: 0.9091125954198473, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 230/313, Loss: 1.580505132675171, Running Accuracy: 0.9092205323193916, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 231/313, Loss: 1.5368198156356812, Running Accuracy: 0.9093276515151515, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 232/313, Loss: 1.5396875143051147, Running Accuracy: 0.909433962264151, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 233/313, Loss: 1.6142430305480957, Running Accuracy: 0.909421992481203, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 234/313, Loss: 1.5817869901657104, Running Accuracy: 0.9092930711610487, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 235/313, Loss: 1.5768985748291016, Running Accuracy: 0.9091651119402985, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 236/313, Loss: 1.5591883659362793, Running Accuracy: 0.9092704460966543, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 237/313, Loss: 1.5500730276107788, Running Accuracy: 0.909375, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 238/313, Loss: 1.5782614946365356, Running Accuracy: 0.9093634686346863, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 239/313, Loss: 1.6014643907546997, Running Accuracy: 0.9092371323529411, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 240/313, Loss: 1.5974211692810059, Running Accuracy: 0.9092261904761905, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 241/313, Loss: 1.520527720451355, Running Accuracy: 0.9094434306569343, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 242/313, Loss: 1.5550404787063599, Running Accuracy: 0.9094318181818182, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 243/313, Loss: 1.6033787727355957, Running Accuracy: 0.9094202898550725, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 244/313, Loss: 1.5812610387802124, Running Accuracy: 0.9092960288808665, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 245/313, Loss: 1.6381512880325317, Running Accuracy: 0.9090602517985612, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 246/313, Loss: 1.5920639038085938, Running Accuracy: 0.9088261648745519, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 247/313, Loss: 1.5566282272338867, Running Accuracy: 0.9089285714285714, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 248/313, Loss: 1.496689796447754, Running Accuracy: 0.9092526690391459, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 249/313, Loss: 1.553087830543518, Running Accuracy: 0.9093528368794326, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 250/313, Loss: 1.608709692955017, Running Accuracy: 0.9092314487632509, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 251/313, Loss: 1.591838002204895, Running Accuracy: 0.9091109154929577, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 252/313, Loss: 1.5911093950271606, Running Accuracy: 0.9092105263157895, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 253/313, Loss: 1.5676417350769043, Running Accuracy: 0.9092001748251748, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 254/313, Loss: 1.60416841506958, Running Accuracy: 0.9090810104529616, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 255/313, Loss: 1.4942015409469604, Running Accuracy: 0.9093967013888888, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 256/313, Loss: 1.6413027048110962, Running Accuracy: 0.9090614186851211, Current Accuracy 0.8125\n",
      "Epoch: 2, Batch: 257/313, Loss: 1.5196582078933716, Running Accuracy: 0.9092672413793104, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 258/313, Loss: 1.6186355352401733, Running Accuracy: 0.9091494845360825, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 259/313, Loss: 1.5783255100250244, Running Accuracy: 0.9092465753424658, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 260/313, Loss: 1.550079584121704, Running Accuracy: 0.9093430034129693, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 261/313, Loss: 1.6046139001846313, Running Accuracy: 0.9091198979591837, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 262/313, Loss: 1.529012680053711, Running Accuracy: 0.9093220338983051, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 263/313, Loss: 1.6280150413513184, Running Accuracy: 0.909206081081081, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 264/313, Loss: 1.5913197994232178, Running Accuracy: 0.9091961279461279, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 265/313, Loss: 1.5885461568832397, Running Accuracy: 0.9092911073825504, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 266/313, Loss: 1.544793725013733, Running Accuracy: 0.9092809364548495, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 267/313, Loss: 1.5907765626907349, Running Accuracy: 0.9092708333333334, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 268/313, Loss: 1.5639952421188354, Running Accuracy: 0.9093646179401993, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 269/313, Loss: 1.5800952911376953, Running Accuracy: 0.9092508278145696, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 270/313, Loss: 1.5559178590774536, Running Accuracy: 0.9093440594059405, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 271/313, Loss: 1.5186359882354736, Running Accuracy: 0.9095394736842105, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 272/313, Loss: 1.6014518737792969, Running Accuracy: 0.9093237704918032, Current Accuracy 0.84375\n",
      "Epoch: 2, Batch: 273/313, Loss: 1.5527288913726807, Running Accuracy: 0.9095179738562091, Current Accuracy 0.96875\n",
      "Epoch: 2, Batch: 274/313, Loss: 1.5752723217010498, Running Accuracy: 0.9094055374592834, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 275/313, Loss: 1.5828185081481934, Running Accuracy: 0.9093952922077922, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 276/313, Loss: 1.5738232135772705, Running Accuracy: 0.9093851132686084, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 277/313, Loss: 1.6070582866668701, Running Accuracy: 0.9092741935483871, Current Accuracy 0.875\n",
      "Epoch: 2, Batch: 278/313, Loss: 1.542729139328003, Running Accuracy: 0.9093649517684887, Current Accuracy 0.9375\n",
      "Epoch: 2, Batch: 279/313, Loss: 1.489357829093933, Running Accuracy: 0.9096554487179487, Current Accuracy 1.0\n",
      "Epoch: 2, Batch: 280/313, Loss: 1.5778576135635376, Running Accuracy: 0.9096445686900958, Current Accuracy 0.90625\n",
      "Epoch: 2, Batch: 281/313, Loss: 1.5937618017196655, Running Accuracy: 0.9095342356687898, Current Accuracy 0.875\n",
      "Epoch: 2, Test Accuracy: 0.9375\n",
      "Epoch: 2, Test Accuracy: 0.90625\n",
      "Epoch: 2, Test Accuracy: 0.9270833333333334\n",
      "Epoch: 2, Test Accuracy: 0.921875\n",
      "Epoch: 2, Test Accuracy: 0.9125\n",
      "Epoch: 2, Test Accuracy: 0.9166666666666666\n",
      "Epoch: 2, Test Accuracy: 0.9285714285714286\n",
      "Epoch: 2, Test Accuracy: 0.9375\n",
      "Epoch: 2, Test Accuracy: 0.9305555555555556\n",
      "Epoch: 2, Test Accuracy: 0.93125\n",
      "Epoch: 2, Test Accuracy: 0.9232954545454546\n",
      "Epoch: 2, Test Accuracy: 0.9010416666666666\n",
      "Epoch: 2, Test Accuracy: 0.9038461538461539\n",
      "Epoch: 2, Test Accuracy: 0.9084821428571429\n",
      "Epoch: 2, Test Accuracy: 0.90625\n",
      "Epoch: 2, Test Accuracy: 0.90625\n",
      "Epoch: 2, Test Accuracy: 0.8988970588235294\n",
      "Epoch: 2, Test Accuracy: 0.8975694444444444\n",
      "Epoch: 2, Test Accuracy: 0.9013157894736842\n",
      "Epoch: 2, Test Accuracy: 0.9015625\n",
      "Epoch: 2, Test Accuracy: 0.9032738095238095\n",
      "Epoch: 2, Test Accuracy: 0.9019886363636364\n",
      "Epoch: 2, Test Accuracy: 0.9008152173913043\n",
      "Epoch: 2, Test Accuracy: 0.90234375\n",
      "Epoch: 2, Test Accuracy: 0.9025\n",
      "Epoch: 2, Test Accuracy: 0.9014423076923077\n",
      "Epoch: 2, Test Accuracy: 0.9027777777777778\n",
      "Epoch: 2, Test Accuracy: 0.9006696428571429\n",
      "Epoch: 2, Test Accuracy: 0.9019396551724138\n",
      "Epoch: 2, Test Accuracy: 0.9020833333333333\n",
      "Epoch: 2, Test Accuracy: 0.9022177419354839\n",
      "Epoch: 2, Test Accuracy: 0.9013671875\n",
      "Epoch: 3, Batch: 0/313, Loss: 1.4976515769958496, Running Accuracy: 0.9043560606060606, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 1/313, Loss: 1.540263295173645, Running Accuracy: 0.9053308823529411, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 2/313, Loss: 1.5278356075286865, Running Accuracy: 0.90625, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 3/313, Loss: 1.6764719486236572, Running Accuracy: 0.9027777777777778, Current Accuracy 0.78125\n",
      "Epoch: 3, Batch: 4/313, Loss: 1.5857192277908325, Running Accuracy: 0.9028716216216216, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 5/313, Loss: 1.5086554288864136, Running Accuracy: 0.9046052631578947, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 6/313, Loss: 1.5722520351409912, Running Accuracy: 0.9046474358974359, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 7/313, Loss: 1.5784695148468018, Running Accuracy: 0.90390625, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 8/313, Loss: 1.5233467817306519, Running Accuracy: 0.9054878048780488, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 9/313, Loss: 1.6031557321548462, Running Accuracy: 0.9047619047619048, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 10/313, Loss: 1.5264586210250854, Running Accuracy: 0.90625, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 11/313, Loss: 1.5836255550384521, Running Accuracy: 0.90625, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 12/313, Loss: 1.528896450996399, Running Accuracy: 0.9069444444444444, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 13/313, Loss: 1.581078052520752, Running Accuracy: 0.9069293478260869, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 14/313, Loss: 1.5547330379486084, Running Accuracy: 0.9075797872340425, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 15/313, Loss: 1.557040810585022, Running Accuracy: 0.9075520833333334, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 16/313, Loss: 1.498587965965271, Running Accuracy: 0.9094387755102041, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 17/313, Loss: 1.5654757022857666, Running Accuracy: 0.91, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 18/313, Loss: 1.5133610963821411, Running Accuracy: 0.9111519607843137, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 19/313, Loss: 1.6488324403762817, Running Accuracy: 0.9098557692307693, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 20/313, Loss: 1.5553607940673828, Running Accuracy: 0.910377358490566, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 21/313, Loss: 1.5475192070007324, Running Accuracy: 0.9114583333333334, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 22/313, Loss: 1.5007716417312622, Running Accuracy: 0.9130681818181818, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 23/313, Loss: 1.5498441457748413, Running Accuracy: 0.9140625, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 24/313, Loss: 1.5213420391082764, Running Accuracy: 0.9150219298245614, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 25/313, Loss: 1.5416172742843628, Running Accuracy: 0.9164870689655172, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 26/313, Loss: 1.5402741432189941, Running Accuracy: 0.916843220338983, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 27/313, Loss: 1.6077518463134766, Running Accuracy: 0.915625, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 28/313, Loss: 1.5361547470092773, Running Accuracy: 0.9164959016393442, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 29/313, Loss: 1.5621123313903809, Running Accuracy: 0.9168346774193549, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 30/313, Loss: 1.5819722414016724, Running Accuracy: 0.9166666666666666, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 31/313, Loss: 1.5259073972702026, Running Accuracy: 0.91748046875, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 32/313, Loss: 1.5883383750915527, Running Accuracy: 0.9173076923076923, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 33/313, Loss: 1.562883734703064, Running Accuracy: 0.9176136363636364, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 34/313, Loss: 1.6458274126052856, Running Accuracy: 0.9165111940298507, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 35/313, Loss: 1.558208703994751, Running Accuracy: 0.9163602941176471, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 36/313, Loss: 1.5493391752243042, Running Accuracy: 0.916213768115942, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 37/313, Loss: 1.5073322057724, Running Accuracy: 0.9169642857142857, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 38/313, Loss: 1.572097659111023, Running Accuracy: 0.9168133802816901, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 39/313, Loss: 1.6156401634216309, Running Accuracy: 0.9157986111111112, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 40/313, Loss: 1.5648280382156372, Running Accuracy: 0.916095890410959, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 41/313, Loss: 1.5319006443023682, Running Accuracy: 0.9163851351351351, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 42/313, Loss: 1.5271801948547363, Running Accuracy: 0.9170833333333334, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 43/313, Loss: 1.5394434928894043, Running Accuracy: 0.9173519736842105, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 44/313, Loss: 1.5359050035476685, Running Accuracy: 0.9176136363636364, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 45/313, Loss: 1.524570107460022, Running Accuracy: 0.9182692307692307, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 46/313, Loss: 1.5804541110992432, Running Accuracy: 0.9177215189873418, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 47/313, Loss: 1.571112871170044, Running Accuracy: 0.91796875, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 48/313, Loss: 1.570944905281067, Running Accuracy: 0.9178240740740741, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 49/313, Loss: 1.5062572956085205, Running Accuracy: 0.9184451219512195, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 50/313, Loss: 1.5540828704833984, Running Accuracy: 0.9186746987951807, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 51/313, Loss: 1.488037347793579, Running Accuracy: 0.9196428571428571, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 52/313, Loss: 1.5115389823913574, Running Accuracy: 0.9202205882352941, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 53/313, Loss: 1.625290870666504, Running Accuracy: 0.920421511627907, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 54/313, Loss: 1.5385301113128662, Running Accuracy: 0.9209770114942529, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 55/313, Loss: 1.6605265140533447, Running Accuracy: 0.9200994318181818, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 56/313, Loss: 1.5270400047302246, Running Accuracy: 0.9206460674157303, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 57/313, Loss: 1.5374336242675781, Running Accuracy: 0.9208333333333333, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 58/313, Loss: 1.5405253171920776, Running Accuracy: 0.9210164835164835, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 59/313, Loss: 1.5257691144943237, Running Accuracy: 0.9215353260869565, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 60/313, Loss: 1.5039457082748413, Running Accuracy: 0.9223790322580645, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 61/313, Loss: 1.5868453979492188, Running Accuracy: 0.9222074468085106, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 62/313, Loss: 1.5763559341430664, Running Accuracy: 0.9220394736842106, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 63/313, Loss: 1.5514813661575317, Running Accuracy: 0.9222005208333334, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 64/313, Loss: 1.5434211492538452, Running Accuracy: 0.9226804123711341, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 65/313, Loss: 1.5858802795410156, Running Accuracy: 0.9225127551020408, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 66/313, Loss: 1.5435737371444702, Running Accuracy: 0.9226641414141414, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 67/313, Loss: 1.5803676843643188, Running Accuracy: 0.9228125, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 68/313, Loss: 1.544557809829712, Running Accuracy: 0.9232673267326733, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 69/313, Loss: 1.5122545957565308, Running Accuracy: 0.9237132352941176, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 70/313, Loss: 1.5700947046279907, Running Accuracy: 0.9238470873786407, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 71/313, Loss: 1.5149120092391968, Running Accuracy: 0.9242788461538461, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 72/313, Loss: 1.5638113021850586, Running Accuracy: 0.924404761904762, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 73/313, Loss: 1.5534420013427734, Running Accuracy: 0.9245283018867925, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 74/313, Loss: 1.5324281454086304, Running Accuracy: 0.9246495327102804, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 75/313, Loss: 1.547928810119629, Running Accuracy: 0.9247685185185185, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 76/313, Loss: 1.53396475315094, Running Accuracy: 0.9248853211009175, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 77/313, Loss: 1.4950166940689087, Running Accuracy: 0.9252840909090909, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 78/313, Loss: 1.5190898180007935, Running Accuracy: 0.9259572072072072, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 79/313, Loss: 1.5490995645523071, Running Accuracy: 0.9263392857142857, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 80/313, Loss: 1.5283799171447754, Running Accuracy: 0.9267146017699115, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 81/313, Loss: 1.5849947929382324, Running Accuracy: 0.9265350877192983, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 82/313, Loss: 1.562544822692871, Running Accuracy: 0.9266304347826086, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 83/313, Loss: 1.5343756675720215, Running Accuracy: 0.9269935344827587, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 84/313, Loss: 1.544144868850708, Running Accuracy: 0.9273504273504274, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 85/313, Loss: 1.5558832883834839, Running Accuracy: 0.9274364406779662, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 86/313, Loss: 1.560142993927002, Running Accuracy: 0.9275210084033614, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 87/313, Loss: 1.5276259183883667, Running Accuracy: 0.9276041666666667, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 88/313, Loss: 1.5888569355010986, Running Accuracy: 0.9271694214876033, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 89/313, Loss: 1.5652778148651123, Running Accuracy: 0.9272540983606558, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 90/313, Loss: 1.5315428972244263, Running Accuracy: 0.9275914634146342, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 91/313, Loss: 1.5815826654434204, Running Accuracy: 0.9274193548387096, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 92/313, Loss: 1.5852130651474, Running Accuracy: 0.92725, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 93/313, Loss: 1.510401725769043, Running Accuracy: 0.9275793650793651, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 94/313, Loss: 1.5913188457489014, Running Accuracy: 0.9271653543307087, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 95/313, Loss: 1.505771279335022, Running Accuracy: 0.927734375, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 96/313, Loss: 1.6092510223388672, Running Accuracy: 0.9273255813953488, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 97/313, Loss: 1.5145925283432007, Running Accuracy: 0.9278846153846154, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 98/313, Loss: 1.5381674766540527, Running Accuracy: 0.9279580152671756, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 99/313, Loss: 1.5539968013763428, Running Accuracy: 0.9277935606060606, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 100/313, Loss: 1.5519102811813354, Running Accuracy: 0.9278665413533834, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 101/313, Loss: 1.506131649017334, Running Accuracy: 0.9281716417910447, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 102/313, Loss: 1.5547478199005127, Running Accuracy: 0.9280092592592593, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 103/313, Loss: 1.6161553859710693, Running Accuracy: 0.9273897058823529, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 104/313, Loss: 1.6097626686096191, Running Accuracy: 0.927007299270073, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 105/313, Loss: 1.5452475547790527, Running Accuracy: 0.9270833333333334, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 106/313, Loss: 1.5706487894058228, Running Accuracy: 0.927158273381295, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 107/313, Loss: 1.5930546522140503, Running Accuracy: 0.9267857142857143, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 108/313, Loss: 1.5890434980392456, Running Accuracy: 0.9266400709219859, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 109/313, Loss: 1.5587513446807861, Running Accuracy: 0.9267165492957746, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 110/313, Loss: 1.5435335636138916, Running Accuracy: 0.9270104895104895, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 111/313, Loss: 1.5547666549682617, Running Accuracy: 0.9270833333333334, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 112/313, Loss: 1.5075081586837769, Running Accuracy: 0.9273706896551724, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 113/313, Loss: 1.5632476806640625, Running Accuracy: 0.9274400684931506, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 114/313, Loss: 1.5485621690750122, Running Accuracy: 0.9275085034013606, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 115/313, Loss: 1.5298272371292114, Running Accuracy: 0.9275760135135135, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 116/313, Loss: 1.6058728694915771, Running Accuracy: 0.9272231543624161, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 117/313, Loss: 1.474788784980774, Running Accuracy: 0.9277083333333334, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 118/313, Loss: 1.6094117164611816, Running Accuracy: 0.9275662251655629, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 119/313, Loss: 1.5627015829086304, Running Accuracy: 0.9276315789473685, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 120/313, Loss: 1.6144614219665527, Running Accuracy: 0.9270833333333334, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 121/313, Loss: 1.5005320310592651, Running Accuracy: 0.9273538961038961, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 122/313, Loss: 1.5297926664352417, Running Accuracy: 0.9276209677419355, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 123/313, Loss: 1.5879557132720947, Running Accuracy: 0.9276842948717948, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 124/313, Loss: 1.5636273622512817, Running Accuracy: 0.9277468152866242, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 125/313, Loss: 1.5412122011184692, Running Accuracy: 0.9278085443037974, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 126/313, Loss: 1.504234790802002, Running Accuracy: 0.9280660377358491, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 127/313, Loss: 1.5995466709136963, Running Accuracy: 0.9275390625, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 128/313, Loss: 1.5559332370758057, Running Accuracy: 0.9276009316770186, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 129/313, Loss: 1.5188437700271606, Running Accuracy: 0.9276620370370371, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 130/313, Loss: 1.568620204925537, Running Accuracy: 0.9275306748466258, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 131/313, Loss: 1.4892427921295166, Running Accuracy: 0.9279725609756098, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 132/313, Loss: 1.5335530042648315, Running Accuracy: 0.928219696969697, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 133/313, Loss: 1.5432634353637695, Running Accuracy: 0.9284638554216867, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 134/313, Loss: 1.5420135259628296, Running Accuracy: 0.9285179640718563, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 135/313, Loss: 1.5400453805923462, Running Accuracy: 0.9285714285714286, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 136/313, Loss: 1.5501952171325684, Running Accuracy: 0.9288091715976331, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 137/313, Loss: 1.5397838354110718, Running Accuracy: 0.9290441176470589, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 138/313, Loss: 1.5755572319030762, Running Accuracy: 0.9289108187134503, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 139/313, Loss: 1.5997411012649536, Running Accuracy: 0.9285973837209303, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 140/313, Loss: 1.5857781171798706, Running Accuracy: 0.9282875722543352, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 141/313, Loss: 1.6151151657104492, Running Accuracy: 0.9279813218390804, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 142/313, Loss: 1.5176090002059937, Running Accuracy: 0.9283928571428571, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 143/313, Loss: 1.5449395179748535, Running Accuracy: 0.9286221590909091, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 144/313, Loss: 1.5658682584762573, Running Accuracy: 0.9286723163841808, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 145/313, Loss: 1.4812296628952026, Running Accuracy: 0.9290730337078652, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 146/313, Loss: 1.545524001121521, Running Accuracy: 0.9292946927374302, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 147/313, Loss: 1.5316722393035889, Running Accuracy: 0.9295138888888889, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 148/313, Loss: 1.5169974565505981, Running Accuracy: 0.9295580110497238, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 149/313, Loss: 1.5261675119400024, Running Accuracy: 0.929945054945055, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 150/313, Loss: 1.5924732685089111, Running Accuracy: 0.9298155737704918, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 151/313, Loss: 1.518837571144104, Running Accuracy: 0.9301970108695652, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 152/313, Loss: 1.5251775979995728, Running Accuracy: 0.9302364864864865, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 153/313, Loss: 1.5047760009765625, Running Accuracy: 0.9304435483870968, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 154/313, Loss: 1.5510931015014648, Running Accuracy: 0.93048128342246, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 155/313, Loss: 1.5722224712371826, Running Accuracy: 0.9305186170212766, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 156/313, Loss: 1.6421396732330322, Running Accuracy: 0.9300595238095238, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 157/313, Loss: 1.5601997375488281, Running Accuracy: 0.9300986842105263, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 158/313, Loss: 1.5475910902023315, Running Accuracy: 0.9303010471204188, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 159/313, Loss: 1.4991155862808228, Running Accuracy: 0.9305013020833334, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 160/313, Loss: 1.5635451078414917, Running Accuracy: 0.930699481865285, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 161/313, Loss: 1.5158970355987549, Running Accuracy: 0.930895618556701, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 162/313, Loss: 1.545462965965271, Running Accuracy: 0.9309294871794872, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 163/313, Loss: 1.501933217048645, Running Accuracy: 0.9311224489795918, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 164/313, Loss: 1.5487688779830933, Running Accuracy: 0.9311548223350253, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 165/313, Loss: 1.6137120723724365, Running Accuracy: 0.9308712121212122, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 166/313, Loss: 1.5100775957107544, Running Accuracy: 0.9310615577889447, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 167/313, Loss: 1.4719531536102295, Running Accuracy: 0.93140625, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 168/313, Loss: 1.5858289003372192, Running Accuracy: 0.9311256218905473, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 169/313, Loss: 1.6081464290618896, Running Accuracy: 0.9306930693069307, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 170/313, Loss: 1.5522793531417847, Running Accuracy: 0.9305726600985221, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 171/313, Loss: 1.529822826385498, Running Accuracy: 0.9306066176470589, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 172/313, Loss: 1.5873697996139526, Running Accuracy: 0.930640243902439, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 173/313, Loss: 1.61333167552948, Running Accuracy: 0.930370145631068, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 174/313, Loss: 1.5942561626434326, Running Accuracy: 0.9302536231884058, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 175/313, Loss: 1.547521710395813, Running Accuracy: 0.9304387019230769, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 176/313, Loss: 1.549288034439087, Running Accuracy: 0.930322966507177, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 177/313, Loss: 1.5637575387954712, Running Accuracy: 0.9303571428571429, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 178/313, Loss: 1.5659544467926025, Running Accuracy: 0.9303909952606635, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 179/313, Loss: 1.5140652656555176, Running Accuracy: 0.9307193396226415, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 180/313, Loss: 1.557413935661316, Running Accuracy: 0.9307511737089202, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 181/313, Loss: 1.6265959739685059, Running Accuracy: 0.9304906542056075, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 182/313, Loss: 1.6214953660964966, Running Accuracy: 0.9302325581395349, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 183/313, Loss: 1.5258547067642212, Running Accuracy: 0.9304108796296297, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 184/313, Loss: 1.5624163150787354, Running Accuracy: 0.9304435483870968, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 185/313, Loss: 1.5306109189987183, Running Accuracy: 0.9306192660550459, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 186/313, Loss: 1.5931352376937866, Running Accuracy: 0.93050799086758, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 187/313, Loss: 1.5241875648498535, Running Accuracy: 0.9306818181818182, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 188/313, Loss: 1.5808383226394653, Running Accuracy: 0.9305712669683258, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 189/313, Loss: 1.6446666717529297, Running Accuracy: 0.9301801801801802, Current Accuracy 0.84375\n",
      "Epoch: 3, Batch: 190/313, Loss: 1.4920772314071655, Running Accuracy: 0.930353139013453, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 191/313, Loss: 1.5580215454101562, Running Accuracy: 0.9302455357142857, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 192/313, Loss: 1.544735312461853, Running Accuracy: 0.9301388888888888, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 193/313, Loss: 1.5192126035690308, Running Accuracy: 0.9303097345132744, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 194/313, Loss: 1.536795973777771, Running Accuracy: 0.9303414096916299, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 195/313, Loss: 1.5869357585906982, Running Accuracy: 0.9302357456140351, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 196/313, Loss: 1.5315253734588623, Running Accuracy: 0.9302674672489083, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 197/313, Loss: 1.5650852918624878, Running Accuracy: 0.9302989130434782, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 198/313, Loss: 1.5655546188354492, Running Accuracy: 0.9303300865800865, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 199/313, Loss: 1.5132986307144165, Running Accuracy: 0.9304956896551724, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 200/313, Loss: 1.5345804691314697, Running Accuracy: 0.9306598712446352, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 201/313, Loss: 1.5459235906600952, Running Accuracy: 0.9308226495726496, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 202/313, Loss: 1.5792533159255981, Running Accuracy: 0.930718085106383, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 203/313, Loss: 1.5193548202514648, Running Accuracy: 0.9308792372881356, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 204/313, Loss: 1.5186680555343628, Running Accuracy: 0.9309071729957806, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 205/313, Loss: 1.5591288805007935, Running Accuracy: 0.9310661764705882, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 206/313, Loss: 1.5631141662597656, Running Accuracy: 0.9310930962343096, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 207/313, Loss: 1.6000797748565674, Running Accuracy: 0.930859375, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 208/313, Loss: 1.5222262144088745, Running Accuracy: 0.9310165975103735, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 209/313, Loss: 1.5889582633972168, Running Accuracy: 0.9309142561983471, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 210/313, Loss: 1.5971015691757202, Running Accuracy: 0.9306841563786008, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 211/313, Loss: 1.55921471118927, Running Accuracy: 0.9307120901639344, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 212/313, Loss: 1.6306934356689453, Running Accuracy: 0.9304846938775511, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 213/313, Loss: 1.5342236757278442, Running Accuracy: 0.930640243902439, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 214/313, Loss: 1.5721325874328613, Running Accuracy: 0.9305414979757085, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 215/313, Loss: 1.5568511486053467, Running Accuracy: 0.9304435483870968, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 216/313, Loss: 1.5421885251998901, Running Accuracy: 0.9305973895582329, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 217/313, Loss: 1.4961079359054565, Running Accuracy: 0.930875, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 218/313, Loss: 1.5384628772735596, Running Accuracy: 0.9310258964143426, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 219/313, Loss: 1.5425183773040771, Running Accuracy: 0.9311755952380952, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 220/313, Loss: 1.5447746515274048, Running Accuracy: 0.9312005928853755, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 221/313, Loss: 1.5906846523284912, Running Accuracy: 0.9309793307086615, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 222/313, Loss: 1.5878716707229614, Running Accuracy: 0.9307598039215687, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 223/313, Loss: 1.575373888015747, Running Accuracy: 0.9306640625, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 224/313, Loss: 1.5839433670043945, Running Accuracy: 0.9304474708171206, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 225/313, Loss: 1.521198034286499, Running Accuracy: 0.9307170542635659, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 226/313, Loss: 1.4780350923538208, Running Accuracy: 0.930984555984556, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 227/313, Loss: 1.5730005502700806, Running Accuracy: 0.9308894230769231, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 228/313, Loss: 1.4849066734313965, Running Accuracy: 0.931154214559387, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 229/313, Loss: 1.5138027667999268, Running Accuracy: 0.9312977099236641, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 230/313, Loss: 1.5236928462982178, Running Accuracy: 0.9314401140684411, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 231/313, Loss: 1.5828964710235596, Running Accuracy: 0.9315814393939394, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 232/313, Loss: 1.5704529285430908, Running Accuracy: 0.9314858490566038, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 233/313, Loss: 1.573687195777893, Running Accuracy: 0.931390977443609, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 234/313, Loss: 1.4927040338516235, Running Accuracy: 0.9316479400749064, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 235/313, Loss: 1.539527416229248, Running Accuracy: 0.9317863805970149, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 236/313, Loss: 1.5206822156906128, Running Accuracy: 0.9318076208178439, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 237/313, Loss: 1.5099087953567505, Running Accuracy: 0.9319444444444445, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 238/313, Loss: 1.5823237895965576, Running Accuracy: 0.9318496309963099, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 239/313, Loss: 1.5171860456466675, Running Accuracy: 0.9318704044117647, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 240/313, Loss: 1.53803551197052, Running Accuracy: 0.9318910256410257, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 241/313, Loss: 1.5469787120819092, Running Accuracy: 0.9320255474452555, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 242/313, Loss: 1.5112582445144653, Running Accuracy: 0.9321590909090909, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 243/313, Loss: 1.529685616493225, Running Accuracy: 0.9322916666666666, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 244/313, Loss: 1.4982117414474487, Running Accuracy: 0.932423285198556, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 245/313, Loss: 1.525789499282837, Running Accuracy: 0.9325539568345323, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 246/313, Loss: 1.567098617553711, Running Accuracy: 0.9326836917562724, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 247/313, Loss: 1.5022308826446533, Running Accuracy: 0.9329241071428571, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 248/313, Loss: 1.5401517152786255, Running Accuracy: 0.9329403914590747, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 249/313, Loss: 1.5157828330993652, Running Accuracy: 0.9330673758865248, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 250/313, Loss: 1.5130095481872559, Running Accuracy: 0.933303886925795, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 251/313, Loss: 1.5552592277526855, Running Accuracy: 0.9334286971830986, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 252/313, Loss: 1.56757390499115, Running Accuracy: 0.9335526315789474, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 253/313, Loss: 1.5738838911056519, Running Accuracy: 0.9334571678321678, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 254/313, Loss: 1.558225393295288, Running Accuracy: 0.9333623693379791, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 255/313, Loss: 1.5535433292388916, Running Accuracy: 0.9333767361111112, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 256/313, Loss: 1.5134354829788208, Running Accuracy: 0.9336072664359861, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 257/313, Loss: 1.507691502571106, Running Accuracy: 0.9337284482758621, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 258/313, Loss: 1.5302722454071045, Running Accuracy: 0.9337414089347079, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 259/313, Loss: 1.6189353466033936, Running Accuracy: 0.9335402397260274, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 260/313, Loss: 1.6341394186019897, Running Accuracy: 0.9331271331058021, Current Accuracy 0.8125\n",
      "Epoch: 3, Batch: 261/313, Loss: 1.5664021968841553, Running Accuracy: 0.9330357142857143, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 262/313, Loss: 1.532951831817627, Running Accuracy: 0.9330508474576271, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 263/313, Loss: 1.4849035739898682, Running Accuracy: 0.933277027027027, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 264/313, Loss: 1.5699617862701416, Running Accuracy: 0.9330808080808081, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 265/313, Loss: 1.5135902166366577, Running Accuracy: 0.9332005033557047, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 266/313, Loss: 1.5366365909576416, Running Accuracy: 0.933319397993311, Current Accuracy 0.96875\n",
      "Epoch: 3, Batch: 267/313, Loss: 1.5399439334869385, Running Accuracy: 0.9333333333333333, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 268/313, Loss: 1.6540189981460571, Running Accuracy: 0.9329318936877077, Current Accuracy 0.8125\n",
      "Epoch: 3, Batch: 269/313, Loss: 1.5268325805664062, Running Accuracy: 0.9329470198675497, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 270/313, Loss: 1.585777997970581, Running Accuracy: 0.9329620462046204, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 271/313, Loss: 1.5975550413131714, Running Accuracy: 0.9327713815789473, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 272/313, Loss: 1.5324279069900513, Running Accuracy: 0.9327868852459016, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 273/313, Loss: 1.4824103116989136, Running Accuracy: 0.9330065359477124, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 274/313, Loss: 1.5141609907150269, Running Accuracy: 0.9332247557003257, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 275/313, Loss: 1.5928798913955688, Running Accuracy: 0.9330357142857143, Current Accuracy 0.875\n",
      "Epoch: 3, Batch: 276/313, Loss: 1.5446418523788452, Running Accuracy: 0.9330501618122977, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 277/313, Loss: 1.5809273719787598, Running Accuracy: 0.9329637096774194, Current Accuracy 0.90625\n",
      "Epoch: 3, Batch: 278/313, Loss: 1.550729751586914, Running Accuracy: 0.9329782958199357, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 279/313, Loss: 1.5391582250595093, Running Accuracy: 0.9329927884615384, Current Accuracy 0.9375\n",
      "Epoch: 3, Batch: 280/313, Loss: 1.5311081409454346, Running Accuracy: 0.9332068690095847, Current Accuracy 1.0\n",
      "Epoch: 3, Batch: 281/313, Loss: 1.5581693649291992, Running Accuracy: 0.9330214968152867, Current Accuracy 0.875\n",
      "Epoch: 3, Test Accuracy: 0.96875\n",
      "Epoch: 3, Test Accuracy: 0.953125\n",
      "Epoch: 3, Test Accuracy: 0.9270833333333334\n",
      "Epoch: 3, Test Accuracy: 0.90625\n",
      "Epoch: 3, Test Accuracy: 0.91875\n",
      "Epoch: 3, Test Accuracy: 0.9114583333333334\n",
      "Epoch: 3, Test Accuracy: 0.9017857142857143\n",
      "Epoch: 3, Test Accuracy: 0.90625\n",
      "Epoch: 3, Test Accuracy: 0.8993055555555556\n",
      "Epoch: 3, Test Accuracy: 0.903125\n",
      "Epoch: 3, Test Accuracy: 0.9034090909090909\n",
      "Epoch: 3, Test Accuracy: 0.90625\n",
      "Epoch: 3, Test Accuracy: 0.90625\n",
      "Epoch: 3, Test Accuracy: 0.9107142857142857\n",
      "Epoch: 3, Test Accuracy: 0.9125\n",
      "Epoch: 3, Test Accuracy: 0.90625\n",
      "Epoch: 3, Test Accuracy: 0.9099264705882353\n",
      "Epoch: 3, Test Accuracy: 0.90625\n",
      "Epoch: 3, Test Accuracy: 0.9078947368421053\n",
      "Epoch: 3, Test Accuracy: 0.9109375\n",
      "Epoch: 3, Test Accuracy: 0.9107142857142857\n",
      "Epoch: 3, Test Accuracy: 0.9119318181818182\n",
      "Epoch: 3, Test Accuracy: 0.9130434782608695\n",
      "Epoch: 3, Test Accuracy: 0.9114583333333334\n",
      "Epoch: 3, Test Accuracy: 0.9075\n",
      "Epoch: 3, Test Accuracy: 0.9074519230769231\n",
      "Epoch: 3, Test Accuracy: 0.9097222222222222\n",
      "Epoch: 3, Test Accuracy: 0.9107142857142857\n",
      "Epoch: 3, Test Accuracy: 0.9084051724137931\n",
      "Epoch: 3, Test Accuracy: 0.909375\n",
      "Epoch: 3, Test Accuracy: 0.9082661290322581\n",
      "Epoch: 3, Test Accuracy: 0.9072265625\n",
      "Epoch: 4, Batch: 0/313, Loss: 1.5462685823440552, Running Accuracy: 0.9081439393939394, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 1/313, Loss: 1.5442074537277222, Running Accuracy: 0.9099264705882353, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 2/313, Loss: 1.4783363342285156, Running Accuracy: 0.9125, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 3/313, Loss: 1.4841079711914062, Running Accuracy: 0.9149305555555556, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 4/313, Loss: 1.5445168018341064, Running Accuracy: 0.9146959459459459, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 5/313, Loss: 1.5885335206985474, Running Accuracy: 0.9144736842105263, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 6/313, Loss: 1.5169072151184082, Running Accuracy: 0.9158653846153846, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 7/313, Loss: 1.4855670928955078, Running Accuracy: 0.91796875, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 8/313, Loss: 1.5121275186538696, Running Accuracy: 0.9192073170731707, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 9/313, Loss: 1.520337700843811, Running Accuracy: 0.9203869047619048, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 10/313, Loss: 1.5442759990692139, Running Accuracy: 0.9207848837209303, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 11/313, Loss: 1.530372142791748, Running Accuracy: 0.9211647727272727, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 12/313, Loss: 1.5517085790634155, Running Accuracy: 0.9215277777777777, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 13/313, Loss: 1.5766009092330933, Running Accuracy: 0.9211956521739131, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 14/313, Loss: 1.5283408164978027, Running Accuracy: 0.9222074468085106, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 15/313, Loss: 1.4965977668762207, Running Accuracy: 0.9231770833333334, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 16/313, Loss: 1.5628199577331543, Running Accuracy: 0.923469387755102, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 17/313, Loss: 1.5783414840698242, Running Accuracy: 0.923125, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 18/313, Loss: 1.5161340236663818, Running Accuracy: 0.9240196078431373, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 19/313, Loss: 1.5832176208496094, Running Accuracy: 0.9230769230769231, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 20/313, Loss: 1.5131354331970215, Running Accuracy: 0.9239386792452831, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 21/313, Loss: 1.5164203643798828, Running Accuracy: 0.9247685185185185, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 22/313, Loss: 1.53996741771698, Running Accuracy: 0.9255681818181818, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 23/313, Loss: 1.5147948265075684, Running Accuracy: 0.9268973214285714, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 24/313, Loss: 1.547313928604126, Running Accuracy: 0.9276315789473685, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 25/313, Loss: 1.5082377195358276, Running Accuracy: 0.9283405172413793, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 26/313, Loss: 1.5464997291564941, Running Accuracy: 0.9284957627118644, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 27/313, Loss: 1.5317063331604004, Running Accuracy: 0.9291666666666667, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 28/313, Loss: 1.4948900938034058, Running Accuracy: 0.930327868852459, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 29/313, Loss: 1.6145122051239014, Running Accuracy: 0.9294354838709677, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 30/313, Loss: 1.5214283466339111, Running Accuracy: 0.9300595238095238, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 31/313, Loss: 1.4886940717697144, Running Accuracy: 0.93115234375, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 32/313, Loss: 1.575896978378296, Running Accuracy: 0.93125, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 33/313, Loss: 1.5591586828231812, Running Accuracy: 0.931344696969697, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 34/313, Loss: 1.5252034664154053, Running Accuracy: 0.9314365671641791, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 35/313, Loss: 1.4999030828475952, Running Accuracy: 0.9324448529411765, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 36/313, Loss: 1.5045822858810425, Running Accuracy: 0.9334239130434783, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 37/313, Loss: 1.564107060432434, Running Accuracy: 0.9330357142857143, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 38/313, Loss: 1.6569592952728271, Running Accuracy: 0.9313380281690141, Current Accuracy 0.8125\n",
      "Epoch: 4, Batch: 39/313, Loss: 1.5327684879302979, Running Accuracy: 0.9318576388888888, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 40/313, Loss: 1.564612627029419, Running Accuracy: 0.9319349315068494, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 41/313, Loss: 1.554986834526062, Running Accuracy: 0.9315878378378378, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 42/313, Loss: 1.5172797441482544, Running Accuracy: 0.9316666666666666, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 43/313, Loss: 1.6036115884780884, Running Accuracy: 0.930921052631579, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 44/313, Loss: 1.6101199388504028, Running Accuracy: 0.929788961038961, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 45/313, Loss: 1.5748693943023682, Running Accuracy: 0.9294871794871795, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 46/313, Loss: 1.5685447454452515, Running Accuracy: 0.9291930379746836, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 47/313, Loss: 1.4933152198791504, Running Accuracy: 0.9296875, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 48/313, Loss: 1.5371912717819214, Running Accuracy: 0.9297839506172839, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 49/313, Loss: 1.5173852443695068, Running Accuracy: 0.9302591463414634, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 50/313, Loss: 1.5498507022857666, Running Accuracy: 0.9307228915662651, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 51/313, Loss: 1.5311683416366577, Running Accuracy: 0.9311755952380952, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 52/313, Loss: 1.6388287544250488, Running Accuracy: 0.9297794117647059, Current Accuracy 0.8125\n",
      "Epoch: 4, Batch: 53/313, Loss: 1.5529999732971191, Running Accuracy: 0.9298691860465116, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 54/313, Loss: 1.564483404159546, Running Accuracy: 0.9299568965517241, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 55/313, Loss: 1.588535189628601, Running Accuracy: 0.9293323863636364, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 56/313, Loss: 1.5344579219818115, Running Accuracy: 0.9297752808988764, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 57/313, Loss: 1.5837440490722656, Running Accuracy: 0.9295138888888889, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 58/313, Loss: 1.5450413227081299, Running Accuracy: 0.9292582417582418, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 59/313, Loss: 1.5328779220581055, Running Accuracy: 0.9293478260869565, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 60/313, Loss: 1.5639547109603882, Running Accuracy: 0.9294354838709677, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 61/313, Loss: 1.5568360090255737, Running Accuracy: 0.929188829787234, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 62/313, Loss: 1.5333276987075806, Running Accuracy: 0.9292763157894737, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 63/313, Loss: 1.5199846029281616, Running Accuracy: 0.9293619791666666, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 64/313, Loss: 1.653442621231079, Running Accuracy: 0.9281572164948454, Current Accuracy 0.8125\n",
      "Epoch: 4, Batch: 65/313, Loss: 1.592393159866333, Running Accuracy: 0.9276147959183674, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 66/313, Loss: 1.502198576927185, Running Accuracy: 0.928030303030303, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 67/313, Loss: 1.5044920444488525, Running Accuracy: 0.9284375, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 68/313, Loss: 1.505411982536316, Running Accuracy: 0.9291460396039604, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 69/313, Loss: 1.578355073928833, Running Accuracy: 0.9292279411764706, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 70/313, Loss: 1.4967302083969116, Running Accuracy: 0.9299150485436893, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 71/313, Loss: 1.5709656476974487, Running Accuracy: 0.9293870192307693, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 72/313, Loss: 1.5293684005737305, Running Accuracy: 0.9297619047619048, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 73/313, Loss: 1.5505565404891968, Running Accuracy: 0.9298349056603774, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 74/313, Loss: 1.5862523317337036, Running Accuracy: 0.9299065420560748, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 75/313, Loss: 1.5322413444519043, Running Accuracy: 0.9302662037037037, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 76/313, Loss: 1.532407283782959, Running Accuracy: 0.9306192660550459, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 77/313, Loss: 1.5920324325561523, Running Accuracy: 0.9298295454545454, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 78/313, Loss: 1.582837462425232, Running Accuracy: 0.9293355855855856, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 79/313, Loss: 1.481360673904419, Running Accuracy: 0.9299665178571429, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 80/313, Loss: 1.513064980506897, Running Accuracy: 0.9303097345132744, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 81/313, Loss: 1.4957020282745361, Running Accuracy: 0.930921052631579, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 82/313, Loss: 1.5497195720672607, Running Accuracy: 0.9309782608695653, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 83/313, Loss: 1.5063050985336304, Running Accuracy: 0.9313038793103449, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 84/313, Loss: 1.5366930961608887, Running Accuracy: 0.9313568376068376, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 85/313, Loss: 1.5486828088760376, Running Accuracy: 0.9314088983050848, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 86/313, Loss: 1.4942097663879395, Running Accuracy: 0.9317226890756303, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 87/313, Loss: 1.4836513996124268, Running Accuracy: 0.9322916666666666, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 88/313, Loss: 1.5076481103897095, Running Accuracy: 0.9325929752066116, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 89/313, Loss: 1.5897951126098633, Running Accuracy: 0.9323770491803278, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 90/313, Loss: 1.538581132888794, Running Accuracy: 0.9326727642276422, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 91/313, Loss: 1.560477375984192, Running Accuracy: 0.9324596774193549, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 92/313, Loss: 1.527199149131775, Running Accuracy: 0.93275, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 93/313, Loss: 1.5428872108459473, Running Accuracy: 0.9327876984126984, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 94/313, Loss: 1.501797080039978, Running Accuracy: 0.9330708661417323, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 95/313, Loss: 1.5225858688354492, Running Accuracy: 0.93310546875, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 96/313, Loss: 1.5365135669708252, Running Accuracy: 0.9333817829457365, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 97/313, Loss: 1.5147770643234253, Running Accuracy: 0.9336538461538462, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 98/313, Loss: 1.5040801763534546, Running Accuracy: 0.9341603053435115, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 99/313, Loss: 1.5713540315628052, Running Accuracy: 0.9341856060606061, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 100/313, Loss: 1.574377179145813, Running Accuracy: 0.9339755639097744, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 101/313, Loss: 1.5458858013153076, Running Accuracy: 0.9340018656716418, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 102/313, Loss: 1.542114019393921, Running Accuracy: 0.9337962962962963, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 103/313, Loss: 1.517203688621521, Running Accuracy: 0.9340533088235294, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 104/313, Loss: 1.5213351249694824, Running Accuracy: 0.9343065693430657, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 105/313, Loss: 1.5149656534194946, Running Accuracy: 0.9345561594202898, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 106/313, Loss: 1.4717787504196167, Running Accuracy: 0.9350269784172662, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 107/313, Loss: 1.5607433319091797, Running Accuracy: 0.9350446428571428, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 108/313, Loss: 1.5896769762039185, Running Accuracy: 0.9346187943262412, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 109/313, Loss: 1.5272966623306274, Running Accuracy: 0.9348591549295775, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 110/313, Loss: 1.5579259395599365, Running Accuracy: 0.9346590909090909, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 111/313, Loss: 1.549161672592163, Running Accuracy: 0.9344618055555556, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 112/313, Loss: 1.5236902236938477, Running Accuracy: 0.9344827586206896, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 113/313, Loss: 1.5569080114364624, Running Accuracy: 0.9345034246575342, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 114/313, Loss: 1.5393576622009277, Running Accuracy: 0.9347363945578231, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 115/313, Loss: 1.5326677560806274, Running Accuracy: 0.9349662162162162, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 116/313, Loss: 1.546941876411438, Running Accuracy: 0.93498322147651, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 117/313, Loss: 1.4800585508346558, Running Accuracy: 0.9354166666666667, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 118/313, Loss: 1.5980098247528076, Running Accuracy: 0.9350165562913907, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 119/313, Loss: 1.521639108657837, Running Accuracy: 0.9352384868421053, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 120/313, Loss: 1.5611374378204346, Running Accuracy: 0.9350490196078431, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 121/313, Loss: 1.596793532371521, Running Accuracy: 0.9344561688311688, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 122/313, Loss: 1.5434002876281738, Running Accuracy: 0.9344758064516129, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 123/313, Loss: 1.5470060110092163, Running Accuracy: 0.9342948717948718, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 124/313, Loss: 1.5342459678649902, Running Accuracy: 0.9345143312101911, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 125/313, Loss: 1.5211820602416992, Running Accuracy: 0.9347310126582279, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 126/313, Loss: 1.5469794273376465, Running Accuracy: 0.934748427672956, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 127/313, Loss: 1.5676159858703613, Running Accuracy: 0.9345703125, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 128/313, Loss: 1.5218983888626099, Running Accuracy: 0.9347826086956522, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 129/313, Loss: 1.5127198696136475, Running Accuracy: 0.9349922839506173, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 130/313, Loss: 1.6033965349197388, Running Accuracy: 0.9344325153374233, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 131/313, Loss: 1.5364494323730469, Running Accuracy: 0.934641768292683, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 132/313, Loss: 1.6141878366470337, Running Accuracy: 0.9340909090909091, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 133/313, Loss: 1.4800593852996826, Running Accuracy: 0.9344879518072289, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 134/313, Loss: 1.5514787435531616, Running Accuracy: 0.9345059880239521, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 135/313, Loss: 1.512524127960205, Running Accuracy: 0.9347098214285714, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 136/313, Loss: 1.5573339462280273, Running Accuracy: 0.9347263313609467, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 137/313, Loss: 1.6449633836746216, Running Accuracy: 0.9340073529411764, Current Accuracy 0.8125\n",
      "Epoch: 4, Batch: 138/313, Loss: 1.476898193359375, Running Accuracy: 0.9343932748538012, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 139/313, Loss: 1.5444563627243042, Running Accuracy: 0.9342296511627907, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 140/313, Loss: 1.558458924293518, Running Accuracy: 0.9342485549132948, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 141/313, Loss: 1.4700466394424438, Running Accuracy: 0.9346264367816092, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 142/313, Loss: 1.4830965995788574, Running Accuracy: 0.935, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 143/313, Loss: 1.483241081237793, Running Accuracy: 0.9353693181818182, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 144/313, Loss: 1.5997999906539917, Running Accuracy: 0.935204802259887, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 145/313, Loss: 1.5865854024887085, Running Accuracy: 0.9350421348314607, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 146/313, Loss: 1.5418604612350464, Running Accuracy: 0.9350558659217877, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 147/313, Loss: 1.5001064538955688, Running Accuracy: 0.9354166666666667, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 148/313, Loss: 1.4774245023727417, Running Accuracy: 0.9357734806629834, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 149/313, Loss: 1.4871037006378174, Running Accuracy: 0.9361263736263736, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 150/313, Loss: 1.5578292608261108, Running Accuracy: 0.9359631147540983, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 151/313, Loss: 1.5828416347503662, Running Accuracy: 0.9356317934782609, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 152/313, Loss: 1.5528331995010376, Running Accuracy: 0.9356418918918918, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 153/313, Loss: 1.5015469789505005, Running Accuracy: 0.9359879032258065, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 154/313, Loss: 1.4848144054412842, Running Accuracy: 0.9363302139037433, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 155/313, Loss: 1.5325772762298584, Running Accuracy: 0.9363364361702128, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 156/313, Loss: 1.6075329780578613, Running Accuracy: 0.9360119047619048, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 157/313, Loss: 1.5273798704147339, Running Accuracy: 0.9360197368421053, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 158/313, Loss: 1.5241812467575073, Running Accuracy: 0.9360274869109948, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 159/313, Loss: 1.5200796127319336, Running Accuracy: 0.93603515625, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 160/313, Loss: 1.6038780212402344, Running Accuracy: 0.9357189119170984, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 161/313, Loss: 1.532929539680481, Running Accuracy: 0.9357280927835051, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 162/313, Loss: 1.5124049186706543, Running Accuracy: 0.9358974358974359, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 163/313, Loss: 1.526790976524353, Running Accuracy: 0.9360650510204082, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 164/313, Loss: 1.4992930889129639, Running Accuracy: 0.936230964467005, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 165/313, Loss: 1.5389171838760376, Running Accuracy: 0.936395202020202, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 166/313, Loss: 1.575332522392273, Running Accuracy: 0.9362437185929648, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 167/313, Loss: 1.5219449996948242, Running Accuracy: 0.93625, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 168/313, Loss: 1.5718039274215698, Running Accuracy: 0.9359452736318408, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 169/313, Loss: 1.56718909740448, Running Accuracy: 0.9359529702970297, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 170/313, Loss: 1.5346827507019043, Running Accuracy: 0.9361145320197044, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 171/313, Loss: 1.4781855344772339, Running Accuracy: 0.9364276960784313, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 172/313, Loss: 1.4842058420181274, Running Accuracy: 0.9367378048780488, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 173/313, Loss: 1.5347083806991577, Running Accuracy: 0.9367415048543689, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 174/313, Loss: 1.5139042139053345, Running Accuracy: 0.9368961352657005, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 175/313, Loss: 1.5852253437042236, Running Accuracy: 0.9367487980769231, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 176/313, Loss: 1.5007827281951904, Running Accuracy: 0.9370514354066986, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 177/313, Loss: 1.5326718091964722, Running Accuracy: 0.937202380952381, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 178/313, Loss: 1.5257434844970703, Running Accuracy: 0.9372037914691943, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 179/313, Loss: 1.5222314596176147, Running Accuracy: 0.9375, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 180/313, Loss: 1.5021538734436035, Running Accuracy: 0.9376467136150235, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 181/313, Loss: 1.5148539543151855, Running Accuracy: 0.9377920560747663, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 182/313, Loss: 1.5505406856536865, Running Accuracy: 0.9376453488372093, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 183/313, Loss: 1.4865957498550415, Running Accuracy: 0.9379340277777778, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 184/313, Loss: 1.5014846324920654, Running Accuracy: 0.9380760368663594, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 185/313, Loss: 1.5433388948440552, Running Accuracy: 0.9380733944954128, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 186/313, Loss: 1.5160044431686401, Running Accuracy: 0.9382134703196348, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 187/313, Loss: 1.5646986961364746, Running Accuracy: 0.9382102272727273, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 188/313, Loss: 1.565278172492981, Running Accuracy: 0.9380656108597285, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 189/313, Loss: 1.6045655012130737, Running Accuracy: 0.9377815315315315, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 190/313, Loss: 1.6505053043365479, Running Accuracy: 0.9372197309417041, Current Accuracy 0.8125\n",
      "Epoch: 4, Batch: 191/313, Loss: 1.4915919303894043, Running Accuracy: 0.9375, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 192/313, Loss: 1.6393755674362183, Running Accuracy: 0.9369444444444445, Current Accuracy 0.8125\n",
      "Epoch: 4, Batch: 193/313, Loss: 1.5636271238327026, Running Accuracy: 0.936808628318584, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 194/313, Loss: 1.5234555006027222, Running Accuracy: 0.9370870044052864, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 195/313, Loss: 1.5292209386825562, Running Accuracy: 0.9372258771929824, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 196/313, Loss: 1.5999056100845337, Running Accuracy: 0.9369541484716157, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 197/313, Loss: 1.6200414896011353, Running Accuracy: 0.9366847826086957, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 198/313, Loss: 1.628174066543579, Running Accuracy: 0.9364177489177489, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 199/313, Loss: 1.4904189109802246, Running Accuracy: 0.9366918103448276, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 200/313, Loss: 1.5423736572265625, Running Accuracy: 0.9368293991416309, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 201/313, Loss: 1.5217758417129517, Running Accuracy: 0.936965811965812, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 202/313, Loss: 1.5827960968017578, Running Accuracy: 0.9368351063829787, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 203/313, Loss: 1.4937121868133545, Running Accuracy: 0.9371027542372882, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 204/313, Loss: 1.4834449291229248, Running Accuracy: 0.9373681434599156, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 205/313, Loss: 1.4853508472442627, Running Accuracy: 0.9376313025210085, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 206/313, Loss: 1.4887062311172485, Running Accuracy: 0.9378922594142259, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 207/313, Loss: 1.5090293884277344, Running Accuracy: 0.9380208333333333, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 208/313, Loss: 1.5353230237960815, Running Accuracy: 0.9380186721991701, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 209/313, Loss: 1.5599931478500366, Running Accuracy: 0.9378873966942148, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 210/313, Loss: 1.551486849784851, Running Accuracy: 0.9378858024691358, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 211/313, Loss: 1.5200107097625732, Running Accuracy: 0.9378842213114754, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 212/313, Loss: 1.5079138278961182, Running Accuracy: 0.9380102040816326, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 213/313, Loss: 1.6206361055374146, Running Accuracy: 0.9376270325203252, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 214/313, Loss: 1.4911125898361206, Running Accuracy: 0.9378795546558705, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 215/313, Loss: 1.6021937131881714, Running Accuracy: 0.9375, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 216/313, Loss: 1.5637681484222412, Running Accuracy: 0.9373744979919679, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 217/313, Loss: 1.526074767112732, Running Accuracy: 0.9375, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 218/313, Loss: 1.5499625205993652, Running Accuracy: 0.9375, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 219/313, Loss: 1.5417759418487549, Running Accuracy: 0.9376240079365079, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 220/313, Loss: 1.521398663520813, Running Accuracy: 0.9377470355731226, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 221/313, Loss: 1.506766438484192, Running Accuracy: 0.937746062992126, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 222/313, Loss: 1.4824668169021606, Running Accuracy: 0.9379901960784314, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 223/313, Loss: 1.5254634618759155, Running Accuracy: 0.93798828125, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 224/313, Loss: 1.5340971946716309, Running Accuracy: 0.9379863813229572, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 225/313, Loss: 1.5003248453140259, Running Accuracy: 0.9381056201550387, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 226/313, Loss: 1.5011351108551025, Running Accuracy: 0.9382239382239382, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 227/313, Loss: 1.552700400352478, Running Accuracy: 0.9381009615384616, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 228/313, Loss: 1.5370639562606812, Running Accuracy: 0.9382183908045977, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 229/313, Loss: 1.521716833114624, Running Accuracy: 0.9383349236641222, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 230/313, Loss: 1.5347955226898193, Running Accuracy: 0.9383317490494296, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 231/313, Loss: 1.4899158477783203, Running Accuracy: 0.9385653409090909, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 232/313, Loss: 1.5192826986312866, Running Accuracy: 0.9386792452830188, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 233/313, Loss: 1.5056720972061157, Running Accuracy: 0.9387922932330827, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 234/313, Loss: 1.5441416501998901, Running Accuracy: 0.9387874531835206, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 235/313, Loss: 1.5645896196365356, Running Accuracy: 0.9386660447761194, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 236/313, Loss: 1.5325963497161865, Running Accuracy: 0.9387778810408922, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 237/313, Loss: 1.5298116207122803, Running Accuracy: 0.9387731481481482, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 238/313, Loss: 1.5788013935089111, Running Accuracy: 0.9386531365313653, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 239/313, Loss: 1.488267183303833, Running Accuracy: 0.9388786764705882, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 240/313, Loss: 1.5118141174316406, Running Accuracy: 0.9391025641025641, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 241/313, Loss: 1.5435736179351807, Running Accuracy: 0.9390967153284672, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 242/313, Loss: 1.5127780437469482, Running Accuracy: 0.9392045454545455, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 243/313, Loss: 1.515690803527832, Running Accuracy: 0.9393115942028986, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 244/313, Loss: 1.545841097831726, Running Accuracy: 0.9393050541516246, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 245/313, Loss: 1.5640923976898193, Running Accuracy: 0.9392985611510791, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 246/313, Loss: 1.5097382068634033, Running Accuracy: 0.9394041218637993, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 247/313, Loss: 1.5200191736221313, Running Accuracy: 0.9395089285714285, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 248/313, Loss: 1.5847277641296387, Running Accuracy: 0.9395017793594306, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 249/313, Loss: 1.5239406824111938, Running Accuracy: 0.9396054964539007, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 250/313, Loss: 1.5092607736587524, Running Accuracy: 0.939708480565371, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 251/313, Loss: 1.4965342283248901, Running Accuracy: 0.9399207746478874, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 252/313, Loss: 1.5142126083374023, Running Accuracy: 0.9400219298245615, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 253/313, Loss: 1.5724451541900635, Running Accuracy: 0.9399038461538461, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 254/313, Loss: 1.5472919940948486, Running Accuracy: 0.9398954703832753, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 255/313, Loss: 1.5288923978805542, Running Accuracy: 0.9399956597222222, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 256/313, Loss: 1.4801095724105835, Running Accuracy: 0.9402032871972318, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 257/313, Loss: 1.5231162309646606, Running Accuracy: 0.940301724137931, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 258/313, Loss: 1.6040314435958862, Running Accuracy: 0.9400773195876289, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 259/313, Loss: 1.5987179279327393, Running Accuracy: 0.9398544520547946, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 260/313, Loss: 1.5281431674957275, Running Accuracy: 0.939953071672355, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 261/313, Loss: 1.5694775581359863, Running Accuracy: 0.9399447278911565, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 262/313, Loss: 1.5160199403762817, Running Accuracy: 0.940042372881356, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 263/313, Loss: 1.5345094203948975, Running Accuracy: 0.9400337837837838, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 264/313, Loss: 1.575698971748352, Running Accuracy: 0.9399200336700336, Current Accuracy 0.90625\n",
      "Epoch: 4, Batch: 265/313, Loss: 1.5189779996871948, Running Accuracy: 0.94001677852349, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 266/313, Loss: 1.5464324951171875, Running Accuracy: 0.9400083612040134, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 267/313, Loss: 1.6021201610565186, Running Accuracy: 0.9397916666666667, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 268/313, Loss: 1.4743926525115967, Running Accuracy: 0.9399916943521595, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 269/313, Loss: 1.4794033765792847, Running Accuracy: 0.9401903973509934, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 270/313, Loss: 1.528889775276184, Running Accuracy: 0.9401815181518152, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 271/313, Loss: 1.534178376197815, Running Accuracy: 0.940172697368421, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 272/313, Loss: 1.552549123764038, Running Accuracy: 0.940266393442623, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 273/313, Loss: 1.5487782955169678, Running Accuracy: 0.9402573529411765, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 274/313, Loss: 1.6014100313186646, Running Accuracy: 0.939942996742671, Current Accuracy 0.84375\n",
      "Epoch: 4, Batch: 275/313, Loss: 1.570624828338623, Running Accuracy: 0.9397321428571429, Current Accuracy 0.875\n",
      "Epoch: 4, Batch: 276/313, Loss: 1.5109912157058716, Running Accuracy: 0.9398260517799353, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 277/313, Loss: 1.506946086883545, Running Accuracy: 0.9399193548387097, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 278/313, Loss: 1.5464926958084106, Running Accuracy: 0.939911575562701, Current Accuracy 0.9375\n",
      "Epoch: 4, Batch: 279/313, Loss: 1.5023514032363892, Running Accuracy: 0.9401041666666666, Current Accuracy 1.0\n",
      "Epoch: 4, Batch: 280/313, Loss: 1.5138758420944214, Running Accuracy: 0.9401956869009584, Current Accuracy 0.96875\n",
      "Epoch: 4, Batch: 281/313, Loss: 1.4683635234832764, Running Accuracy: 0.9403861464968153, Current Accuracy 1.0\n",
      "Epoch: 4, Test Accuracy: 0.90625\n",
      "Epoch: 4, Test Accuracy: 0.9375\n",
      "Epoch: 4, Test Accuracy: 0.9375\n",
      "Epoch: 4, Test Accuracy: 0.921875\n",
      "Epoch: 4, Test Accuracy: 0.93125\n",
      "Epoch: 4, Test Accuracy: 0.921875\n",
      "Epoch: 4, Test Accuracy: 0.9151785714285714\n",
      "Epoch: 4, Test Accuracy: 0.8984375\n",
      "Epoch: 4, Test Accuracy: 0.90625\n",
      "Epoch: 4, Test Accuracy: 0.9125\n",
      "Epoch: 4, Test Accuracy: 0.8977272727272727\n",
      "Epoch: 4, Test Accuracy: 0.8958333333333334\n",
      "Epoch: 4, Test Accuracy: 0.8990384615384616\n",
      "Epoch: 4, Test Accuracy: 0.8973214285714286\n",
      "Epoch: 4, Test Accuracy: 0.9020833333333333\n",
      "Epoch: 4, Test Accuracy: 0.904296875\n",
      "Epoch: 4, Test Accuracy: 0.8988970588235294\n",
      "Epoch: 4, Test Accuracy: 0.8993055555555556\n",
      "Epoch: 4, Test Accuracy: 0.9029605263157895\n",
      "Epoch: 4, Test Accuracy: 0.9046875\n",
      "Epoch: 4, Test Accuracy: 0.90625\n",
      "Epoch: 4, Test Accuracy: 0.90625\n",
      "Epoch: 4, Test Accuracy: 0.9089673913043478\n",
      "Epoch: 4, Test Accuracy: 0.91015625\n",
      "Epoch: 4, Test Accuracy: 0.91125\n",
      "Epoch: 4, Test Accuracy: 0.9098557692307693\n",
      "Epoch: 4, Test Accuracy: 0.9097222222222222\n",
      "Epoch: 4, Test Accuracy: 0.9084821428571429\n",
      "Epoch: 4, Test Accuracy: 0.9084051724137931\n",
      "Epoch: 4, Test Accuracy: 0.9083333333333333\n",
      "Epoch: 4, Test Accuracy: 0.9082661290322581\n",
      "Epoch: 4, Test Accuracy: 0.9072265625\n",
      "Epoch: 5, Batch: 0/313, Loss: 1.4967763423919678, Running Accuracy: 0.9100378787878788, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 1/313, Loss: 1.4769400358200073, Running Accuracy: 0.9126838235294118, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 2/313, Loss: 1.5252124071121216, Running Accuracy: 0.9142857142857143, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 3/313, Loss: 1.5579133033752441, Running Accuracy: 0.9140625, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 4/313, Loss: 1.5212905406951904, Running Accuracy: 0.9146959459459459, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 5/313, Loss: 1.4871059656143188, Running Accuracy: 0.9169407894736842, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 6/313, Loss: 1.4946610927581787, Running Accuracy: 0.9182692307692307, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 7/313, Loss: 1.5457106828689575, Running Accuracy: 0.91875, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 8/313, Loss: 1.526686668395996, Running Accuracy: 0.9199695121951219, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 9/313, Loss: 1.5134942531585693, Running Accuracy: 0.9211309523809523, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 10/313, Loss: 1.4869962930679321, Running Accuracy: 0.9229651162790697, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 11/313, Loss: 1.4894955158233643, Running Accuracy: 0.9247159090909091, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 12/313, Loss: 1.5222562551498413, Running Accuracy: 0.9256944444444445, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 13/313, Loss: 1.5500867366790771, Running Accuracy: 0.9259510869565217, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 14/313, Loss: 1.480073094367981, Running Accuracy: 0.9275265957446809, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 15/313, Loss: 1.563029170036316, Running Accuracy: 0.9270833333333334, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 16/313, Loss: 1.5469290018081665, Running Accuracy: 0.9272959183673469, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 17/313, Loss: 1.502863883972168, Running Accuracy: 0.928125, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 18/313, Loss: 1.5202187299728394, Running Accuracy: 0.928921568627451, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 19/313, Loss: 1.608500361442566, Running Accuracy: 0.9278846153846154, Current Accuracy 0.875\n",
      "Epoch: 5, Batch: 20/313, Loss: 1.5359528064727783, Running Accuracy: 0.9286556603773585, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 21/313, Loss: 1.517619252204895, Running Accuracy: 0.9293981481481481, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 22/313, Loss: 1.5842652320861816, Running Accuracy: 0.9289772727272727, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 23/313, Loss: 1.5922268629074097, Running Accuracy: 0.9280133928571429, Current Accuracy 0.875\n",
      "Epoch: 5, Batch: 24/313, Loss: 1.5350967645645142, Running Accuracy: 0.9281798245614035, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 25/313, Loss: 1.5659056901931763, Running Accuracy: 0.927801724137931, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 26/313, Loss: 1.4777036905288696, Running Accuracy: 0.9290254237288136, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 27/313, Loss: 1.5605388879776, Running Accuracy: 0.9286458333333333, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 28/313, Loss: 1.5674808025360107, Running Accuracy: 0.9282786885245902, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 29/313, Loss: 1.4868601560592651, Running Accuracy: 0.9294354838709677, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 30/313, Loss: 1.4941884279251099, Running Accuracy: 0.9300595238095238, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 31/313, Loss: 1.5994631052017212, Running Accuracy: 0.92919921875, Current Accuracy 0.875\n",
      "Epoch: 5, Batch: 32/313, Loss: 1.5743041038513184, Running Accuracy: 0.9288461538461539, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 33/313, Loss: 1.535905122756958, Running Accuracy: 0.9294507575757576, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 34/313, Loss: 1.5195213556289673, Running Accuracy: 0.9300373134328358, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 35/313, Loss: 1.4802579879760742, Running Accuracy: 0.9310661764705882, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 36/313, Loss: 1.4947764873504639, Running Accuracy: 0.9316123188405797, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 37/313, Loss: 1.556756615638733, Running Accuracy: 0.93125, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 38/313, Loss: 1.4773744344711304, Running Accuracy: 0.9322183098591549, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 39/313, Loss: 1.518981695175171, Running Accuracy: 0.9327256944444444, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 40/313, Loss: 1.523445963859558, Running Accuracy: 0.9332191780821918, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 41/313, Loss: 1.4949719905853271, Running Accuracy: 0.9341216216216216, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 42/313, Loss: 1.4832748174667358, Running Accuracy: 0.935, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 43/313, Loss: 1.5413694381713867, Running Accuracy: 0.9350328947368421, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 44/313, Loss: 1.545372486114502, Running Accuracy: 0.935064935064935, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 45/313, Loss: 1.574236273765564, Running Accuracy: 0.9346955128205128, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 46/313, Loss: 1.5515133142471313, Running Accuracy: 0.9347310126582279, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 47/313, Loss: 1.4976518154144287, Running Accuracy: 0.935546875, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 48/313, Loss: 1.574191927909851, Running Accuracy: 0.9351851851851852, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 49/313, Loss: 1.5127979516983032, Running Accuracy: 0.9355945121951219, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 50/313, Loss: 1.5682791471481323, Running Accuracy: 0.9356174698795181, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 51/313, Loss: 1.4918755292892456, Running Accuracy: 0.9360119047619048, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 52/313, Loss: 1.4892346858978271, Running Accuracy: 0.9367647058823529, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 53/313, Loss: 1.5241767168045044, Running Accuracy: 0.9367732558139535, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 54/313, Loss: 1.521924376487732, Running Accuracy: 0.9371408045977011, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 55/313, Loss: 1.5197806358337402, Running Accuracy: 0.9375, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 56/313, Loss: 1.502697467803955, Running Accuracy: 0.9378511235955056, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 57/313, Loss: 1.4983067512512207, Running Accuracy: 0.9385416666666667, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 58/313, Loss: 1.4918837547302246, Running Accuracy: 0.9388736263736264, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 59/313, Loss: 1.474171757698059, Running Accuracy: 0.9395380434782609, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 60/313, Loss: 1.4779669046401978, Running Accuracy: 0.9401881720430108, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 61/313, Loss: 1.5339093208312988, Running Accuracy: 0.9401595744680851, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 62/313, Loss: 1.4904861450195312, Running Accuracy: 0.9407894736842105, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 63/313, Loss: 1.5319983959197998, Running Accuracy: 0.9407552083333334, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 64/313, Loss: 1.5376193523406982, Running Accuracy: 0.9407216494845361, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 65/313, Loss: 1.5544120073318481, Running Accuracy: 0.9406887755102041, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 66/313, Loss: 1.5178121328353882, Running Accuracy: 0.9409722222222222, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 67/313, Loss: 1.5079461336135864, Running Accuracy: 0.94125, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 68/313, Loss: 1.547996997833252, Running Accuracy: 0.9412128712871287, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 69/313, Loss: 1.5216304063796997, Running Accuracy: 0.9414828431372549, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 70/313, Loss: 1.49515700340271, Running Accuracy: 0.9420509708737864, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 71/313, Loss: 1.541561484336853, Running Accuracy: 0.9420072115384616, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 72/313, Loss: 1.562833547592163, Running Accuracy: 0.9422619047619047, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 73/313, Loss: 1.4775201082229614, Running Accuracy: 0.9428066037735849, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 74/313, Loss: 1.486159324645996, Running Accuracy: 0.9433411214953271, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 75/313, Loss: 1.5008273124694824, Running Accuracy: 0.9435763888888888, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 76/313, Loss: 1.5553181171417236, Running Accuracy: 0.9432339449541285, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 77/313, Loss: 1.49954354763031, Running Accuracy: 0.94375, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 78/313, Loss: 1.4959957599639893, Running Accuracy: 0.9439752252252253, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 79/313, Loss: 1.5101264715194702, Running Accuracy: 0.9444754464285714, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 80/313, Loss: 1.5175203084945679, Running Accuracy: 0.9446902654867256, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 81/313, Loss: 1.5747185945510864, Running Accuracy: 0.9443530701754386, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 82/313, Loss: 1.5028231143951416, Running Accuracy: 0.9448369565217392, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 83/313, Loss: 1.5210295915603638, Running Accuracy: 0.9450431034482759, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 84/313, Loss: 1.4714689254760742, Running Accuracy: 0.9455128205128205, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 85/313, Loss: 1.5422964096069336, Running Accuracy: 0.9454449152542372, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 86/313, Loss: 1.545817255973816, Running Accuracy: 0.9453781512605042, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 87/313, Loss: 1.4866102933883667, Running Accuracy: 0.9458333333333333, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 88/313, Loss: 1.5601109266281128, Running Accuracy: 0.9457644628099173, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 89/313, Loss: 1.52044677734375, Running Accuracy: 0.945952868852459, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 90/313, Loss: 1.5273573398590088, Running Accuracy: 0.9461382113821138, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 91/313, Loss: 1.5052335262298584, Running Accuracy: 0.946320564516129, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 92/313, Loss: 1.5489909648895264, Running Accuracy: 0.9465, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 93/313, Loss: 1.5634539127349854, Running Accuracy: 0.9461805555555556, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 94/313, Loss: 1.5039446353912354, Running Accuracy: 0.9463582677165354, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 95/313, Loss: 1.5341591835021973, Running Accuracy: 0.9462890625, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 96/313, Loss: 1.5276516675949097, Running Accuracy: 0.9462209302325582, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 97/313, Loss: 1.5000828504562378, Running Accuracy: 0.9463942307692308, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 98/313, Loss: 1.491234540939331, Running Accuracy: 0.9468034351145038, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 99/313, Loss: 1.549215316772461, Running Accuracy: 0.9467329545454546, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 100/313, Loss: 1.5106794834136963, Running Accuracy: 0.9468984962406015, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 101/313, Loss: 1.5133311748504639, Running Accuracy: 0.9470615671641791, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 102/313, Loss: 1.528382420539856, Running Accuracy: 0.9469907407407407, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 103/313, Loss: 1.52207612991333, Running Accuracy: 0.9471507352941176, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 104/313, Loss: 1.4785645008087158, Running Accuracy: 0.947536496350365, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 105/313, Loss: 1.557801604270935, Running Accuracy: 0.9472373188405797, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 106/313, Loss: 1.5279828310012817, Running Accuracy: 0.9473920863309353, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 107/313, Loss: 1.496483564376831, Running Accuracy: 0.9477678571428572, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 108/313, Loss: 1.5143698453903198, Running Accuracy: 0.9476950354609929, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 109/313, Loss: 1.5492671728134155, Running Accuracy: 0.9476232394366197, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 110/313, Loss: 1.5287922620773315, Running Accuracy: 0.9477709790209791, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 111/313, Loss: 1.5695562362670898, Running Accuracy: 0.9476996527777778, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 112/313, Loss: 1.554200291633606, Running Accuracy: 0.9478448275862069, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 113/313, Loss: 1.4991343021392822, Running Accuracy: 0.9482020547945206, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 114/313, Loss: 1.5251355171203613, Running Accuracy: 0.9483418367346939, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 115/313, Loss: 1.538377046585083, Running Accuracy: 0.9484797297297297, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 116/313, Loss: 1.525504469871521, Running Accuracy: 0.9486157718120806, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 117/313, Loss: 1.5492275953292847, Running Accuracy: 0.9485416666666666, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 118/313, Loss: 1.5259637832641602, Running Accuracy: 0.9484685430463576, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 119/313, Loss: 1.540129542350769, Running Accuracy: 0.9486019736842105, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 120/313, Loss: 1.5776448249816895, Running Accuracy: 0.9483251633986928, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 121/313, Loss: 1.562187910079956, Running Accuracy: 0.948051948051948, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 122/313, Loss: 1.56026291847229, Running Accuracy: 0.947983870967742, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 123/313, Loss: 1.5138899087905884, Running Accuracy: 0.9479166666666666, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 124/313, Loss: 1.5086219310760498, Running Accuracy: 0.9480493630573248, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 125/313, Loss: 1.4961671829223633, Running Accuracy: 0.9481803797468354, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 126/313, Loss: 1.5030523538589478, Running Accuracy: 0.9485062893081762, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 127/313, Loss: 1.5066434144973755, Running Accuracy: 0.9486328125, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 128/313, Loss: 1.514515995979309, Running Accuracy: 0.9487577639751553, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 129/313, Loss: 1.501887321472168, Running Accuracy: 0.9488811728395061, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 130/313, Loss: 1.5472557544708252, Running Accuracy: 0.9488113496932515, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 131/313, Loss: 1.5369654893875122, Running Accuracy: 0.9487423780487805, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 132/313, Loss: 1.569425106048584, Running Accuracy: 0.9486742424242425, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 133/313, Loss: 1.5491468906402588, Running Accuracy: 0.9486069277108434, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 134/313, Loss: 1.55316162109375, Running Accuracy: 0.9485404191616766, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 135/313, Loss: 1.5455299615859985, Running Accuracy: 0.9484747023809523, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 136/313, Loss: 1.4743987321853638, Running Accuracy: 0.9487795857988166, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 137/313, Loss: 1.5608367919921875, Running Accuracy: 0.9487132352941177, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 138/313, Loss: 1.5645983219146729, Running Accuracy: 0.9486476608187134, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 139/313, Loss: 1.5747572183609009, Running Accuracy: 0.9484011627906976, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 140/313, Loss: 1.4839749336242676, Running Accuracy: 0.9486994219653179, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 141/313, Loss: 1.5235105752944946, Running Accuracy: 0.9486350574712644, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 142/313, Loss: 1.496771216392517, Running Accuracy: 0.94875, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 143/313, Loss: 1.5419942140579224, Running Accuracy: 0.9486860795454546, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 144/313, Loss: 1.5629020929336548, Running Accuracy: 0.9484463276836158, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 145/313, Loss: 1.536297082901001, Running Accuracy: 0.948560393258427, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 146/313, Loss: 1.5730206966400146, Running Accuracy: 0.9483240223463687, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 147/313, Loss: 1.5251504182815552, Running Accuracy: 0.9482638888888889, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 148/313, Loss: 1.491434097290039, Running Accuracy: 0.948549723756906, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 149/313, Loss: 1.485026240348816, Running Accuracy: 0.9488324175824175, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 150/313, Loss: 1.506367564201355, Running Accuracy: 0.948941256830601, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 151/313, Loss: 1.490572452545166, Running Accuracy: 0.9490489130434783, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 152/313, Loss: 1.4891172647476196, Running Accuracy: 0.9493243243243243, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 153/313, Loss: 1.5476592779159546, Running Accuracy: 0.949260752688172, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 154/313, Loss: 1.5980607271194458, Running Accuracy: 0.9486965240641712, Current Accuracy 0.84375\n",
      "Epoch: 5, Batch: 155/313, Loss: 1.5346486568450928, Running Accuracy: 0.9486369680851063, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 156/313, Loss: 1.5569372177124023, Running Accuracy: 0.9484126984126984, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 157/313, Loss: 1.5588570833206177, Running Accuracy: 0.9483552631578948, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 158/313, Loss: 1.4945820569992065, Running Accuracy: 0.9486256544502618, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 159/313, Loss: 1.529686450958252, Running Accuracy: 0.94873046875, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 160/313, Loss: 1.5114569664001465, Running Accuracy: 0.9489961139896373, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 161/313, Loss: 1.563329815864563, Running Accuracy: 0.9489368556701031, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 162/313, Loss: 1.5411131381988525, Running Accuracy: 0.9488782051282051, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 163/313, Loss: 1.5300687551498413, Running Accuracy: 0.9488201530612245, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 164/313, Loss: 1.4718141555786133, Running Accuracy: 0.9490799492385786, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 165/313, Loss: 1.5228545665740967, Running Accuracy: 0.9490214646464646, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 166/313, Loss: 1.5476295948028564, Running Accuracy: 0.948963567839196, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 167/313, Loss: 1.5342122316360474, Running Accuracy: 0.94875, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 168/313, Loss: 1.4848194122314453, Running Accuracy: 0.9490049751243781, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 169/313, Loss: 1.5359567403793335, Running Accuracy: 0.9489480198019802, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 170/313, Loss: 1.5492953062057495, Running Accuracy: 0.9488916256157636, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 171/313, Loss: 1.5078625679016113, Running Accuracy: 0.9491421568627451, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 172/313, Loss: 1.4954205751419067, Running Accuracy: 0.949390243902439, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 173/313, Loss: 1.5546046495437622, Running Accuracy: 0.9493325242718447, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 174/313, Loss: 1.6382761001586914, Running Accuracy: 0.948822463768116, Current Accuracy 0.84375\n",
      "Epoch: 5, Batch: 175/313, Loss: 1.5509322881698608, Running Accuracy: 0.9486177884615384, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 176/313, Loss: 1.5545839071273804, Running Accuracy: 0.9485645933014354, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 177/313, Loss: 1.5046411752700806, Running Accuracy: 0.9486607142857143, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 178/313, Loss: 1.5055060386657715, Running Accuracy: 0.948904028436019, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 179/313, Loss: 1.5338574647903442, Running Accuracy: 0.9488502358490566, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 180/313, Loss: 1.5105152130126953, Running Accuracy: 0.948943661971831, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 181/313, Loss: 1.5380808115005493, Running Accuracy: 0.9488901869158879, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 182/313, Loss: 1.5350209474563599, Running Accuracy: 0.9488372093023256, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 183/313, Loss: 1.5861213207244873, Running Accuracy: 0.9484953703703703, Current Accuracy 0.875\n",
      "Epoch: 5, Batch: 184/313, Loss: 1.5254366397857666, Running Accuracy: 0.9485887096774194, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 185/313, Loss: 1.5115939378738403, Running Accuracy: 0.9486811926605505, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 186/313, Loss: 1.52791166305542, Running Accuracy: 0.9487728310502284, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 187/313, Loss: 1.5347676277160645, Running Accuracy: 0.9487215909090909, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 188/313, Loss: 1.5030944347381592, Running Accuracy: 0.9488122171945701, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 189/313, Loss: 1.5209792852401733, Running Accuracy: 0.948902027027027, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 190/313, Loss: 1.473832130432129, Running Accuracy: 0.9491311659192825, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 191/313, Loss: 1.5076560974121094, Running Accuracy: 0.94921875, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 192/313, Loss: 1.4699034690856934, Running Accuracy: 0.9494444444444444, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 193/313, Loss: 1.5308732986450195, Running Accuracy: 0.949391592920354, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 194/313, Loss: 1.5593535900115967, Running Accuracy: 0.9492015418502202, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 195/313, Loss: 1.4744714498519897, Running Accuracy: 0.9494243421052632, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 196/313, Loss: 1.5199240446090698, Running Accuracy: 0.9495087336244541, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 197/313, Loss: 1.5046114921569824, Running Accuracy: 0.9495923913043478, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 198/313, Loss: 1.4981231689453125, Running Accuracy: 0.9496753246753247, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 199/313, Loss: 1.535473346710205, Running Accuracy: 0.9497575431034483, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 200/313, Loss: 1.5521290302276611, Running Accuracy: 0.9495708154506438, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 201/313, Loss: 1.5108379125595093, Running Accuracy: 0.9497863247863247, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 202/313, Loss: 1.4957222938537598, Running Accuracy: 0.9498670212765957, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 203/313, Loss: 1.49744713306427, Running Accuracy: 0.9500794491525424, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 204/313, Loss: 1.5373626947402954, Running Accuracy: 0.9498945147679325, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 205/313, Loss: 1.5118122100830078, Running Accuracy: 0.9498424369747899, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 206/313, Loss: 1.4800918102264404, Running Accuracy: 0.9500523012552301, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 207/313, Loss: 1.4990105628967285, Running Accuracy: 0.9502604166666667, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 208/313, Loss: 1.5220345258712769, Running Accuracy: 0.9503371369294605, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 209/313, Loss: 1.5283983945846558, Running Accuracy: 0.9502840909090909, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 210/313, Loss: 1.5538570880889893, Running Accuracy: 0.9502314814814815, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 211/313, Loss: 1.5451709032058716, Running Accuracy: 0.9501793032786885, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 212/313, Loss: 1.5769538879394531, Running Accuracy: 0.95, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 213/313, Loss: 1.5188853740692139, Running Accuracy: 0.9500762195121951, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 214/313, Loss: 1.5342411994934082, Running Accuracy: 0.9501518218623481, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 215/313, Loss: 1.498820424079895, Running Accuracy: 0.950226814516129, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 216/313, Loss: 1.5564411878585815, Running Accuracy: 0.950175702811245, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 217/313, Loss: 1.50840425491333, Running Accuracy: 0.95025, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 218/313, Loss: 1.540453314781189, Running Accuracy: 0.950199203187251, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 219/313, Loss: 1.5238672494888306, Running Accuracy: 0.9501488095238095, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 220/313, Loss: 1.4944157600402832, Running Accuracy: 0.9503458498023716, Current Accuracy 1.0\n",
      "Epoch: 5, Batch: 221/313, Loss: 1.5929960012435913, Running Accuracy: 0.9501722440944882, Current Accuracy 0.90625\n",
      "Epoch: 5, Batch: 222/313, Loss: 1.5046876668930054, Running Accuracy: 0.9502450980392156, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 223/313, Loss: 1.5432136058807373, Running Accuracy: 0.9501953125, Current Accuracy 0.9375\n",
      "Epoch: 5, Batch: 224/313, Loss: 1.5057957172393799, Running Accuracy: 0.9502675097276264, Current Accuracy 0.96875\n",
      "Epoch: 5, Batch: 225/313, Loss: 1.5430066585540771, Running Accuracy: 0.950218023255814, Current Accuracy 0.9375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# calculate accuracy\u001b[39;00m\n\u001b[1;32m     27\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, pred\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     29\u001b[0m acc_list\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m     30\u001b[0m running_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(acc_list)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(acc_list)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use corss entropy loss\n",
    "# import accuracy and f1 from sklearn\n",
    "model = ptuned_VIT(classes)\n",
    "model = model.to(device)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# use adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "acc_list = []\n",
    "n_epochs = 10\n",
    "fin_acc = []\n",
    "for epoch in range(n_epochs):\n",
    "    batch_no = 0\n",
    "    for sample in train_loader:\n",
    "        image = sample[0]\n",
    "        label = sample[1]\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        # iamge shape is a, 1, b, c, d make it a, b, c, d\n",
    "        image = image.squeeze(1)\n",
    "        output = model(image)\n",
    "        loss = loss_func(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # calculate accuracy\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        acc = accuracy_score(label.cpu(), pred.cpu())\n",
    "        acc_list.append(acc)\n",
    "        running_acc = sum(acc_list)/len(acc_list)\n",
    "        fin_acc.append(acc)\n",
    "        print(f\"Epoch: {epoch}, Batch: {batch_no}/313, Loss: {loss.item()}, Running Accuracy: {running_acc}, Current Accuracy {acc}\")\n",
    "        batch_no += 1\n",
    "    # write testing loop using test_loader\n",
    "    acc_list = []\n",
    "    for sample in test_loader:\n",
    "        image = sample[0]\n",
    "        label = sample[1]\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        image = image.squeeze(1)\n",
    "        output = model(image)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        acc = accuracy_score(label.cpu(), pred.cpu())\n",
    "        acc_list.append(acc)\n",
    "        running_acc = sum(acc_list)/len(acc_list)\n",
    "        print(f\"Epoch: {epoch}, Test Accuracy: {running_acc}\")\n",
    "    torch.save(model, \"pt_vit_mnist_model.pt\")\n",
    "    torch.save(fin_acc, \"pt_vit_mnist_acc.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptuned_VIT(\n",
      "  (model): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (pooler): ViTPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (embeddings): Embedding(3, 768)\n",
      "  (classification_layer): Linear(in_features=768, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_new = torch.load(\"pt_vit_mnist_model.pt\")\n",
    "print(model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0625, 0.21875, 0.21875, 0.3125, 0.125, 0.3125, 0.21875, 0.125, 0.21875, 0.25, 0.1875, 0.34375, 0.40625, 0.34375, 0.25, 0.34375, 0.53125, 0.40625, 0.5, 0.53125, 0.5625, 0.4375, 0.46875, 0.5, 0.5, 0.625, 0.625, 0.5625, 0.53125, 0.53125, 0.40625, 0.53125, 0.5625, 0.53125, 0.5625, 0.59375, 0.34375, 0.5, 0.53125, 0.5625, 0.6875, 0.5, 0.5, 0.65625, 0.6875, 0.53125, 0.5625, 0.40625, 0.65625, 0.5625, 0.78125, 0.59375, 0.59375, 0.75, 0.625, 0.625, 0.6875, 0.65625, 0.71875, 0.71875, 0.65625, 0.5625, 0.75, 0.6875, 0.625, 0.625, 0.71875, 0.6875, 0.59375, 0.3125, 0.59375, 0.6875, 0.6875, 0.65625, 0.4375, 0.65625, 0.5625, 0.59375, 0.5625, 0.75, 0.6875, 0.65625, 0.6875, 0.65625, 0.875, 0.6875, 0.5625, 0.625, 0.75, 0.6875, 0.59375, 0.6875, 0.5625, 0.78125, 0.84375, 0.625, 0.8125, 0.65625, 0.6875, 0.5, 0.8125, 0.6875, 0.71875, 0.75, 0.84375, 0.75, 0.6875, 0.6875, 0.8125, 0.78125, 0.75, 0.78125, 0.8125, 0.8125, 0.78125, 0.84375, 0.59375, 0.78125, 0.6875, 0.75, 0.71875, 0.75, 0.71875, 0.8125, 0.84375, 0.75, 0.75, 0.71875, 0.5625, 0.8125, 0.5625, 0.6875, 0.65625, 0.78125, 0.71875, 0.78125, 0.84375, 0.75, 0.6875, 0.75, 0.6875, 0.84375, 0.78125, 0.78125, 0.84375, 0.625, 0.65625, 0.8125, 0.6875, 0.78125, 0.8125, 0.8125, 0.84375, 0.6875, 0.71875, 0.78125, 0.78125, 0.75, 0.8125, 0.84375, 0.8125, 0.8125, 0.78125, 0.875, 0.75, 0.84375, 0.6875, 0.8125, 0.78125, 0.78125, 0.71875, 0.875, 0.8125, 0.75, 0.78125, 0.75, 0.75, 0.59375, 0.71875, 0.84375, 0.75, 0.78125, 0.71875, 0.875, 0.75, 0.75, 0.78125, 0.90625, 0.78125, 0.71875, 0.75, 0.75, 0.96875, 0.875, 0.90625, 0.65625, 0.84375, 0.875, 0.75, 0.75, 0.6875, 0.9375, 0.90625, 0.625, 0.8125, 0.75, 0.78125, 0.65625, 0.75, 0.625, 0.8125, 0.6875, 0.875, 0.71875, 0.71875, 0.8125, 0.84375, 0.75, 0.78125, 0.84375, 0.84375, 0.875, 0.8125, 0.71875, 0.78125, 0.9375, 0.78125, 0.71875, 0.84375, 0.8125, 0.875, 0.9375, 0.75, 0.8125, 0.75, 0.71875, 0.78125, 0.75, 0.8125, 0.71875, 0.84375, 0.84375, 0.875, 0.90625, 0.71875, 0.6875, 0.78125, 0.75, 0.875, 0.71875, 0.78125, 0.71875, 0.875, 0.75, 0.75, 0.8125, 0.8125, 0.9375, 0.8125, 0.78125, 0.8125, 0.625, 0.875, 0.8125, 0.90625, 0.75, 0.75, 0.6875, 0.78125, 0.65625, 0.78125, 0.71875, 0.84375, 0.8125, 0.875, 0.78125, 0.84375, 0.78125, 0.90625, 0.8125, 0.71875, 0.5, 0.6875, 0.6875, 0.8125, 0.71875, 0.84375, 0.90625, 0.78125, 0.90625, 0.84375, 0.84375, 0.78125, 0.71875, 0.90625, 0.8125, 0.75, 0.875, 0.84375, 0.8125, 0.90625, 0.84375, 0.75, 0.75, 0.78125, 0.78125, 0.78125, 0.78125, 0.84375, 1.0, 0.78125, 0.78125, 0.84375, 0.84375, 0.84375, 0.75, 0.9375, 0.9375, 0.75, 0.84375, 0.78125, 0.75, 0.8125, 0.875, 0.78125, 0.8125, 0.78125, 0.75, 0.78125, 0.78125, 0.90625, 0.875, 0.78125, 0.84375, 0.84375, 0.6875, 0.78125, 0.875, 0.90625, 0.78125, 0.75, 0.875, 0.65625, 0.75, 0.875, 0.84375, 0.84375, 0.875, 0.75, 0.875, 0.8125, 0.78125, 0.8125, 0.8125, 0.75, 0.8125, 0.875, 0.875, 0.84375, 0.78125, 0.90625, 0.90625, 0.84375, 0.875, 0.75, 0.8125, 0.90625, 0.90625, 0.875, 0.78125, 0.8125, 0.90625, 0.84375, 0.90625, 0.84375, 0.84375, 0.9375, 0.84375, 0.875, 0.90625, 0.90625, 0.875, 0.90625, 0.90625, 0.84375, 0.875, 0.90625, 0.875, 0.875, 0.8125, 0.90625, 0.90625, 0.96875, 0.9375, 0.96875, 0.78125, 0.90625, 0.8125, 0.9375, 0.875, 1.0, 0.84375, 0.75, 0.96875, 0.875, 0.8125, 0.9375, 0.90625, 0.875, 0.75, 0.84375, 0.9375, 0.90625, 0.90625, 0.84375, 0.875, 0.875, 0.84375, 0.8125, 0.90625, 0.875, 0.90625, 0.875, 0.9375, 0.78125, 0.9375, 0.875, 0.96875, 0.90625, 0.875, 0.90625, 0.90625, 0.875, 0.84375, 0.96875, 0.875, 0.96875, 0.96875, 0.875, 0.90625, 0.90625, 0.875, 0.71875, 0.875, 0.8125, 0.90625, 0.875, 0.90625, 0.84375, 0.84375, 0.9375, 0.90625, 0.90625, 0.875, 0.90625, 0.90625, 0.96875, 0.90625, 0.84375, 0.9375, 0.875, 0.84375, 0.75, 0.9375, 0.90625, 0.8125, 0.90625, 0.96875, 0.875, 0.875, 0.875, 0.875, 0.84375, 0.90625, 0.90625, 0.9375, 0.78125, 0.875, 0.875, 0.9375, 0.78125, 0.8125, 0.8125, 0.875, 0.90625, 0.90625, 0.96875, 0.90625, 0.90625, 0.90625, 1.0, 0.875, 0.8125, 0.875, 0.84375, 0.9375, 0.90625, 0.9375, 0.84375, 0.9375, 0.84375, 0.8125, 0.875, 0.90625, 0.8125, 0.9375, 0.875, 0.84375, 0.90625, 0.71875, 0.90625, 0.9375, 0.9375, 0.875, 0.875, 0.9375, 0.9375, 0.875, 0.84375, 0.90625, 0.84375, 0.9375, 0.875, 0.75, 0.875, 0.90625, 0.90625, 0.9375, 0.8125, 0.8125, 1.0, 0.9375, 0.8125, 0.8125, 0.84375, 0.78125, 0.8125, 0.90625, 0.90625, 0.90625, 0.90625, 0.96875, 0.90625, 0.78125, 0.9375, 1.0, 0.84375, 0.9375, 0.8125, 0.9375, 0.78125, 0.9375, 0.8125, 0.9375, 0.875, 0.84375, 0.90625, 0.9375, 0.8125, 0.96875, 0.90625, 0.84375, 0.875, 1.0, 0.9375, 0.90625, 0.9375, 0.9375, 0.90625, 0.90625, 0.9375, 1.0, 0.9375, 0.90625, 0.875, 0.84375, 0.90625, 0.84375, 0.96875, 0.90625, 0.875, 0.90625, 0.96875, 0.96875, 1.0, 0.8125, 0.875, 0.8125, 0.84375, 0.9375, 0.875, 0.9375, 0.90625, 0.875, 0.90625, 0.9375, 0.90625, 1.0, 0.84375, 0.875, 0.96875, 1.0, 0.90625, 0.96875, 0.875, 0.90625, 0.8125, 0.96875, 0.90625, 0.96875, 0.84375, 0.9375, 0.9375, 0.96875, 0.96875, 0.9375, 0.875, 0.9375, 0.9375, 0.875, 0.9375, 0.875, 0.8125, 0.9375, 0.84375, 0.84375, 0.90625, 0.875, 0.96875, 0.96875, 0.90625, 0.90625, 0.90625, 0.9375, 0.9375, 0.90625, 0.9375, 0.875, 1.0, 0.9375, 0.875, 0.9375, 0.8125, 0.9375, 0.875, 0.9375, 0.875, 0.875, 0.875, 0.84375, 0.96875, 0.96875, 0.9375, 0.96875, 0.84375, 0.96875, 0.96875, 0.90625, 0.9375, 0.96875, 0.96875, 0.84375, 0.9375, 0.9375, 0.9375, 0.96875, 0.875, 0.96875, 0.90625, 0.71875, 0.9375, 0.875, 1.0, 0.9375, 0.96875, 0.875, 0.71875, 0.90625, 0.96875, 0.84375, 0.875, 0.875, 0.9375, 0.84375, 0.9375, 0.84375, 0.96875, 0.90625, 0.9375, 0.90625, 1.0, 0.84375, 0.875, 0.875, 0.84375, 0.8125, 0.9375, 0.84375, 1.0, 0.875, 0.9375, 0.96875, 0.9375, 0.96875, 0.9375, 0.96875, 0.9375, 0.9375, 0.875, 0.9375, 0.84375, 0.875, 0.96875, 0.9375, 0.875, 0.96875, 1.0, 0.90625, 0.96875, 0.9375, 0.90625, 0.9375, 0.9375, 0.90625, 0.875, 0.90625, 0.90625, 0.9375, 0.90625, 0.9375, 0.90625, 0.8125, 0.90625, 0.9375, 0.875, 0.9375, 0.90625, 0.875, 0.96875, 0.90625, 0.9375, 0.875, 0.96875, 0.90625, 0.8125, 1.0, 0.90625, 0.84375, 0.84375, 0.96875, 0.96875, 0.90625, 0.96875, 0.96875, 0.75, 0.8125, 0.90625, 0.9375, 0.84375, 0.9375, 0.875, 0.875, 1.0, 0.90625, 0.875, 0.90625, 0.9375, 0.90625, 1.0, 0.90625, 0.96875, 0.875, 1.0, 0.90625, 0.90625, 1.0, 0.96875, 0.8125, 0.875, 0.9375, 0.9375, 0.90625, 0.96875, 0.90625, 0.96875, 0.8125, 0.875, 0.90625, 0.90625, 0.90625, 0.875, 0.9375, 0.90625, 0.90625, 0.9375, 0.9375, 0.9375, 0.90625, 0.875, 0.875, 0.9375, 0.9375, 0.90625, 0.875, 0.90625, 0.96875, 0.90625, 0.90625, 0.875, 0.84375, 0.84375, 0.9375, 1.0, 0.9375, 0.875, 0.875, 0.9375, 0.90625, 0.875, 1.0, 0.8125, 0.96875, 0.875, 0.9375, 0.9375, 0.84375, 0.96875, 0.875, 0.90625, 0.9375, 0.90625, 0.90625, 0.9375, 0.875, 0.9375, 0.96875, 0.84375, 0.96875, 0.875, 0.90625, 0.90625, 0.875, 0.9375, 1.0, 0.90625, 0.875, 1.0, 0.9375, 0.9375, 0.78125, 0.90625, 0.96875, 0.90625, 0.875, 0.96875, 0.875, 0.96875, 0.90625, 0.9375, 0.90625, 0.9375, 0.90625, 1.0, 0.9375, 0.96875, 0.84375, 0.9375, 0.96875, 1.0, 0.96875, 0.96875, 1.0, 0.9375, 0.84375, 0.96875, 0.9375, 0.90625, 0.96875, 0.90625, 0.9375, 0.84375, 0.90625, 0.90625, 0.96875, 0.90625, 0.84375, 0.9375, 0.9375, 0.96875, 0.9375, 0.9375, 0.96875, 0.875, 0.9375, 0.90625, 0.96875, 0.9375, 1.0, 0.96875, 0.9375, 0.96875, 0.84375, 0.96875, 0.9375, 0.9375, 0.96875, 1.0, 0.90625, 0.90625, 0.9375, 0.96875, 0.90625, 0.9375, 0.9375, 0.96875, 0.96875, 0.9375, 0.96875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.96875, 1.0, 0.96875, 0.96875, 0.90625, 0.9375, 0.96875, 0.96875, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.96875, 0.90625, 0.90625, 0.96875, 0.875, 1.0, 0.875, 1.0, 0.9375, 0.90625, 0.9375, 0.96875, 0.90625, 0.84375, 0.875, 0.9375, 0.9375, 0.875, 0.90625, 0.9375, 0.96875, 0.9375, 0.96875, 0.9375, 0.9375, 0.9375, 0.875, 1.0, 0.90625, 0.9375, 0.84375, 0.96875, 0.96875, 0.9375, 0.9375, 0.9375, 0.96875, 0.84375, 0.9375, 0.9375, 0.90625, 1.0, 0.96875, 0.96875, 0.9375, 0.9375, 0.96875, 0.96875, 0.90625, 0.875, 0.875, 0.875, 1.0, 0.96875, 0.9375, 1.0, 0.96875, 0.96875, 0.9375, 1.0, 0.90625, 1.0, 0.9375, 0.96875, 0.9375, 0.9375, 0.84375, 0.9375, 0.96875, 0.96875, 0.96875, 0.96875, 0.9375, 0.96875, 0.9375, 0.875, 0.96875, 1.0, 0.875, 0.84375, 0.90625, 0.9375, 0.9375, 0.875, 0.90625, 0.96875, 0.90625, 0.9375, 0.9375, 1.0, 0.9375, 0.875, 0.875, 0.96875, 0.9375, 0.96875, 0.90625, 0.96875, 0.90625, 0.84375, 0.96875, 0.90625, 0.90625, 0.96875, 0.9375, 0.90625, 0.9375, 0.9375, 0.9375, 0.96875, 0.96875, 0.96875, 0.90625, 0.96875, 0.9375, 0.96875, 0.9375, 0.875, 0.96875, 0.90625, 0.875, 0.9375, 0.875, 0.96875, 0.90625, 0.90625, 0.96875, 1.0, 0.96875, 0.96875, 0.9375, 0.875, 0.875, 0.90625, 0.875, 1.0, 1.0, 0.90625, 1.0, 0.96875, 0.96875, 0.96875, 0.90625, 0.90625, 1.0, 0.96875, 0.9375, 0.96875, 0.90625, 0.9375, 0.9375, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 1.0, 0.9375, 0.96875, 1.0, 0.96875, 0.96875, 0.90625, 0.90625, 0.9375, 1.0, 0.96875, 0.9375, 0.875, 0.8125, 0.90625, 0.9375, 1.0, 0.875, 0.96875, 0.96875, 0.9375, 0.8125, 0.9375, 0.9375, 0.875, 0.9375, 1.0, 1.0, 0.875, 0.9375, 0.90625, 0.9375, 0.9375, 1.0, 0.875, 0.9375, 0.96875, 1.0, 1.0, 0.90625, 0.90625, 0.96875, 1.0, 0.96875, 0.96875, 0.9375, 0.9375, 0.9375, 0.90625, 0.96875, 0.96875, 0.9375, 0.90625, 0.96875, 0.875, 0.96875, 0.96875, 0.96875, 1.0, 0.96875, 0.96875, 0.9375, 0.96875, 1.0, 0.875, 0.96875, 1.0, 0.9375, 0.9375, 0.9375, 1.0, 1.0, 0.90625, 0.8125, 0.96875, 0.9375, 0.90625, 0.9375, 0.875, 0.84375, 0.90625, 0.90625, 0.96875, 0.9375, 0.96875, 0.96875, 0.96875, 0.8125, 0.9375, 0.9375, 0.875, 0.96875, 0.90625, 0.90625, 0.9375, 0.9375, 0.90625, 0.9375, 0.9375, 0.8125, 0.875, 0.96875, 0.96875, 1.0, 0.9375, 1.0, 0.875, 0.96875, 0.9375, 0.9375, 0.96875, 0.96875, 0.84375, 0.875, 1.0, 0.96875, 1.0, 0.9375, 0.96875, 0.9375, 0.9375, 0.96875, 1.0, 0.96875, 0.90625, 0.96875, 0.90625, 0.96875, 0.9375, 0.96875, 0.9375, 0.96875, 0.96875, 1.0, 0.9375, 0.90625, 0.9375, 0.90625, 0.96875, 0.96875, 0.96875, 1.0, 0.9375, 0.875, 0.96875, 0.90625, 0.90625, 0.9375, 0.9375, 0.96875, 0.96875, 0.9375, 1.0, 0.875, 0.96875, 0.90625, 0.84375, 0.9375, 0.90625, 0.96875, 0.96875, 0.9375, 0.90625, 0.96875, 0.96875, 0.84375, 0.96875, 0.84375, 1.0, 0.9375, 0.96875, 0.9375, 0.8125, 1.0, 0.90625, 0.9375, 1.0, 1.0, 1.0, 0.90625, 0.90625, 0.9375, 1.0, 1.0, 1.0, 0.90625, 0.875, 0.9375, 1.0, 1.0, 0.9375, 0.875, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.96875, 0.96875, 0.96875, 0.96875, 0.90625, 0.9375, 0.875, 0.9375, 0.96875, 1.0, 1.0, 0.9375, 0.96875, 0.90625, 1.0, 0.96875, 0.9375, 1.0, 0.96875, 0.96875, 0.90625, 1.0, 0.96875, 0.9375, 0.96875, 0.9375, 0.90625, 0.875, 0.8125, 1.0, 0.8125, 0.90625, 1.0, 0.96875, 0.875, 0.875, 0.875, 1.0, 0.96875, 0.96875, 0.90625, 1.0, 1.0, 1.0, 1.0, 0.96875, 0.9375, 0.90625, 0.9375, 0.9375, 0.96875, 0.84375, 1.0, 0.84375, 0.90625, 0.96875, 0.9375, 0.96875, 0.96875, 0.9375, 1.0, 0.9375, 0.9375, 0.96875, 0.96875, 0.90625, 0.96875, 0.96875, 0.9375, 1.0, 0.96875, 0.96875, 0.9375, 0.90625, 0.96875, 0.9375, 0.90625, 1.0, 1.0, 0.9375, 0.96875, 0.96875, 0.9375, 0.9375, 0.96875, 0.96875, 0.9375, 0.96875, 0.96875, 1.0, 0.96875, 0.90625, 0.9375, 0.96875, 1.0, 0.96875, 0.875, 0.875, 0.96875, 0.9375, 0.96875, 0.9375, 0.90625, 0.96875, 0.9375, 0.875, 1.0, 1.0, 0.9375, 0.9375, 0.96875, 0.9375, 0.84375, 0.875, 0.96875, 0.96875, 0.9375, 1.0, 0.96875, 1.0]\n"
     ]
    }
   ],
   "source": [
    "new_list = torch.load(\"pt_vit_mnist_acc.pt\")\n",
    "print(new_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
